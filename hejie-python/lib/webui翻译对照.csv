英文,中文(DM),中文(github),中文(内部),日文
tp_baidu,,,,tp_baidu
"If the number of tokens is more than the number of vectors, some may be skipped.\nLeave the textbox empty to start with zeroed out vectors",,,,ト`クンの数がベクタ`の数より多い龊稀⒁徊郡スキップされることがあります。\nテキストボックスを空にしておくと、ゼロになったベクタ`からスタ`トします
(when reading generation parameters from text into UI),,,(当从外部复制生成参数的时候),
Load training option from saved json file. This will override settings above,,,,保存されたjsonファイルからトレ`ニングオプションをiみzみます。これは既存のO定を上きします
Use half floats,,,使用半精度浮点,
Torch AdamW,,,,Torch AdamW
sd-parseq manifest,,,,sd-parseqマニフェスト
Select ControlNet input from random segmentation gallery. Choose 2 for Edit-Anything ControlNet.,,,选项1是为了以后ControlNet预留的现在没有功能，选项2是搭配Edit-Anything 使用的。,
to fix the issue.,修复,修复,修复,
"Ignore the negative prompt. Magic Prompt and I'm feeling lucky generate negative prompts by default, check this to disable that functionality.",忽略负面提示词\n魔法提示词和手气不错默认生成负面提示词，勾选此选项以禁用这种功能,忽略反向提示词\n魔法提示词和手气不错默认生成反向提示词，勾选此选项以禁用这种功能,忽略反向提示词\n魔法提示词和手气不错默认生成反向提示词，勾选此选项以禁用这种功能,
Only Hand,仅额外编辑手部骨架（隐藏脚）,,,
img2img folder,,,,img2imgフォルダ
"Separate a list of words with commas, and the first word will be used as a keyword: script will search for this word in the prompt, and replace it with others",以逗号分割的单词列表，第一个单词将被用作关键词：脚本将在提示词中搜索这个单词，并用其他单词替换它,以逗号分割的单词列表，第一个单词将被用作关键词：脚本将在提示词中搜索这个单词，并用其他单词替换它,以逗号分割的单词列表，第一个单词将被用作关键词：脚本将在提示词中搜索这个单词，并用其他单词替换它,
Just resize,拉伸,拉伸,拉伸,湫
mn,,,,mn
Cutoff Strong,,,,Cutoff く遮断
Sidebar default width,侧边栏默认宽度,,,
Cutoff Disable for Negative Prompt,,,,Cutoff ネガティブプロンプトではo炕
Extract every nth frame,每第 n 帧提取一次,每第 n 帧提取一次,每第 n 帧提取一次,抽出rのフレ`ムg隔
Classification dataset directory (optional).,分类(Classification)数据集目录（可选）,分类(Classification)数据集目录（可选）,分类(Classification)数据集目录（可选）,
softshrink,softshrink,,,softshrink
ControlNet v1.1.273,扩散控制网络(ControlNet),,,
Loads weights from checkpoint before making images. You can either use hash or a part of filename (as seen in settings) for checkpoint name. Recommended to use with Y axis for less switching.,在生成图像之前从 Stable Diffusion 模型(ckpt) 中加载权重。你可以使用哈希值或文件名的一部分（如设置中所示）作为 Stable Diffusion 模型(ckpt) 名称。建议用在Y轴上以减少过程中模型的切换,在生成图像之前从模型(ckpt)中加载权重。你可以使用哈希值或文件名的一部分（如设置中所示）作为模型(ckpt)名称。建议用在Y轴上以减少过程中模型的切换,在生成图像之前从模型(ckpt)中加载权重。你可以使用哈希值或文件名的一部分（如设置中所示）作为模型(ckpt)名称。建议用在Y轴上以减少过程中模型的切换,画像を生成する前に、Checkpointからweights重みをiみzみます。Checkpoint名には、ハッシュまたはファイル名の一部を使用できます(O定で表示)。切り替えを少なくするには、YSでの利用を推Xします。
Reload Cache List,重新加载缓存列表,,,
Please test on small images before actual upscale. Default params require denoise <= 0.6,放大前请先对小图像测试。默认参数需要重绘幅度小于0.6,,,
ckpt,,,,ckpt
Lora Weight,,,,LoRA Weights
UNet Weight 2,UNet 权重 2,UNet 权重 2,UNet 权重 2,UNetの重み 2
bottom-to-top,,,,下から上へ
Localization,,,本地化,
stable-diffusion-webui-randomize,随机化,随机化,随机化,stable-diffusion-webui-rembg
Randomize Width,随机化 宽度,随机化 宽度,随机化 宽度,
Copy to ControlNet Inpaint,将蒙版复制到 ControlNet 的局部重绘,,复制到ControlNet重绘,
X panning,沿 X 轴滚动,沿 X 轴滚动,沿 X 轴滚动,xS方向へずらす
Maximum batch size,,,最大批处理大小,
ControlNet v1.1.192,扩散控制网络(ControlNet),,,
Split oversized images into two,将过大的图像分为两份,将过大的图像分为两份,将过大的图像分为两份,
DDIM ETA ? eta,,,,DDIM ETA ? eta
BSRGAN 4x,BSRGAN 4x,,,
Blacklist,黑名单（禁用tag自动填充）,黑名单（禁用tag自动填充）,黑名单（禁用tag自动填充）,ブラックリスト
OpenPose,,,姿态,
kmeans,,,,k平均法
Inter Denoise,,,,Inter Denoise
?,?,,,
Just Resize,拉伸引导图像以适配画布（不推荐）,仅调整大小（拉伸）,仅调整大小（拉伸）,gに湫
https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git,,,,https://github.com/klimaleksus/stable-diffusion-webui-conditioning-highres-fix.git
Style to fuse,,,,Style to fuse
Keep -1 for seeds,保持随机种子为-1,保持随机种子为-1,保持随机种子为-1,シ`ドを-1で固定
Abandoned,,,,削除された
Meli/GPT2-Prompt,,,,Meli/GPT2-Prompt
Hide samplers in user interface (requires restart),在用户界面中隐藏采样器（需要保存设置并重启）,在用户界面中隐藏采样器（需要保存设置并重启）,在用户界面中隐藏采样器（需要保存设置并重启）,使わないサンプリングアルゴリズムをLす (再起婴必要)
Padding radius in pixels ? padding,,,,ピクセルg位のパディング半径 <unk> padding
Parse Recipe,,剖析配方,剖析配方,
Final image not showing up? Try using this workaround ? use_workaround,,,,最K画像が表示されませんか？この回避策を使用してみてください ? use_workaround
Prerequisites and Important Info:,,,,前提条件と重要情螅
Custom width,,,,カスタム幅
negative,负面,负面,负面,ネガティブ
Keep models in VRAM,,,保持反推模型在显存中,
Scale Learning Rate,缩放学习率,缩放学习率,缩放学习率,
Use delta values for movement parameters,,,,移鹰靴楗岍`タ`にデルタを使用
ControlNet v1.1.219,扩散控制网络(ControlNet),,,
hardtanh,hardtanh,,,hardtanh
"Progressbar/preview update period, in milliseconds",进度条/预览更新周期(毫秒),进度条/预览更新周期(毫秒),进度条/预览更新周期(毫秒),M氓些`/プレビュ`の更新期g（ミリ秒）
"These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.",,,,これらのスクリプトは、生成ステップ中の拥膜CFG制御を可能にします。m切なO定により、img2imgでノイズ除去が少ない龊悉扦狻⑸成された画像にダメ`ジを与えることなく、高CFGのを得ることができる可能性があります。
reflection,,,,反射
[ControlNet] Enabled,,,,[ControlNet] 有炕
sd-webui-bilingual-localization,双语本地化插件,双语对照翻译插件,双语对照翻译插件,sd-webui-bilingual-localization
Arm Length,整体臂长,,,
Enable Tiled VAE,启用 分块VAE(Tiled VAE),,启用分块VAE,
Output format,,,,出力形式
pluralize,,,,}数形
Swap X/Z axes,XZ互换,XZ互换,XZ互换,X/ZSを入れ替える
Train Embedding,训练 Embedding,训练 Embedding,训练 Embedding,Embeddingの学を_始
Tag Autocomplete,Tag自动填充,Tag自动填充,Tag自动填充,自鹰骏把a完
ControlNet v1.1.225,扩散控制网络(ControlNet),,,
Preview mask,预览蒙版,,预览,
ControlNet v1.1.116,扩散控制网络(ControlNet),,,
sd-webui-regional-prompter,,,,sd-webui-regional-prompter
sd,,,,sd
Steps (Number of images between each seed),,,,ステップ (各シ`ドgの画像数)
Use PNG alpha channel as loss weight,,,使用PNG的alpha通道作为loss权重,PNGのアルファチャンネルをロスウェイトとして使用する。
https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git,,,,https://github.com/toshiaki1729/stable-diffusion-webui-text2prompt.git
Force Reset,强制重置,强制重置,强制重置,
config,,配置,配置,O定
is,,,,is
Interrupt,中止,中止,中止,中断
Rebuild exif cache,,,重建exif缓存,Exifキャッシュを再B
Padding,,,,余白
Make Images,生成图片（OpenPose + 手脚部位的深度图、法线贴图、硬边缘检测图）,,,
Resize seed from width,宽度(Resize seed),宽度(Resize seed),宽度(Resize seed),元の幅と辘工毳珐`ドからのサイズ涓
Supported engines:,,,,サポ`トしているエンジン:
Limit the height of preivews to the height of the browser window (.html preview files are always limited regardless of this setting),,,,プレビュ`の高さをブラウザウィンドウの高さまでに制限する (.html プレビュ`ファイルはこのO定にvSなく常に制限されます)
ControlNet v1.1.295,扩散控制网络(ControlNet),,,
model_name,,模型名,模型名,
Colorprimaryactive,Colorprimaryactive,,,
Repeats,,,,Rり返し数
"You can generate image layout either in single image or in batch. Since there might be A LOT of outputs, there is no gallery for preview. You need to go to the output folder for either single image or batch process.",可在此生成单个图像或批量图像布局。由于可能有很多输出，因此不提供页面预览，需要转到单个图像或批处理的输出文件夹查看,,这个功能将输入的图片拆分成多个图层（每个图层一张图），这可能将产生很多图片。,
Include Sub Images,预览子图像,预览次级图像,预览次级图像,サブ画像を含める
(noise multiplier; higher = more unperdictable results),,,（噪音的倍增幅度，此参数越高结果就会越不可预知）,
no image selected,,,未输入图片,
Rotation 3D X,,,,3D回X
Randomize Highres. Width,随机化 高分辨率修复的第一遍的宽度,随机化 高清修复的第一遍的宽度,随机化 高清修复的第一遍的宽度,
"DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext",,,,"DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext"
DreamArtist Train,梦作家 训练,梦作家 训练,梦作家 训练,ドリ`ムア`ティストのトレ`ニングを行う
Dilation factor (B),扩张因子 (B),扩张因子 (B),扩张因子 (B),
Token Merging - Merge attention,合并关注层(attention),,,
Latent tile batch size,潜空间图块(Latent tile)批处理规模,潜变量分块(Latent tile)批处理规模,潜变量分块(Latent tile)批处理规模,Latentタイル バッチサイズ
Unprompted Seed,,,,未プロンプトのシ`ド
MultiDiffusion,分块多重扩散(MultiDiffusion),,,MultiDiffusion
Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.,通过对比调整提示词，实现可控的单发文本到图像生成,通过对比调整提示词，实现可控的单发文本到图像生成,通过对比调整提示词，实现可控的单发文本到图像生成,Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.
dot size,,,,ドットサイズ
regex - e.g. ^(?!.*Hires).*$,使用正则表达式，如^(?!.*Hires).*$,使用正则表达式，如^(?!.*Hires).*$,使用正则表达式，如^(?!.*Hires).*$,正表F - 例: ^(?!.*Hires).*$
ControlNet v1.1.153,扩散控制网络(ControlNet),,,
LDSR processing steps. Lower = faster,LDSR 处理步数。越少越快,LDSR 处理步数。越少越快,LDSR 处理步数。越少越快,LDSRのI理ステップ(低いほど速い)
"Convert currently loaded checkpoint into ONNX. The conversion will fail catastrophically if TensorRT was used at any point prior to conversion, so you might have to restart webui before doing the conversion.",,,将当前加载的chenckpoint转换为ONNX格式。如果在转换之前的任何时候使用过TensorRT，则转换将失败，因此您可能需要在转换之前重新启动webui。,
ControlNet v1.1.181,扩散控制网络(ControlNet),,,
ControlNet v1.1.111,扩散控制网络(ControlNet),,,
sr,,,,sr
rw,,,,rw
openpose_face,姿态检测（openpose 模型，OpenPose 算法，姿态+脸部）,,姿态检测（OpenPose 算法，身体+脸部）,
This is your models list.,,这是您的模型列表,这是您的模型列表,
Custom size,,,,任意のサイズ
"Extra paths to scan for LoRA models, comma-separated. Paths containing commas must be enclosed in double quotes. In the path, "" (one quote) must be replaced by """" (two quotes).","扫描 LoRA 模型的附加目录，以逗号分隔。包含逗号的路径必须用双引号括起来。 在路径中，""（一个引号）必须替换为""""（两个引号）。","扫描 LoRA 模型的附加目录，以逗号分隔。包含逗号的路径必须用双引号括起来。 在路径中，""（一个引号）必须替换为""""（两个引号）。","扫描 LoRA 模型的附加目录，以逗号分隔。包含逗号的路径必须用双引号括起来。 在路径中，""（一个引号）必须替换为""""（两个引号）。","追加でスキャンする LoRA モデルのパス (カンマで区切って}数指定)。パスの中でカンマを含む龊悉媳丐憾重引用符で欷啾匾がある。パス内の '' (g一引用符) は """" (二重引用符) に置きQえる必要がある。"
then press 'Apply' to write them to,,,然后点击“应用”按钮把配置文件写入,
Vertical Mirroring,垂直镜像,垂直镜像,垂直镜像,上下R映化
Hypernetwork-MonkeyPatch-Extension,,,,Hypernetworks-Monkeypatch
Auto TLS-HTTPS,自动 TLS-HTTPS,自动 TLS-HTTPS,自动 TLS-HTTPS,Auto TLS-HTTPS
Mask,蒙版,蒙版,蒙版,マスク
Booru tag autocompletion,Booru 标签(tag)自动补全,Booru 标签(tag)自动补全,Booru 标签(tag)自动补全,Booru tag autocompletion
Replace spaces with a comma and a space,,"用逗号', '替换空格","用逗号', '替换空格",
Disable image generation. Useful if you only want to generate text prompts. (1 image will still be generated to keep Auto1111 happy.).,,,,画像生成をo郡摔筏蓼埂％抓恁螗抓趣违匹ストのみを生成したい龊悉吮憷です。(Auto1111の状BをS持するため、1枚の画像は生成されます。)
Help,帮助,帮助,帮助,
ultrafast,,,,最高に速い
"(skip negative prompt for some steps when the image is almost ready; 0=disable, higher=faster)",,,（在图片已经基本完成时跳过部分负面提示词的处理步骤；0=不跳过，此参数越高跳过的步骤越多，速度也就越快）,
(0 = maximum effect; 1 = minimum effect),,,（0表示影响越大，1表示影响越小）,
Aspect Ratio selector,,,,Aspect Ratio selector
scribble_hed,涂鸦处理（scribble 模型，HED 算法）,,涂鸦处理（scribble，HED 算法）,
Accent,Catppuccin 主题风格（按钮颜色，根据主题样式不同会发生变化，不一定完全与描述相同）,Catppuccin 主题风格（按钮颜色，根据主题样式不同会发生变化，不一定完全与描述相同）,Catppuccin 主题风格（按钮颜色，根据主题样式不同会发生变化，不一定完全与描述相同）,
The annotator directory inside the SAM extension directory is only a symbolic link. This is to save your space and make the extension repository clean.,SAM 插件目录中的预处理器目录只是一个符号链接，这是为了节省您的空间并使扩展存储库变得干净,,分割万物（Segment Anything）插件目录下的预处理器文件夹只是一个符号链接，它并没有真正占用您的储存空间,
"Gamepad repeat period, in milliseconds",,,手柄的采样周期(ms),
Max Resolution,,,,最大解像度
EMA replace steps (positive),EMA 替换步数 (正),EMA 替换步数 (正),EMA 替换步数 (正),EMAの置Qステップ（ポジティブ）
spaceship-digipa-low-impact,,,,宇宙船演算子(digipa-low-impact)
sd-webui-supermerger,SuperMerger,,,
Target tokens (comma separated),需要分离的目标词（逗号分隔）,,要阻断互相污染的提示词（逗号分隔）,象となるト`クン (カンマ区切り)
shift-attention,关注转移,关注转移,关注转移,shift-attention
WDv1.4 Tagger Score Threshold,WD1.4 Tag反推算法 置信阈值下限,,,WDv1.4 タグのスコアしきい
DeepBooru,,,,DeepBooru
ddim,ddim,,,
Checkpoint Merger,模型合并,模型合并,模型合并,Checkpointのマ`ジ
"Hires Fix , Batch size",高分辨率修复 & 批量图片生成,,,
tg,,,,tg
Custom Theme.,,自定义主题,自定义主题,カスタムテ`マ
Control Model - 4,控制模型-4,,,
"Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.",,,,WebUIで3Dモデルのポ`ズを集し、ControlNet用のOpenpose/Depth/Normal/Cannyマップを生成します。
Search,搜索,搜索,搜索,仕
ControlNet v1.1.205,扩散控制网络(ControlNet),,,
FOR HELP CLICK HERE,,,,ヘルプはこちら
depth_leres++,深度估算（depth 模型，LeReS++ 算法）,,深度检测（depth，LeReS++ 算法）,
Hide heatmap images,,,,ヒ`トマップ画像を非表示
reference_adain+attn,图像参考（无需模型，AdaIN 算法+注意力层图像链接）,,图像参考（无需模型，AdaIN风格转移+注意力链接）,
eu,,,,eu
Preload images at startup,在启动时预加载图像,在启动时预加载图像,在启动时预加载图像,起rに画像をプリロ`ドする
embedding-inspector,,,,embedding-inspector
"Upscale masked region to target resolution, do inpainting, downscale back and paste into original image",将蒙版区域（包括预留像素长度的缓冲区域）放大到目标分辨率，进行局部重绘。\n然后缩小并粘贴回原始图像中,将蒙版区域（包括预留像素长度的缓冲区域）放大到目标分辨率，进行局部重绘。\n然后缩小并粘贴回原始图像中,将蒙版区域（包括预留像素长度的缓冲区域）放大到目标分辨率，进行局部重绘。\n然后缩小并粘贴回原始图像中,
Draw mask,绘制蒙版,绘制蒙版,绘制蒙版,
Crop to fit,裁剪以适应宽高比,裁剪以适应宽高比,裁剪以适应宽高比,合うように切りiき
Removed specified value(s) from the array ? _remove,,,,指定したを配列から削除する ? _remove
Source language,需要被翻译的语言,,,
EulerDiscrete,,,,EulerDiscrete
free_youdao_zh,,,,free_youdao_zh
Noise Inversion,噪声反转,,,
Interpolate an existing video,,,,既存のビデオをagする
Video output,,视频输出,视频输出,
like here,,,,ここのように
3D Model,,,,3Dモデル
Re-run your combinatorial batch this many times with a different seed each time.,,,,盎禺なるシ`ドを使って、Mみ合わせバッチを何度も再g行します。
subtract,,,,p算
Select this if you want to use the same seed for every generated image.\nThis is useful if you want to test prompt variations while using the same seed.\nIf there are no wildcards then all the images will be identical.,勾选此选项以对每张生成的图像用同样的随机种子\n这在想用同样的随机种子测试提示词变化时会有用\n没有通配符则所有图像会相同,勾选此选项以对每张生成的图像用同样的随机种子\n这在想用同样的随机种子测试提示词变化时会有用\n没有通配符则所有图像会相同,勾选此选项以对每张生成的图像用同样的随机种子\n这在想用同样的随机种子测试提示词变化时会有用\n没有通配符则所有图像会相同,すべての画像に同じシ`ドを使用する龊悉稀これをxkします。\nこれは、プロンプトのバリエ`ションをテストしたい龊悉吮憷です。\nワイルドカ`ドがない龊悉稀⒒像は全て同じものになります。
all,全部,全部,全部,すべて
Dimension lower bound,,,边长最小值,寸法（幅、高さ）の下限
Always print all generation info to standard output,始终将所有生成信息输出到 standard output (一般为控制台),始终将所有生成信息输出到 standard output (一般为控制台),始终将所有生成信息输出到 standard output (一般为控制台),常にすべての生成にvする情螭食隽(stdout)に出力する
Plot,图表,绘表,绘表,描画
Upscale Before Restoring Faces,放大后再进行面部修复,放大后再进行面部修复,放大后再进行面部修复,
characters,,,,文字数
ControlNet v1.1.293,扩散控制网络(ControlNet),,,
Append value(s) to the array ? _append,,,,配列にを末尾に追加する ? _append
Conditioning Highres.fix strength (for sd-v1-5-inpainting),高分辨率修复原图调节强度 (专为 sd-v1-5-inpainting 设计),高清修复原图调节强度 (专为 sd-v1-5-inpainting 设计),高清修复原图调节强度 (专为 sd-v1-5-inpainting 设计),コンディショニングHighres.fix度(sd-v1-5 inpaint用)
"Maximum mask size (if a bigger mask is found, it will bypass the shortcode) ? mask_size_max",,,,最大マスクサイズ（より大きなマスクがつかった龊稀ショ`トコ`ドはバイパスされます）? mask_size_max
(O2) Output ckpt Name,,(O2) ckpt 输出名,(O2) ckpt 输出名,
Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.,,,,Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.
Resume from timestring,,,,タイムスタンプから再_する
overlap,,,,重ね合わせ
"Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.",,,,スキャンの移釉S容度をQ定します。S容欷低いと、静止している部分の小さな浠も手してしまいます。高いでは、より少ない婴を食訾筏蓼埂＠硐氲膜摔稀⒅匾な婴を食訾贰⒕驳膜什糠证ojな部分をスキップして、それらのフリックをpらすことです。
(only applies if non-zero and overrides above),,,（此参数取0时则使用全局Token合并率）,
Save in .safetensors format,,,,.safetensors形式で保存
How many classifier/regularization images to generate at once.,一次生成多少分类/规范化图像。,一次生成多少分类/规范化图像。,一次生成多少分类/规范化图像。,
Colorbgspotlight,Colorbgspotlight,,,
Control Model - 7,控制模型-7,,,
bn,,,,bn
eo,,,,eo
hyper,超网络(Hypernetwork),hyper,hyper,
"To enable, check use_mask in the Init tab",,,,有郡摔工毪摔稀initタブのuse_maskをチェックしてください
snakecase,,,,スネ`クケ`ス
--api,,,,--api
"for explanation of each parameter. If you still cannot understand, use default.",查看所有可选参数的说明，看不懂请保持默认，为方便与原文对照，此段参数不做翻译,,”查看，如果您不清楚如何设置，请保持默认值。,
A generic prompt used to generate a sample image to verify model fidelity.,,,,モデルの忠g度を试^するためのサンプル画像の生成に使用される用プロンプト。
zeros,,,,ゼロ
Step size (grad mode),步幅 (梯度模式),步幅 (梯度模式),步幅 (梯度模式),
"For hires fix, calculate conds of second pass using extra networks of first pass.",,,高清修复时，使用和第一步相同的额外网络.,
Copy to Inpaint Upload & ControlNet Inpainting,>>局部重绘(上传蒙版) & >>ControlNet 进行局部重绘,,复制到局部重绘（上传蒙版）或ControlNet重绘,
exclusion,,,,除外
"Process an image, use it as an input, repeat.",处理一张图像，将其作为输入，并重复,处理一张图像，将其作为输入，并重复,处理一张图像，将其作为输入，并重复,
Network module (used throughout this tab),附加网络模块(仅此页面使用),附加网络类型(仅此页面使用),附加网络类型(仅此页面使用),
Deselect visible tags,取消选择可见的 Tag,,,表示中のタグのxkを解除
Save masks,保存蒙版,保存蒙版,保存蒙版,
Some settings have been moved to the settings tab. Find them in the Dynamic Prompts section.,,,,いくつかのO定は、O定タブに移婴丹欷皮い蓼埂％昆ぅ圣撺氓プロンプトのセクションを探してください。
Update Parameters,,,,パラメ`タ`を更新
Interpolation Method,合并算法（具体说明会显示在页面顶部）,合并算法（具体说明会显示在页面顶部）,合并算法（具体说明会显示在页面顶部）,混合(Interpolation)方式
"Original value, with advanced expression support ? _from",,,,高度な式サポ`トを持つ元の ? _from
Save score as EXIF or PNG Info Chunk,,,,スコアをEXIFまたはPNGチャンクに保存
Ending Control Step,干涉结束步数,,干涉结束位置,
mbw alpha and beta,分层设置 α和β（每2行为一组）,,,
Upscale factor,,,,アップスケ`ルS数
Redraw options:,,,,再描画オプション:
Delimiter to check for ? _delimiter,,,,チェックする区切り文字 ? _delimiter
https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git,,,,https://github.com/AlUlkesh/stable-diffusion-webui-images-browser.git
OUT_B_10,,模型B 输出层10,模型B 输出层10,
Chess,,,,チェス
Video Output Settings,,,,ビデオ出力のO定
Auto,,,,自
Dynamic Prompts enabled,启用动态提示词,启用动态提示词,启用动态提示词,Dynamic Prompts 有炕
Generate bounding box,生成选区,,生成包围盒,
Replace order (replace mode),取代顺序 (取代模式),取代顺序 (取代模式),取代顺序 (取代模式),
# of threads to use for hash calculation (increase if using an SSD),用于哈希计算的线程数（如果使用SSD可适当增加）,用于哈希计算的线程数（如果使用SSD可适当增加）,用于哈希计算的线程数（如果使用SSD可适当增加）,ハッシュ算に # のスレッドを使用する (SSDを使用する龊悉加)
softmax2d,softmax2d,,,softmax2d
An object detection and auto-mask extension for Stable Diffusion web UI.,一个物件检测与自适应蒙版扩展,一个物件检测与自适应蒙版扩展,一个物件检测与自适应蒙版扩展,Stable DiffusionのWeb UI用のオブジェクト食訾茸鹰蕙攻のC能です。
Maximum number of faces to detect,,,检测面部的最大数量,
Remember to use same fps as generated video for DFI,,,,Remember to use same fps as generated video for DFI
make_grid,,制作宫格,制作宫格,
Upload Mask to ControlNet Inpainting,上传蒙版到 ControlNet 局部重绘的相关设置,,上传蒙版到ControlNet重绘,
Maximum denoising strength ? denoising_max,,,,最大ノイズ除去度→ ノイズ除去 最大
Append Movement tags from CLIP,,,,CLIPからム`ブメントタグを追加
words,,,,gZ
Benchmark Data,基准数据,,,
Use CPU Only (SLOW),只用 CPU (很慢),只用 CPU (很慢),只用 CPU (很慢),
Copy to favorites,复制到收藏夹,复制到收藏夹,复制到收藏夹,
"Here, a random number between 1 and 3 words from adjective.txt will be chosen and joined together with the word 'and' instead of the default comma.",此处，会从 adjective.txt 中选取随机 1 至 3 行，以 'and' (而不是默认的逗号)拼接,此处，会从 adjective.txt 中选取随机 1 至 3 行，以 'and' (而不是默认的逗号)拼接,此处，会从 adjective.txt 中选取随机 1 至 3 行，以 'and' (而不是默认的逗号)拼接,"この龊1~3のgZがadjective.txtからxkされ、それらのgZがandで接Aされます。デフォルトO定はカンマ”,”です。"
training,训练相关,训练相关,训练相关,トレ`ニング
wd14-vit-v2,,,,wd14-vit-v2
pinpoint blocks (alpha or beta must be selected for another axis),受另一个轴控制的 层ID,,,
fill it with colors of the image,用图像的颜色(高强度模糊)填充它,用图像的颜色(高强度模糊)填充它,用图像的颜色(高强度模糊)填充它,元画像の色で埋める
Decays learning rate every cycle,,,,各サイクルの学率を算出する
Layer4 mask blur,,,,Layer4 マスクのぼかし
Frames to process,,,,Frames to process
Video extract,,,,Video extract
kk,,,,kk
"In loopback mode, on each loop the denoising strength is multiplied by this value. <1 means decreasing variety so your sequence will converge on a fixed picture. >1 means increasing variety so your sequence will become more and more chaotic.",在回送模式下，在每个循环中，重绘幅度都会乘以该值。<1 表示减少多样性，因此你的这一组图将集中在固定的图像上。>1 意味着增加多样性，因此你的这一组图将变得越来越混乱,在回送模式下，在每个循环中，重绘幅度都会乘以该值。<1 表示减少多样性，因此你的这一组图将集中在固定的图像上。>1 意味着增加多样性，因此你的这一组图将变得越来越混乱,在回送模式下，在每个循环中，重绘幅度都会乘以该值。<1 表示减少多样性，因此你的这一组图将集中在固定的图像上。>1 意味着增加多样性，因此你的这一组图将变得越来越混乱,
Affine,,,,アフィン
info: Returns various types of metadata about the content.,,,,info: コンテンツにvする々なNのメタデ`タを返します。
DELETE cannot be undone. The files will be deleted completely.,删除无法撤回，文件将被彻底删除,,,「削除」操作は取り消せません。ファイルは完全に削除されます。
(A3) Primary,,(A3) 主要,(A3) 主要,
Layer2 mask blur,,,,Layer2 マスクのぼかし
Total Number of Class/Reg Images,用于分类/规范化的图像总数,用于分类/规范化的图像总数,用于分类/规范化的图像总数,
eta (noise multiplier) for DDIM,DDIM 的 eta (噪声乘数) ,DDIM 的 eta (噪声乘数) ,DDIM 的 eta (噪声乘数) ,DDIMで用いるeta (noise multiplier)
Save crops to:,储存裁剪好的成品到：,储存裁剪好的成品到：,储存裁剪好的成品到：,作成した画像の保存先：
Show sample per step,,,,ステップごとにサンプルを表示する
daspartho/prompt-extend,,,,daspartho/prompt-extend
cfg_scale,,,,cfgスケ`ル
translate,翻译,,,翻U
Positive Filter,正面筛选条件,,,正のフィルタ`
steps,采样迭代步数(Steps),采样迭代步数(Steps),采样迭代步数(Steps),ステップ数
"Mask alpha, must be used in conjunction with mask color ? sketch_alpha",,,,マスクアルファ。マスクカラ`と阌盲工氡匾があります。 ? sketch_alpha
Config file for Adapter models,自适应模型(Adapter models)的配置文件,自适应模型(Adapter models)的配置文件,自适应模型(Adapter models)的配置文件,Adapter モデルのO定ファイル
Clear inputs,,清除输入,清除输入,
Tweening frames schedule,,,,中gフレ`ムのスケジュ`ル
Control Model - 3,控制模型-3,,,
kebabcase,,,,ケバブケ`ス
override_settings,,,覆盖的设置,
"weights for alpha, base alpha,IN00,IN02,...IN11,M00,OUT00,...,OUT11",各层 α 权重,,,
Coherence:,,相干性:,相干性:,
Layer2 mask strength,,,,レイヤ`2のマスク不透明度
Generate all possible prompts up to a maximum of Batch count * Batch size),生成不超过（生成批次 * 每批数量）的所有可能的提示词,生成不超过（生成批次 * 每批数量）的所有可能的提示词,生成不超过（生成批次 * 每批数量）的所有可能的提示词,
realesrgan-x4plus,,,,realesrgan-x4plus
Replace Class with Subject in Caption,将描述文本中的类(Class)替换成主体(Subject),将描述文本中的类(Class)替换成主体(Subject),将描述文本中的类(Class)替换成主体(Subject),キャプションのクラスをサブジェクトに置きQえる
Custom Model Name,,,,カスタムモデル名
Destination seed(s) (Comma separated),目标种子 (逗号分割),目标种子 (逗号分割),目标种子 (逗号分割),宛先シ`ド(カンマ区切り)
Generate a .ckpt file when saving during training.,,,,トレ`ニング中に保存するときに .ckpt ファイルを生成します。
wd-v1-4-swinv2-tagger-v2,,,,wd-v1-4-swinv2-tagger-v2
Resize mode,缩放模式,缩放模式,缩放模式,サイズ涓の方式
wd-v1-4-vit-tagger-v2,,,,wd-v1-4-vit-tagger-v2
Step multiplier per cycle,,,,サイクルごとのステップ\数
DAAM,,,,DAAM
you can get the artists or art styles list from here,,,,ここからア`ティストやア`トスタイルのリストを手に入れることができます
segmentation,语义分割（ADE20k 协议）,ADE20k 语义分割（Semantic segmentation）,ADE20k 语义分割（Semantic segmentation）,segmentation
Save copy of large images as JPG,,,图片过大时保存JPG副本,
https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git,,,,https://github.com/DominikDoom/a1111-sd-webui-tagcomplete.git
##,,,,##
Video FPS,视频 FPS,视频 FPS,视频 FPS,
Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage.,为 DataLoader 开启 pin_memory（增加内存占用换取训练加速）,打开 DataLoader 的 pin_memeory (稍微加快训练速度，但会增加内存消耗),打开 DataLoader 的 pin_memeory (稍微加快训练速度，但会增加内存消耗),DataLoaderのpin_memoryをONにします。トレ`ニングが若干速くなりますが、メモリ使用量が加する可能性があります。
Live preview display period,,,实时预览的间隔,
Save Checkpoint to Subdirectory,,,,Checkpointをサブディレクトリに保存
Extra networks tab order,附加网络标签的顺序,附加网络标签的顺序,附加网络标签的顺序,追加ネットワ`クのタブ序
"mklink /j ""<path_to_pykrita>\krita_diff"" ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff""\nmklink ""<path_to_pykrita>\krita_diff.desktop"" ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff.desktop""",,,,"mklink /j ""<path_to_pykrita>\krita_diff"" ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff""\nmklink ""<path_to_pykrita>\krita_diff.desktop"" ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff.desktop"""
Interrogate\nCLIP,CLIP 提示词反推,　　CLIP　　\n反推提示词,　　CLIP　　\n反推提示词,CLIPによる解析
Jinja2 templates is an experimental feature for advanced template generation. It is not recommended for general use unless you are comfortable with writing scripts.,Jinja2 模板是一个用于高级模板生成的实验特性。如果不熟悉编写脚本，正常使用时不推荐启用,Jinja2 模板是一个用于高级模板生成的实验特性。如果不熟悉编写脚本，正常使用时不推荐启用,Jinja2 模板是一个用于高级模板生成的实验特性。如果不熟悉编写脚本，正常使用时不推荐启用,Jinja2テンプレ`トは、高度なテンプレ`ト生成のためのgY的なC能です。スクリプトをくことにTれていない限り、一般的な使用はお幛幛筏蓼护蟆
"New value, with advanced expression support ? _to",,,,高度な式サポ`トを持つ新しい ? _to
Hypernetwork strengths,超网络强度,超网络强度,超网络强度,
No interpolation,无插值,无插值,无插值,agなし
Import Background Images,导入 背景图像,导入 背景图像,导入 背景图像,
af,,,,af
Use common negative prompt,使用公共负面提示词,,,共通のネガティブプロンプトを使用
ControlNet v1.1.231,扩散控制网络(ControlNet),,,
"To activate inspiration function, you need get ""inspiration"" images first.",,,,インスピレ`ションC能を有郡摔工毪摔稀まず「インスピレ`ション」画像を取得する必要があります。
Translation file uses old 3-column translation format instead of the new 2-column one,使用旧的三列翻译文件格式取代新的两列格式,使用旧的三列翻译文件格式取代新的两列格式,使用旧的三列翻译文件格式取代新的两列格式,古い３カラムフォ`マットの翻Uファイルの代わりに新しい２カラムフォ`マットのを使用する
will then become available.,文件放在相应目录就能被识别,文件放在相应目录就能被识别,文件放在相应目录就能被识别,こうすることで利用可能になります。
Resume timestring,,,,rg文字列から再_
Show Button On Thumb Mode,在 缩略预览图 中显示额外按钮,,悬停时显示本插件按钮,
? Setting,? 侧边栏设置,,,
Model Scale,,,,モデルの大きさ
Directory for saving init images when using img2img,保存 图生图 原始输入图像的目录,,图生图时初始图片保存路径,
txt2img_width,宽度,,,
ex B.,例子B：,,,例えば、B.
You must enter text prompts to enable groundingdino. Otherwise this extension will fall back to point prompts only.,必须在此处输入提示词(prompt)才能激活 GroundingDINO 算法，否则将仅使用提示点(point prompt),,你需要输入提示词，否则GroundingDINO将不生效,
Embedding Merge,,,,Embedding Merge
Stop,停止,,,停止
sdweb-merge-board,合并面板,合并面板,合并面板,
Show Ad,显示广告,显示广告,显示广告,
Step length multiplier every cycle,,,,サイクルごとのステップLの\数
spaceship-fareast,,,,宇宙船演算子(fareast)
Output Directory,,,,出力ディレクトリ
portrait-fineart,,,,肖像画-ファインア`ト
Marginbase,Marginbase,,,
Theme,Kitchen界面设置,主题,主题,
New defaults will apply after you restart the UI.,,,新的默认值会在你重启UI后生效,
Checkpoint name,Stable Diffusion 模型(ckpt) 名称,模型(ckpt)名,模型(ckpt)名,Checkpoint名
"how fast should the training go. Low values will take longer to train, high values may fail to converge (not generate accurate results) and/or may break the embedding (This has happened if you see Loss: nan in the training info textbox. If this happens, you need to manually restore your embedding from an older not-broken backup).\n\nYou can set a single numeric value, or multiple learning rates using the syntax:\n\n   rate_1:max_steps_1, rate_2:max_steps_2, ...\n\nEG:   0.005:100, 1e-3:1000, 1e-5\n\nWill train with rate of 0.005 for first 100 steps, then 1e-3 until 1000 steps, then 1e-5 for all remaining steps.","训练应该多快。低值将需要更长的时间来训练，高值可能无法收敛（无法产生准确的结果）以及/也许可能会破坏 Embedding（如果你在训练信息文本框中看到 Loss: nan 就会发生这种情况。如果发生这种情况，你需要从较旧的未损坏的备份手动恢复 Embedding）\n\n你可以使用以下语法设置单个数值或多个学习率：\n\n   率1:步限1, 率2:步限2, ...\n\n如：   0.005:100, 1e-3:1000, 1e-5\n\n即前 100 步将以 0.005 的速率训练，接着直到 1000 步为止以 1e-3 训练，然后剩余所有步以 1e-5 训练","训练应该多快。低值将需要更长的时间来训练，高值可能无法收敛（无法产生准确的结果）以及/也许可能会破坏 Embedding（如果你在训练信息文本框中看到 Loss: nan 就会发生这种情况。如果发生这种情况，你需要从较旧的未损坏的备份手动恢复 Embedding）\n\n你可以使用以下语法设置单个数值或多个学习率：\n\n   率1:步限1, 率2:步限2, ...\n\n如：   0.005:100, 1e-3:1000, 1e-5\n\n即前 100 步将以 0.005 的速率训练，接着直到 1000 步为止以 1e-3 训练，然后剩余所有步以 1e-5 训练","训练应该多快。低值将需要更长的时间来训练，高值可能无法收敛（无法产生准确的结果）以及/也许可能会破坏 Embedding（如果你在训练信息文本框中看到 Loss: nan 就会发生这种情况。如果发生这种情况，你需要从较旧的未损坏的备份手动恢复 Embedding）\n\n你可以使用以下语法设置单个数值或多个学习率：\n\n   率1:步限1, 率2:步限2, ...\n\n如：   0.005:100, 1e-3:1000, 1e-5\n\n即前 100 步将以 0.005 的速率训练，接着直到 1000 步为止以 1e-3 训练，然后剩余所有步以 1e-5 训练",
ControlNet v1.1.232,扩散控制网络(ControlNet),,,
length,,,,Lさ
VRAM usage polls per second during generation.,,,每秒轮询显存使用率的次数,
Show output folder video,,,,Show output folder video
Use raw CLIP token to calculate token count (without emphasis or embeddings),,,,未加工のCLIPト`クンを使用してト`クン数を算出する ({やembeddingの区eなし)
zh-CN,,,,zh-CN
Resize Mode,画面缩放模式,画面缩放模式,画面缩放模式,リサイズモ`ド
GroundingDINO Box Threshold,GroundingDINO 选区阈值,,GroundingDINO包围盒阈值,
Cache LDSR model in memory,把LDSR模型缓存在内存中,把LDSR模型缓存在内存中,把LDSR模型缓存在内存中,LDSRモデルをメモリにキャッシュ
Move ControlNet images to CPU (if applicable),条件允许时，将 扩散控制网络(ControlNet) 移至 内存,如果可以的话将ControlNet图像用CPU处理,尝试用CPU计算ControlNet,ControlNetの画像をCPUに移 (可能な龊)
ControlNet v1.1.226,扩散控制网络(ControlNet),,,
ControlNet v1.1.142,扩散控制网络(ControlNet),,,
info,,,,info
Dropdown,下拉列表,下拉列表,下拉列表,ドロップダウン
Gradio theme (requires restart),Gradio 的主题配色（使用 Kitchen Theme 或其他界面美化插件时请保持默认，需要保存设置并重启）,,Gradio主题（需要重启）,
resize_mode,,,,サイズ涓モ`ド
range,,,,
Colorfillsecondary,Colorfillsecondary,,,
epsilon,,,,エプシロン
Guess Mode,"无引导模式（需在设置中启用""基于CFG的引导""）","无提示词(prompt)模式（需在设置中启用""基于CFG的引导""）","无提示词(prompt)模式（需在设置中启用""基于CFG的引导""）",推yモ`ド
Save a copy of image before doing face restoration.,在进行面部修复之前保存图像副本,在进行面部修复之前保存图像副本,在进行面部修复之前保存图像副本,の修亭蛐肖η挨嗽画像のコピ`を保存しておく。
Feather,,羽化,羽化,
Number of clusters:,簇数：,簇数：,簇数：,クラスタ`の数:
Mimic Scale Scheduler,模拟提示词相关性(Mimic CFG Scale) 调度函数（一般设为“半区间余弦递增”）,,,
Perspective Flip,,,,透投影反
ControlNet-1,控制网络-1,,,
Config Presets,预设配置,预设配置,预设配置,
fixed,,固定,固定,修正
Fall-off exponent (lower=higher detail),衰减指数(越小细节越好),衰减指数(越小细节越好),衰减指数(越小细节越好),フォ`ルオフ指数(低いほどかい)
- Joints and Limbs,--关节和肢体--,--关节和肢体--,--关节和肢体--,
Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.,一个用于生成不同随机种子之间的渐变过程的小脚本,一个用于生成不同随机种子之间的渐变过程的小脚本,一个用于生成不同随机种子之间的渐变过程的小脚本,Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.
ControlNet v1.1.195,扩散控制网络(ControlNet),,,
Reload the last SD checkpoint back into VRAM,将最后一次使用的 Stable Diffusion 模型(ckpt) 重新载入,,将最近一个模型（checkpoint）重新载入显存（无需重启）,最後のSD checkpointをVRAMに再iみzみ
Batch name,,,,バッチ名
casing,,,,ケ`シング
lms,lms,,,
"In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.",,,,"In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible."
Architecture,结构,,,
Loss for cond match (grad mode),匹配文字调节(cond)损失 (梯度模式),匹配文字调节(cond)损失 (梯度模式),匹配文字调节(cond)损失 (梯度模式),
Positions,"分区位置（列:行，""0-4:3-5""可表示跨多个区块）",位置,位置,位置
Wildcards,通配符,通配符,通配符,ワイルドカ`ド
tp__reverso,,,,tp__reverso
IN06,,输入层06,输入层06,
AdamW beta2 parameter,,,,AdamW beta2 パラメ`タ
"I love {{ choice('red', 'blue', 'green') }} roses","I love {{ choice('red', 'blue', 'green') }} roses",,,"I love {{ choice('red', 'blue', 'green') }} roses"
Maximum steps fraction to mirror at,镜像干涉止步于总迭代步数的,镜像干涉止步于总迭代步数的,镜像干涉止步于总迭代步数的,R映化g行ステップの比率
BLIP2 Captioner,,,,BLIP-2でキャプション付け
Noise schedule,,,,ノイズスケジュ`ル
"Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.",智能预处理，包括自动主体识别、描述文本主体切换和放大/面部恢复,智能预处理，包括自动主体识别、描述文本主体切换和放大/面部恢复,智能预处理，包括自动主体识别、描述文本主体切换和放大/面部恢复,自颖恍刺遄Re、キャプション被写体入れ替え、アップスケ`ル/驮などのスマ`トプリプロセスをgF。
u2netp,,,,u2netp
Display name for this model,此模型显示的名称,此模型显示的名称,此模型显示的名称,表示名
CPU,,,,CPU
Include ranks of model tags matches in results.,,,在结果中包含模型标签匹配的排名,
Enable Autopruning,启用自动修剪,,,
portrait-anime,,,,ポ`トレイトのアニメ
Each Tags,每一个 Tag,,,それぞれのタグ
house-ukioe,,,,家-浮世}
Original Image,原始图像,,,
(noise multiplier; applies to Euler a and other samplers that have a in them),,,（噪音的倍增幅度，影响名字里有a和SDE的采样器）,
Enable Region 6,启用此区域,,启用区域 6,
Temporal Coherence Tools,,,,rg的な一性ツ`ル
https://github.com/yownas/shift-attention.git,,,,https://github.com/yownas/shift-attention.git
Create a grid where images will have different parameters. Use inputs below to specify which parameters will be shared by columns and rows,创建一个网格，图像将有不同的参数。使用下面的输入来指定哪些参数将由列和行共享,创建一个网格，图像将有不同的参数。使用下面的输入来指定哪些参数将由列和行共享,创建一个网格，图像将有不同的参数。使用下面的输入来指定哪些参数将由列和行共享,
Crop and resize,裁剪,裁剪,裁剪,k横比をS持(切り取り)
Text2Prompt,,,,Text2Prompt
tp_iciba,,,,tp_iciba
Image strength schedule,,,,画像度スケジュ`ル
Swap Batch,,,,バッチの入れ替え
Sort by alphabetical order,按首字母排序 (不推荐勾选),按首字母排序 (不推荐勾选),按首字母排序 (不推荐勾选),アルファベットでソ`ト
Brazillian portuguese localization,,,,ブラジル?ポルトガルZ翻U
Absolute,,,,~
Optimizations,,,性能优化,
Lora,LoRA,,,LoRA
Reserve XY Plot,预约XY队列,,,
Dest Path,,,,あて先のパス
UNet Weight 5,UNet 权重 5,UNet 权重 5,UNet 权重 5,UNetの重み 5
Upscaler 1,放大算法 1 (Upscaler 1),放大算法 1 (Upscaler 1),放大算法 1 (Upscaler 1),アップスケ`ラ` 1
Infer styles from prompts of pasted infotext,,,从粘贴的信息文本的提示中推断出样式,
Toolkit,模型工具包,,,
Scan model,扫描模型（通过 SHA256哈希值 为所有模型匹配C站信息，不会重复扫描，不会覆盖原有预览图）,扫描模型（通过 SHA256哈希值 为所有模型匹配C站信息，不会重复扫描，不会覆盖原有预览图）,扫描模型（通过 SHA256哈希值 为所有模型匹配C站信息，不会重复扫描，不会覆盖原有预览图）,
Constant,定常值(Constant),,,
A range can be provided:,项数可以有范围,项数可以有范围,项数可以有范围,プロンプトをxkする数に幅をもたせられます。
Maximum results,单页最大结果数量,单页最大结果数量,单页最大结果数量,表示されるタグの数
Precision,精度,精度,精度,
openpose-editor,OpenPose 编辑器插件,OpenPose 编辑器插件,OpenPose 编辑器插件,openpose-editor
Perlin octaves,,,,パ`リンノイズのA{
ControlNet v1.1.228,扩散控制网络(ControlNet),,,
Save mask previews,保存蒙版预览,保存蒙版预览,保存蒙版预览,
(S5) Inter-Method,,(S5) 插值方法,(S5) 插值方法,
translate negative prompt.,,,,ネガティブプロンプトを翻U
Use different seed for each picture,为每张图片使用不同随机种子,为每张图片使用不同随机种子,为每张图片使用不同随机种子,画像ごとになるシ`ドを使用
stable-diffusion-webui-aesthetic-gradients,美术风格梯度,美术风格梯度,美术风格梯度,stable-diffusion-webui-aesthetic-gradients
Region 2,区域 2,区域 2,区域 2,
cafe-aesthetic,,,,cafe-aesthetic
Minimum CFG scale ? cfg_scale_min,,,,最小CFGスケ`ル ? cfg_scale_min
"CodeFormer weight (0 = maximum effect, 1 = minimum effect)",CodeFormer 权重(为 0 时效果最大，为 1 时效果最小),CodeFormer 权重(为 0 时效果最大，为 1 时效果最小),CodeFormer 权重(为 0 时效果最大，为 1 时效果最小),CodeFormerの重み (注:0で最大、1で最小)
Controls the maximum length in tokens of the generated prompt.,按 token 数控制提示词生成的最大长度,按 token 数控制提示词生成的最大长度,按 token 数控制提示词生成的最大长度,生成されたプロンプトのト`クンの最大Lをコントロ`ルします。
Sysinfo,,,系统信息,
Minimum number of pages per load,每次加载的最小页数,每次加载的最小页数,每次加载的最小页数,ロ`ドあたりの最小ペ`ジ数
Output directory for txt2img images,文生图的输出目录,文生图的输出目录,文生图的输出目录,txt2img画像の出力ディレクトリ
Region 8,区域 8,区域 8,区域 8,
replace,取代,取代,取代,置Q
Pick frames every n-th,每 n 帧挑选 1 帧,每 n 帧挑选 1 帧,每 n 帧挑选 1 帧,
Use init,,,,初期を使用する
house,,,,家
Intermediate files path,,中间步骤文件路径,中间步骤文件路径,
comma,逗号,逗号,逗号,カンマ
A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.,,,,フレ`ムをダンプしてビデオファイルをBする基本的なimg2imgスクリプト。d味深いズ`ムイン?ワ`ピングの踊を作成するのにmしています。これは、img2imgのタスクを自踊するための多C能なツ`ルセットであることを意恧筏皮い蓼埂
A integrated translator for translating prompts to English using Deepl or Baidu.,,,,DeeplやBaiduを使ってプロンプトを英Zに翻Uするためのy合翻UCです。
Sample Steps,样本迭代步数,样本迭代步数,样本迭代步数,サンプルステップ
Bucket Steps,,,,バケットステップ
C:\directory\of\datasets,,,,C:\directory\of\datasets
Gradient Clipping Options,,,,グラデ`ションクリッピングオプション
Use Custom Threshold (Booru),自定义 DeepBooru算法 置信阈值,,,カスタムしきいを使用 (Booru)
Subject Name to replace class with in captions,,,,キャプションでクラスを置きQえるサブジェクト名
Try freeing CLIP model from memory? ? free_memory,,,,メモリからCLIPモデルを解放してみて下さい? free_memory
ControlNet v1.1.188,扩散控制网络(ControlNet),,,
Embedding,Embedding,,,Embedding
Results,结果,,,Y果
Export,导出,,,
Show Noise Scheduler Options(for both),,,,Noise Scheduler オプションを表示(for both)
Output path,输出路径,,拆分输出的路径,
Use dropdown for sampler selection instead of radio group,使用下拉菜单取代单选列表,使用下拉菜单取代单选列表,使用下拉菜单取代单选列表,サンプラ`のxkでラジオボタンの代わりにドロップダウンを利用する
Restore low quality faces using GFPGAN neural network,使用 GFPGAN 神经网络修复低质量面部,使用 GFPGAN 神经网络修复低质量面部,使用 GFPGAN 神经网络修复低质量面部,GFPGANニュ`ラルネットワ`クを使用して、低品|の画像を修亭筏蓼埂
hires_resize_y,,,,高解像度 サイズ涓Y
github,,,,github
ui text,UI界面上的文本,,,UI文字列
ControlNet v1.1.255,扩散控制网络(ControlNet),,,
Extension State,扩展 版本,,扩展状态,
Weight Decay,,,,荷重p衰
Elemental Merge,元素合并,,,
/extections/stable-diffusion-webui-inspiration,,,,/extections/stable-diffusion-webui-inspiration
Folder,,,,フォルダ`
Path to directory with classification images,分类图像的目录路径,分类图像的目录路径,分类图像的目录路径,
Upscale,图像放大,图像放大,图像放大,アップスケ`ル
You can enhance semantic segmentation for control_v11p_sd15_seg from lllyasviel. Non-semantic segmentation for,可以增强 control_v11p_sd15_seg 模型的效果，非语义分割工具,,通过使用lllyasviel的control_v11p_sd15_seg模型可以增强语义分割的效果，非语义分割效果增强将在,
Multi Model Merge,,多重模型合并,多重模型合并,
ex A.,例子A：,,,例えば、A.
Frames to Video,,,,フレ`ムからビデオへ
"Supports boolean operations: (! - negation, & - and, | - or, ^ - xor, \ - difference, () - nested operations)",,,,"ブ`ル演算をサポ`トしています： (! - negation, & - and, | - or ^ - xor, \ - difference, () - ネストされた演算)"
Out Res,,,,アウト
Search Tags,搜索 Tag,,,タグを仕鳏工
Process Text,,,,プロセス テキスト
Variation strength,差异强度,差异强度,差异强度,バリエ`ションの度
autocorrect,,,,自有拚
Replace underscores with spaces on insertion,将下划线替换为空格,将下划线替换为空格,将下划线替换为空格,タグ啡rにアンダ`スコアをスペ`スに置きQえる
Conditional check ? str,,,,状Bのチェック ? str
Enable Randomize extension,启用随机化扩展,启用随机化扩展,启用随机化扩展,
Images filename pattern,图像文件名格式,图像文件名格式,图像文件名格式,ファイル名のパタ`ン
"This won't break your system, if you find you can't update, try `git checkout webui.py` ~~`git fetch --all` `git reset --hard origin/master`~~",操作不会破坏系统，如发现不能更新，请尝试 'git checkout webui.py' ~~'git fetch --all' 'git reset --hard origin/master'~~,操作不会破坏系统，如发现不能更新，请尝试 'git checkout webui.py' ~~'git fetch --all' 'git reset --hard origin/master'~~,操作不会破坏系统，如发现不能更新，请尝试 'git checkout webui.py' ~~'git fetch --all' 'git reset --hard origin/master'~~,
New text file will be created if you are using filename as captions.,如果使用文件名作为注释，将创建新的文本文件,,,ファイル名をキャプションとして使用している龊稀⑿陇筏ぅ匹ストファイルが作成されます。
Area 6 Weight,蒙版 6 的权重(Weight),,,
OUT_B_04,,模型B 输出层04,模型B 输出层04,
Denoising,重绘幅度,重绘幅度,重绘幅度,ノイズ除去
Model description/readme/notes/instructions,模型的描述信息,模型的描述信息,模型的描述信息,モデルのh明/README/メモ/h明
Enable emphasis,,,启用强调符,
Standard Deviation for Normal weight initialization,,,,手亓砍跗诨の势位
Hybrid Settings,,,,ハイブリッドO定
Hold key to pan the canvas,,,按住来平移画布,
Subject Name,主体(Subject)名,主体(Subject)名,主体(Subject)名,件名
ControlNet v1.1.207,扩散控制网络(ControlNet),,,
Classification Dataset Directory,分类(Classification)数据集目录,分类(Classification)数据集目录,分类(Classification)数据集目录,分デ`タセットのディレクトリ
Batch Face Swap,,,,Batch Face Swap
"Prompt Placeholder, which can be used at the top of prompt input",,,,プロンプト入力の先^で使用できるプロンプトプレ`スホルダ`
template,提示词分段模板（每段内容请写入分隔词之前，最后一段无分隔词）,,,テンプレ`ト
mp4,mp4,,,
I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.,,,,I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.
"Weight decay for the Adam optimizer, duh.",Adam 优化器的权重衰减（废话）,Adam 优化器的权重衰减（废话）,Adam 优化器的权重衰减（废话）,
IN_A_11,,模型A 输入层11,模型A 输入层11,
Swap axes,交换XY轴,交换XY轴,交换XY轴,
Use,,,,使用
Batch Edit Captions,批量编辑图片注释,,,キャプションの一括集
Extra args,附加参数,,,そのほかの引数
Mask blur,蒙版模糊,蒙版模糊,蒙版模糊,マスクのぼかし
Mask source,,蒙版来源,蒙版来源,
gelu,gelu,,,gelu
Hug-the-middle,,,,Hug-the-middle
Merge models and load it for generation,合并，并加载合并后的模型用于文生图,,,
txt2img_restore_faces,是否启用面部修复,,,
Region Prompt Control,区域性附加提示词（仅在分块扩散生效时有用，无法替代画面分区）,分区控制,分区控制,
"The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.",,,,新しいアルゴリズムは、各フレ`ムのパラメ`タをxkするために、DFIのS容欷诉m辘筏蓼埂Ｖ匾：アルゴリズムは、デフリックとコラプションのバランスを保つように最m化されており、低ノイズ化でStableDiffusionを使用すると、得られた安定性をS持しながら失われたディテ`ルを再Bすることが容易になる。
normal_midas,法线贴图（normalbae 模型，MiDaS 算法）,,法线贴图（Normal Map，MiDaS 算法）,
gu,,,,gu
"Frame Interpolation to smooth out, slow-mo (or both) any video.",,,,フレ`ムagを使用して、ビデオを滑らかにしたり、スロ`モ`ションにしたりします。
Maximum image size,,,最大图片大小,
Power,,,,パワ`
Coherence,,,,一性
ControlNet v1.1.132,扩散控制网络(ControlNet),,,
tp_itranslate,,,,tp_itranslate
Check progress (first),(首次)查看进度,(首次)查看进度,(首次)查看进度,
Target dataset num: 0,,,,象デ`タセット番号: 0
ControlNet v1.1.147,扩散控制网络(ControlNet),,,
Restore Checkpoint after process,完成后恢复开始前选择的 Stable Diffusion 模型(ckpt),完成后恢复开始前选择的模型(ckpt),完成后恢复开始前选择的模型(ckpt),
Horizontal Mirroring,水平镜像,水平镜像,水平镜像,左右R映化
Saving images/grids,图像保存,保存图像/宫格图,图像保存,画像/グリッド画像の保存
*Stitch frames to video*,,,,*フレ`ムをビデオにげる*
house-c,,,,家-C
Download image,下载图片,下载图片,下载图片,
Iterations,迭代,迭代,迭代,Rり返し
"Prompts are stored in JSON format. If you've got an error, check it in a",,,,プロンプトは JSON 形式で保存されます。エラ`がk生した龊悉稀⒁韵陇谴_Jしてください。
u2net_human_seg,,,,u2net 人物区分
"List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others, All, Maintenance. Custom folders are also supported by specifying their path.",,,"显示的标签（以逗号分隔）支持的选项有：txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others, All, Maintenance.也支持自定义的文件夹路径。",
tp_reverso,,,,tp_reverso
faster,,,,より速い
Eta for DDIM,,,DDIM的Eta,
Action,操作,操作,操作,g行
Encoder Tile Size,编码器图块尺寸(Encoder Tile Size),编码器图块尺寸(Encoder Tile Size),编码器图块尺寸(Encoder Tile Size),エンコ`ダタイルのサイズ
Farneback,,,,Farneback
Saved Configs,已保存的设置,,要保存的设置,
Extension version,,,,C能のバ`ジョン
Hires sampling method,,,高清修复采样方法,
"Incremental/decremental percentage (-50%, +50%)",,,,p率（-50%、+50%）
N2,,,,N2
nai,,,,nai
Paddingbase,Paddingbase,,,
tile division BG Removers,分块处理设置,,,
(requires restart),,,需要重启,
tp__mglip,,,,tp__mglip
OpenPose Editor,OpenPose 编辑器,OpenPose 编辑器,OpenPose 编辑器,OpenPose Editor
Scan,开始扫描,Scan,扫描,
PBRemTools,PBRem背景去除,,,PBRemTools
Prespective flip ― Low VRAM pseudo-3D mode:,,透视翻转 ― 低显存(VRAM)伪3D模式:,透视翻转 ― 低显存(VRAM)伪3D模式:,
rating,,,,u
AddNet UNet Weight 3,[附加网络] UNet 权重 3,[可选附加网络] UNet 权重 3,[可选附加网络] UNet 权重 3,UNetの重み 3(AddNet)
Mirror webcam,,,镜像摄像头画面,
"""Hug the middle"" during interpolation","在插值的途中 ""主动去找中间点""","在插值的途中 ""主动去找中间点""","在插值的途中 ""主动去找中间点""",
contrast,,,,コントラスト
Artists to study,艺术家图库,艺术家图库,艺术家图库,Artists to study
Y panning,沿 Y 轴滚动,沿 Y 轴滚动,沿 Y 轴滚动,yS方向へずらす
Add dot prompt or enable GroundingDINO with text prompts to preview segmentation,预览切分结果，请先添加提示点或启用 GroundingDINO 后配合文字提示,,,
Add hypernetwork to prompt,将 超网络(Hypernetwork) 添加到提示词,将超网络(Hypernetwork)添加到提示词,将超网络(Hypernetwork)添加到提示词,プロンプトに Hypernetwork を追加
Insert after,在后面插入,在后面插入,在后面插入,後ろに啡
Maximum ranking,,,最大评级,
Network module,附加网络模块,附加网络模式,附加网络模式,ネットワ`クモジュ`ル
Mixed Precision,混合精度,混合精度,混合精度,混合された精度
Token Merging - Use random perturbations,使用随机扰动,,,
Softmax,,,,ソフトマックス
Image layout status,执行状态,,拆分状态,
Use recursive with glob pattern,全局递归查找,全局递归查找,全局递归查找,Globパタ`ンで再⒌膜耸褂盲工
Show advanced learn rate scheduler options,,,,高度なlearn rateスケジュ`ラオプションを表示
"Original Text = ""A, B, C""?Common Tags = ""(nothing)""?Edit Tags = ""X, Y""","　　原始文本：“A, B, C”，共有 Tag：“<无>”，编辑为：“X, Y”",,,"元のテキスト= ""A、B、C"" 共通のタグ= ""(なし)"" タグを集= ""X、Y"""
Commit,版本哈希值,,提交hash,
override_these_with_webui,,用 webui 覆写这些,用 webui 覆写这些,
Bilingual Localization,双语本地化,双语对照翻译,双语对照翻译,Bilingual Localization
HakuImg,,,,HakuImg
X type,X轴类型,X轴类型,X轴类型,XSのN
Default value if the variable doesn't exist ? _default,,,,涫が存在しない龊悉违钎榨━毳 ? _default
Civitai Helper's extension tab,C站助手插件选项卡,C站助手插件选项卡,C站助手插件选项卡,
Use an empty output directory to save pictures normally instead of writing to the output directory.,输出图像到一个空目录，而非设置里指定的输出目录,输出图像到一个空目录，而非设置里指定的输出目录,输出图像到一个空目录，而非设置里指定的输出目录,"""出力ディレクトリ""を空冥摔工毪取⑼ǔＭà辘嘶像が保存されます。"
Done,,,完成,
(O6) Output ckpt Name,,(O6) ckpt 输出名,(O6) ckpt 输出名,
Prompts from file or textbox,从文本框或文件载入提示词,从文本框或文件载入提示词,从文本框或文件载入提示词,ファイルまたはテキストボックスからプロンプトを入力
hmn,,,,hmn
Directory path,目标路径,目标路径,目标路径,ディレクトリ パス
Images path,图像输入路径,,,
"Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.",,,,Riffusionモデルを使用して、gradioで音Sを生成します。元のag技gを再Fするには、プロンプトのトラベルエクステンション出力フレ`ムをRiffusionタブに入力してください。
"It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.",,,,1枚の画像に}数の}jな被写体を作成するのに役立つ、深度をJRするC能です。背景を生成し、次に}数の前景の被写体を生成し、深度解析後に背景をカットして背景にNり付け、最後にimg2imgできれいに仕上げます。
Download Max Size Preview,下载高清预览图,下载最大尺寸的预览图,下载最大尺寸的预览图,
https://github.com/Interpause/auto-sd-paint-ext.git,,,,https://github.com/Interpause/auto-sd-paint-ext.git
Memory,内存及显存用量,内存及显存用量,内存及显存用量,
ControlNet v1.1.182,扩散控制网络(ControlNet),,,
Low fps,低帧率模式,低帧率模式,低帧率模式,
String to append to the variable ? _after,,,,涫の後に追加する文字列 ? _after
Extract from frame,,,,フレ`ムから抽出
Dump U-Net,,,,Dump U-Net
Add alternatives to the default tunneling methods. (including cloudflared),,,,デフォルトのトンネリングメソッドに代わるものを追加します(Cloudflaredを含む)。
Keep the Ratio,保持输入图像宽高比,,,
Select which Real-ESRGAN models to show in the web UI.,,,选择要在 Web UI 中显示的 Real-ESRGAN 系列放大算法（需要保存设置并重启）,
Hypernetworks List,可选的超网络模型列表,可选的超网络列表,可选的超网络列表,
IN_A_05,,模型A 输入层05,模型A 输入层05,
Do not save heatmap images,,,,ヒ`トマップ画像を保存しない
Positive,正面提示词,,,
"Training information, dateset, etc",,,,トレ`ニング情蟆⑷崭顶互氓趣胜
Search by translation,使用译名搜索,使用译名搜索,使用译名搜索,U文で仕
IN_B_02,,模型B 输入层02,模型B 输入层02,
Create Beta hypernetwork,,,,Beta hypernetworkを作成
inpaint,局部重绘,局部重绘,局部重绘,Inpaint
Smoothing radius in pixels ? smoothing,,,,半径をピクセルで平滑化→ 平滑化
linear,线性(linear),线性(linear),线性(linear),linear
PBRemTools(Precise background remover tools) is a collection of tools to crop backgrounds from a single picture with high accuracy.,,,,PBRemTools(正_な背景除去ツ`ル)は、1枚の写真から背景を高精度に切りiくためのツ`ル集です。
Directory name pattern,目录名称格式,目录名称格式,目录名称格式,ディレクトリ名のパタ`ン
Examples,示例,示例,示例,例
tp__utibet,,,,tp__utibet
IN_B_04,,模型B 输入层04,模型B 输入层04,
it,,,,it
Deforum,Deforum,,,Deforum
Troubleshooting,,,,トラブルシュ`ティング
Cond.fix: Full,修复时调节：完全,修复时调节：完全,修复时调节：完全,Cond.fix: フル
deterministic,,多次平均,多次平均,Q定的
Match input size (size is ignored when using boost),,,,一致する入力サイズ(ブ`ストを使用する龊悉膝单ぅ氦oされます)
Add model hash to generation information,将模型的哈希值添加到生成信息（建议开启）,将模型的哈希值添加到生成信息（建议开启）,将模型的哈希值添加到生成信息（建议开启）,モデルのハッシュを生成情螭俗芳
ControlNet v1.1.236,扩散控制网络(ControlNet),,,
URL,网址,网址,网址,URL
Accumulation steps,,累加步数,累加步数,累eバッチ回数
"When this box is *checked* latents will not be cached. When latents are not cached, you will save a bit of VRAM, but train slightly slower",当此框被*选中*时，将不会缓存潜空间参数(latents)。当潜空间参数(latents)没有被缓存时，你会节省一点显存(VRAM)，但训练速度会稍微慢一些,当此框被*选中*时，将不会缓存潜变量(latents)。当潜变量(latents)没有被缓存时，你会节省一点显存(VRAM)，但训练速度会稍微慢一些,当此框被*选中*时，将不会缓存潜变量(latents)。当潜变量(latents)没有被缓存时，你会节省一点显存(VRAM)，但训练速度会稍微慢一些,
When searched,,,当被搜索时,
Euler,Euler,,,Euler
Comma separated list,以逗号分割的列表,以逗号分割的列表,以逗号分割的列表,
Send to txt2img,>> 文生图,>> 文生图,>>文生图,txt2imgに送
8 units,,,启用了8个单元,
Camera Parameters,视角参数,,,
Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.,为随机或组合式提示词的生成实现了一种表达性模板语言，并支持深层目录结构中的通配符,为随机或组合式提示词的生成实现了一种表达性模板语言，并支持深层目录结构中的通配符,为随机或组合式提示词的生成实现了一种表达性模板语言，并支持深层目录结构中的通配符,表F力Nかなテンプレ`ト言Zを使って、ランダムまたはMみ合わせ式のプロンプト生成をgFし、}jなワイルドカ`ドのディレクトリ造にも辘扦るC能をg装しています。
Max generations (0 = all combinations - the batch count value is ignored),,,,最大生成数 (0 = すべてのMみ合わせ - このrバッチ数はoされます)
dog-special,,,,犬-特e
OUT_B_11,,模型B 输出层11,模型B 输出层11,
Cond.fix: High (recommended),修复时调节：高 (推荐),修复时调节：高 (推荐),修复时调节：高 (推荐),Cond.fix: 高 (推X)
"Early stopping parameter for CLIP model; 1 is stop at last layer as usual, 2 is stop at penultimate layer, etc.",,,,CLIPモデルの初期停止パラメ`タ、1は通常通り最後のレイヤ`で停止、2は最後から2つ目のレイヤ`で停止、など。
(,,,,(
difference threshold,差异阈值,,,
none,无,无,无,なし
Relative,,,,相
batch_name,,批次名称,批次名称,
"Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.",,,,キャラクタ`のプロンプトを含むyamlファイルをBし、生成を押すと、gZの属性やモディファイアによって素早くプレビュ`することができます。
Select prompt,选择生效的范围,选择提示词(prompt),选择提示词(prompt),プロンプトのNをxk
(M1) Multiplier,,(M1) 倍率,(M1) 倍率,
chance: Returns the content if the number you passed is greater than or equal to a random number between 1 and 100.,,,,chance: 1から100のランダムな数に大きさが等しいか、それ以上であれば、コンテンツを返します。
scribble_thr,涂鸦处理（scribble 模型，THR 算法）,,,
Shuffle Tags,,,,タグをシャッフル
HuggingFace Token,HuggingFace 令牌(Token),HuggingFace 令牌(Token),HuggingFace 令牌(Token),HuggingFace Token
general,大众内容/General（无性暗示）,大众级/普通内容（General）,大众级/普通内容（General）,
Save a copy of image before applying color correction to img2img results,在对图生图结果应用颜色校正之前保存图像副本,在对图生图结果应用颜色校正之前保存图像副本,在对图生图结果应用颜色校正之前保存图像副本,色a正をする前の画像も保存する
Don't show again,,,,次回から表示しない。
OUT_A_03,,模型A 输出层03,模型A 输出层03,
sd-webui-additional-networks,附加网络(AddNet),可选附加网络(LoRA插件),可选附加网络(LoRA插件),sd-webui-additional-networks
Open images output directory,打开图像输出目录,打开图像输出目录,打开图像输出目录,画像の出力ディレクトリを_く
quick-css,,,,quick-css
file2mask,,,,file2マスク
Destination directory,目标目录,目标目录,目标目录,保存先のディレクトリ
Override `Sampling Steps` to the same value as `Decode steps`?,覆写 `采样迭代步数` 为 `解码迭代步数`?,覆写 `采样迭代步数` 为 `解码迭代步数`?,覆写 `采样迭代步数` 为 `解码迭代步数`?,サンプリング数をデコ`ドステップ数と同じに上きする
Enable Subseed scheduling,,,,サブシ`ドのスケジュ`リングを有郡摔工
portrait-digipa-low-impact,,,,肖像画-digipaロ`インパクト
"Inpaint at full resolution padding, pixels",预留像素,预留像素,预留像素,
IN10,,输入层10,输入层10,
sort by,排序方式,排序方式,排序方式,ソ`ト
(B9) Secondary,,(B9) 第二,(B9) 第二,
Minimum aesthetic_score,美学评分下限,,,最小美的スコア
"Since there is a self-attention operation in VAE, it may change the distribution of features. This processing will superimpose the attention map of self-attention on the original Att-Map.",,,,VAEにはself-attention操作があるため、特栅畏植激浠する可能性があります。このI理では、self-attentionのアテンションマップを元のAtt-Mapに重ね合わせます。
for,,,,for
Show live previews of the created image,显示已生成图像的实时预览（不建议开启）,显示已生成图像的实时预览（不建议开启）,显示已生成图像的实时预览（不建议开启）,作成された画像のライブプレビュ`を表示する
Delete all wildcards,,,,すべてのワイルドカ`ドを削除する
softedge_pidisafe,边缘检测（softedge 模型，保守 PiDiNet 算法）,,软边缘检测（softedge，保守 PiDiNet 算法）,
Use cache,,,,キャッシュを使用
Active in third party textboxes [Dataset Tag Editor] (Requires restart),在第三方文本框[Dataset Tag Editor]中启用（需要保存设置并重启）,在第三方文本框[Dataset Tag Editor]中启用（需要保存设置并重启）,在第三方文本框[Dataset Tag Editor]中启用（需要保存设置并重启）,サ`ドパ`ティ`uのテキストボックスで有 (再起婴必要)
img2img: height of image editor,,,图生图界面图片编辑器的高度,
Number of frames,,,,フレ`ム数
Style Fuse,,,,Style Fuse
Trace each layers,,,,各レイヤ`をトレ`ス
Image Directory,,,,画像ディレクトリ
(M4) Multiplier,,(M4) 倍率,(M4) 倍率,
Linear,,,,Linear
The name of the model to create.,要创建的模型的名称,要创建的模型的名称,要创建的模型的名称,
BLEND (0=Off),,,,BLEND (0=Off)
Negative prompt (press Ctrl+Enter or Alt+Enter to generate),负面提示词（按 Ctrl+Enter 或 Alt+Enter 生成）\nNegative prompt,反向提示词（按 Ctrl+Enter 或 Alt+Enter 生成）\nNegative prompt,反向提示词（按 Ctrl+Enter 或 Alt+Enter 生成）\nNegative prompt,ネガティブプロンプト (Ctrl+Enter か Alt+Enter を押して生成)
CLIP-test,,,,CLIPテスト
Jinja2 templates are based on the Jinja2 template engine. For more information see the,Jinja2 模板基于 Jinja2 模板引擎，更多信息参见,Jinja2 模板基于 Jinja2 模板引擎，更多信息参见,Jinja2 模板基于 Jinja2 模板引擎，更多信息参见,Jinja2テンプレ`トは、Jinja2テンプレ`トエンジンに基づいています。についてはドキュメントを参照してください。
MultiDiffusion with Tiled VAE,,MultiDiffusion 与 分块 VAE,MultiDiffusion 与 分块 VAE,MultiDiffusion with Tiled VAE
Containing directory,目标模型目录,目标模型目录,目标模型目录,ディレクトリを含む
- Move canvas,,,- 移动画布,
Only use mid-control when inference,仅在推断(inference)时使用中间层控制(mid-control),仅在生成图片(推理 - inference)时使用中间层控制(mid-control),仅在生成图片(推理 - inference)时使用中间层控制(mid-control),推rに mid-control のみを使用する
Canvas Width,画布宽度（使用上传图片时请忽略此项）,画布宽度（使用上传图片时请忽略此项）,画布宽度（使用上传图片时请忽略此项）,キャンバスの幅
This takes server hours depending on your GPU type and how many pictures  you generate for each artist/style,,,,GPUのNと、ア`ティスト/スタイルごとに生成する画像の数に辘袱匹旦`バ`のrgが必要です
Output directory for images from extras tab,附加功能选项卡的输出目录,附加功能选项卡的输出目录,附加功能选项卡的输出目录,その他タブからの画像の出力ディレクトリ
Actions,其他操作,其他操作,其他操作,アクション
gamma,,,,ガンマ
Corruption Refresh (Lower = Faster),,,,Corruption Refresh (Lower = Faster)
Pick every n-th frame,每 n 帧挑选 1 帧,每 n 帧挑选 1 帧,每 n 帧挑选 1 帧,
Link to online results,在线结果查询,,,
cosine_with_restarts,含重启的余弦(cosine),含重启的余弦(cosine),含重启的余弦(cosine),cosine_with_restarts
Generate a .ckpt file when training is canceled.,,,,トレ`ニング中止rに.ckptファイルを生成する。
img2img history,图生图历史记录,图生图历史记录,图生图历史记录,
Model Path,模型路径,模型路径,模型路径,モデルのパス
Navigate image viewer with gamepad,,,支持使用手柄进行图片切换,
SD VAE,VAE 模型 (SD VAE),模型的 VAE (SD VAE),模型的 VAE (SD VAE),SD VAE
OUT_A_06,,模型A 输出层06,模型A 输出层06,
th_TH Localization,,,,th_TH Localization
DDPM,,,,DDPM
ControlNet v1.1.258,扩散控制网络(ControlNet),,,
Append Artist tags from CLIP,,,,CLIPからア`ティストタグを追加
AddNet Weight 2,[附加网络] 权重 2,[可选附加网络] 权重 2,[可选附加网络] 权重 2,重み 2(AddNet)
Compare paths (Separate travels from 1st seed to each destination),对比变迁轨迹 (从第一个种子分别变迁到每一个目标种子),对比变迁轨迹 (从第一个种子分别变迁到每一个目标种子),对比变迁轨迹 (从第一个种子分别变迁到每一个目标种子),パスを比^する(1つのシ`ドからそれぞれの宛先への分x)
Show/Hide Generation Info,显示/隐藏生成信息,,,
Provides a tab to display equirectangular images in interactive 3d-view.,,,,エクイレクタングラ`形式の画像をインタラクティブな3dビュ`で表示するタブを提供します。
(B8) Secondary,,(B8) 第二,(B8) 第二,
Send to Blend,,,,Blendタブに送
https://github.com/AbyszOne/Abysz-LAB-Ext,,,,https://github.com/AbyszOne/Abysz-LAB-Ext
Path to read videos from,读取视频的路径,读取视频的路径,读取视频的路径,踊iみzみ先のパス
Test prompt,,,,テスト プロンプト:
Deflickers,,,,Deflickers
Batch Process,批量处理,批量处理,批量处理,バッチI理
"Regular expression pattern for blocking terms out of the generated prompt. Applied case-insensitively. For instance, to block both ""purple"" and ""interdimensional"", you could use the pattern ""purple|interdimensional"".",,,,"生成されたプロンプトから用Zをブロックするための正表Fパタ`ン。大文字と小文字を区eしない。 例えば、""purple""と""interdimensional""のI方をブロックするには、""purple|interdimensional""というパタ`ンを使用します。"
Save original image with mask and bounding box,保存带有蒙版和选区边界的图像,,保存有蒙版和包围盒的原始图片,
Current ranking,,,当前评级,
UniPC lower order final,在最后几步使用低阶 UniPC,在 UniPC 采样最后步骤中使用低阶解算器 (推荐小于15个推理步骤时开启，可以稳定解算器的采样),在 UniPC 采样最后步骤中使用低阶解算器 (推荐小于15个推理步骤时开启，可以稳定解算器的采样),Unipc 最後の数ステップで、低次のソルバ`を使用する
File with inputs,含输入内容的文件,含输入内容的文件,含输入内容的文件,
Combine into one image.,,,,一つの画像にまとめます。
Animation settings,,动画设定,动画设定,
IN_A_00,,模型A 输入层00,模型A 输入层00,
Video Upscaling,,,,踊のアップスケ`リング
SKip NSFW Preview Images,跳过色情预览图,,跳过不和谐（NSFW）的预览图,
ControlNet v1.1.269,扩散控制网络(ControlNet),,,
Debug Buckets,,,,バケットのデバッグ
"Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.",,,,事前に学させたモデルで、美的／非美的の判定、5NのスタイルJRモ`ド、Waifu_Jができます。また、バッチI理のタブもあります。
ONNX opset version,,,ONNX操作集版本,
Model Type,模型类型,,模型类型,
Manage wildcards for Dynamic Prompts,,,,Dynamic Prompts 用のワイルドカ`ドを管理
Download Model,下载模型,模型下载,模型下载,
Tile width,,,,タイル幅
https://github.com/d8ahazard/sd_smartprocess.git,,,,https://github.com/d8ahazard/sd_smartprocess.git
to share your creations and suggestions.,,,,あなたの作や提案を共有するために
tp_utibet,,,,tp_utibet
How many image to create in a single batch,每批创建多少图像,每批创建多少图像,每批创建多少图像,
Weights Setting,权重设置,,,
Adds various custom themes,,,,々なカスタムテ`マを追加
Hires upscaler,高分辨率修复放大算法,高清修复放大算法,高清修复放大算法,高解像度でのアップスケ`ラ`
Preview as Input,,,将预览图作为输入,
Specify the amount that you wish to expand the mask by (recommend 0-10),需要拓展的蒙版数量（建议1-10）,,蒙版外扩的像素（推荐0-10）,
tp__caiyun,,,,tp__caiyun
"beta (if Triple or Twice is not selected,Twice automatically enable)",β值（若未选择“三项和”或“二次求和”，自动启用“二次求和”）,,,
Framerate,,,,フレ`ムレ`ト
Choose preprocessor for semantic segmentation:,选择预处理器,,选择语义分割的预处理器,
Model path filter,模型路径过滤,模型路径过滤,模型路径过滤,モデルのパスのフィルタ`
small-to-big,,,,小さいものから大きいもの
Extra path to scan for LoRA models (e.g. training output directory),检索 LoRA 模型的附加目录,检索 LoRA 模型的附加目录,检索 LoRA 模型的附加目录,
print change,输出变化,,,
Adam Weight Decay,Adam 权重衰减(Weight Decay),Adam 权重衰减(Weight Decay),Adam 权重衰减(Weight Decay),
Target,目标,,,タ`ゲット
Solid color,纯色,纯色,纯色,g色
cosine_annealing_with_restarts,,,,cosine_annealing_with_restarts
Sample Seed,样本种子,样本种子,样本种子,サンプルシ`ド
Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.,,,,Img2imgとebsynthを使用して踊を作成するための。ebsynthを使用して踊を出力します。ControlNetC能で幼鳏筏蓼埂
Upscaler 2 visibility,放大算法 2 (Upscaler 2) 可见度,放大算法 2 (Upscaler 2) 可见度,放大算法 2 (Upscaler 2) 可见度,Upscaler 2のJ性
Release notes,,,,リリ`スノ`ト
Secondary detection model (B) (optional),次要检测模型 (B) (可选),次要检测模型 (B) (可选),次要检测模型 (B) (可选),
rrelu,rrelu,,,rrelu
Prompt for face,,,面部的提示词,
Style 2,模版风格 2,模版风格 2,模版风格 2,
Save Preview(s) Frequency (Epochs),,,,プレビュ`保存l度 (エポック数)
ControlNet not found. Please install it :),,,,ControlNet がつかりません。インスト`ルしてください :)
depth_zoe,深度估算（depth 模型，ZoeDepth 算法）,,深度检测（depth，ZoeDepth 算法）,
Send size when sending prompt or image to another interface,将提示词或者图像发送到 >> 其他界面时，把尺寸数据也传送过去,将提示词或者图像发送到 >> 其他界面时，把尺寸数据也传送过去,将提示词或者图像发送到 >> 其他界面时，把尺寸数据也传送过去,他のインタ`フェ`スにプロンプトや画像を送信するHにサイズも送信する
Riffusion,,,,Riffusion
Interp X,,,,Xg隔
Ranking Bar,评级控件,,,
Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit),,,,Web UI用のプリセットユ`ティリティツ`ル。カスタムスクリプトとの互Q性を提供します。(制限付き)
ControlNet v1.1.275,扩散控制网络(ControlNet),,,
scheduler type,,,调度器类型,
stable-diffusion-webui-prompt-travel,提示词变迁,提示词变迁,提示词变迁,
Class Image Generation,,,,クラス画像の生成
Sub directories,子目录,,子目录,サブディレクトリ
"I know it lives as a tab, but this was meant to be a demo at first, now it's growing to something more",虽然当前它以 选项卡 的形式呈现，但仅作为演示，后续将会有进一步更新（这个页面纯属摆设）,虽然当前它以 选项卡 的形式呈现，但仅作为演示，后续将会有进一步更新（这个页面纯属摆设）,虽然当前它以 选项卡 的形式呈现，但仅作为演示，后续将会有进一步更新（这个页面纯属摆设）,
Localization dirs,,本地化文件目录,本地化文件目录,言Zファイルのディレクトリ
Promptgen,,,,Promptgen
Max Token Length (Requires Pad Tokens for > 75),最大词元(Token)长度 (词元(Token) > 75 时会进行留空),最大词元(Token)长度 (词元(Token) > 75 时会进行留空),最大词元(Token)长度 (词元(Token) > 75 时会进行留空),
Format,,,,フォ`マット
Enable this to save VRAM.,启用此项以节省显存(VRAM),启用此项以节省显存(VRAM),启用此项以节省显存(VRAM),
Name,名称,名称,名称,名前
Range,权重范围,,,
Extension,扩展,扩展,扩展,C能
Output settings: all settings (including fps and max frames),,,,出力O定：すべてのO定 (FPSと最大フレ`ムを含む)
Upcast cross attention layer to float32,将交叉关注层向上投射到float32,将交叉关注层向上转型到float32,将交叉关注层向上转型到float32,Cross Attention レイヤ`を float32 にアップキャスト
Main menu position,选项卡列表位置,,,
The resolution of input images. You probably want to pre-process them to match this.,输入图像的分辨率。你可能希望对它们进行预处理以匹配它,输入图像的分辨率。你可能希望对它们进行预处理以匹配它,输入图像的分辨率。你可能希望对它们进行预处理以匹配它,
Enable perspective flip,,,,透投影反を有郡摔工
brightness,,,,明度
##: Houses a multiline comment that will not affect the final output.,,,,##: 最K的な出力に影を与えない}数行のコメントを入れる。
turn_page_switch,翻页开关,翻页开关,翻页开关,ペ`ジをめくる
after: Processes arbitrary text following the main output.,,,,after: メイン出力の後に任意のテキストをI理します。
"Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.",,,,ドライブに保存することなく、マ`ジしてg行することができます。次XYマ`ジ生成、LoRAの抽出とマ`ジ、LoRAとckptのY合、Aeのマ`ジ等。一部の操作には大量のRAMとdiffusersが必要です。
Next Steps,,,,次のステップ
top-to-bottom,,,,上から下へ
txt2img_steps,采样迭代步数(Steps),,,
Important Notes:,,,,重要事:
?,,,,?
Image File,图像文件,,,画像ファイル
Divergence (3D effect),,,,ダイバ`ジェンス（3D抗）
Gap fill technique,,,,ギャップ埋め技g
Defaults,,,UI默认值,
Override `Sampling method` to Euler?(this method is built for it),覆写 `采样方法` 为 Euler?(这个方法就是为它设计的),覆写 `采样方法` 为 Euler?(这个方法就是为它设计的),覆写 `采样方法` 为 Euler?(这个方法就是为它设计的),サンプリングアルゴリズムをEulerに上き(そうすることを前提にOされています)
singularize: Converts the content into singular form.,,,,singularize: コンテンツをg数形にQします。
Original negative prompt,初始负面提示词,初始反向提示词,初始反向提示词,オリジナルのネガティブプロンプト
I suggest at least four images for each,,,,それぞれに少なくとも4つの画像を提案します
(A10) Primary,,(A10) 主要,(A10) 主要,
Escape brackets in tag,,,,タグ中の括弧をエスケ`プする
Annotator result,,,,AnnotatorのY果
Scale to,指定分辨率缩放,指定分辨率缩放,指定分辨率缩放,解像度指定
Outfill border color:,填充颜色：,填充颜色：,填充颜色：,Tりつぶしのの色:
(EXCLUSIVE),（严格匹配）,,,(排他的)
"Info, Links and Help",,,,情蟆リンクおよびヘルプ
Color reduce algo,,,,p色アルゴリズム
Filepath ? str,,,,ファイルパス ? str
Enable extras,,打开 ,打开 ,
Dynamic Thresholding,,,,Dynamic Thresholding
Submit results,提交结果,,,
Run Merge,开始合并,开始合并,开始合并,
ig,,,,ig
Grad Accumulation Steps,梯度累加步数(Grad Accumulation Steps),梯度累加步数(Grad Accumulation Steps),梯度累加步数(Grad Accumulation Steps),
- Zoom canvas,,,- 缩放画布,
Image Generation Library,,,,画像生成ライブラリ
Sigma noise,Sigma 噪声,Sigma 噪声,Sigma 噪声,Sigma noise
Add LyCORIS to prompt,将 LyCORIS 添加到提示词,,将 LyCORIS 模型添加到提示词,
"to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.",查看哪些词是使用多个子词构成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（1 个单词但使用 2 个 Embedding 向量）。目前这个扩展还有点问题，在按下按钮之前需要一点时间来处理。如果过了一会还是不行，试试随便加个空格刷新一下,查看哪些词是使用多个子词构成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（1 个单词但使用 2 个 Embedding 向量）。目前这个扩展还有点问题，在按下按钮之前需要一点时间来处理。如果过了一会还是不行，试试随便加个空格刷新一下,查看哪些词是使用多个子词构成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（1 个单词但使用 2 个 Embedding 向量）。目前这个扩展还有点问题，在按下按钮之前需要一点时间来处理。如果过了一会还是不行，试试随便加个空格刷新一下,}数のサブワ`ドを使用して成されているgZを_Jします。「computer」はstable diffusionの CLIP 辞に存在せず、代わりに「compu」と「ter」が使用されます (1 Zで 2 つの埋めzみベクトル)。 F在バグがあり、ボタンを押す前にI理するrgが必要です。 しばらくしてもうまくいかない龊悉稀ランダムなスペ`スを追加して更新してみてください。
"Toggle overlap ( Technical button, neededs for testing )",,,Toggle overlap ( 测试功能 ),
CLIP,,,,CLIP
Maximum width or height (whichever is higher),,,,最大幅または高さ (どちらかLい方)
file: Processes the file content of 'path.',,,,file: 「path」のファイルコンテンツをI理します。
Reverse model sort order,逆序排序,逆序排序,逆序排序,モデルのソ`トを逆にする
Enable translation,启用翻译,,,
Create aesthetic embedding,创建美术风格,创建美术风格,创建美术风格,美的埋めzみの作成
ku,,,,ku
house-cartoon,,,,家のカ`トゥ`ン
Allow overwrite output-model,允许输出模型覆写同名文件,允许输出模型覆盖同名文件,允许输出模型覆盖同名文件,
https://github.com/adieyal/sd-dynamic-prompts.git,,,,https://github.com/adieyal/sd-dynamic-prompts.git
Nucleus,,,,Nucleus
(0 = No limit),,,（0表示无限制）,
stable-diffusion-webui-composable-lora,LoRA 修饰限制(Composable Lora)插件,可自组 LoRA,可自组 LoRA,
Layer4,,,,Layer4
Source Checkpoint:,,,,Source Checkpoint:
Server start time,服务器启动时间,服务器启动时间,服务器启动时间,
Fuse,,,,Fuse
?,?,?,?,
hidden_idx_prev,hidden_idx_prev,,,hidden_idx_prev
Error threshold,,,误差阈值,エラ`のしきい
ja_JP Localization,,,,ja_JP Localization
Remove Auto Trans,移除自动翻译,,,自臃Uを削除
Open New Canvas,,,新建画布设置,
"Allows for random parameters during txt2img generation. This script is processed for all generations, regardless of the script selected, meaning this script will function with others as well, such as AUTOMATIC1111/stable-diffusion-webui-wildcards",允许在文生图的生成期间使用随机的参数。无论选择哪种脚本，此脚本都会针对所有的生成进行处理，这意味着此脚本也可以与其他脚本一起使用，例如通配符脚本,允许在文生图的生成期间使用随机的参数。无论选择哪种脚本，此脚本都会针对所有的生成进行处理，这意味着此脚本也可以与其他脚本一起使用，例如通配符脚本,允许在文生图的生成期间使用随机的参数。无论选择哪种脚本，此脚本都会针对所有的生成进行处理，这意味着此脚本也可以与其他脚本一起使用，例如通配符脚本,
Style frames,,,,Style frames
Metadeta,元数据,,,
Exclude abandoned,,,,削除されたものを除外
DELETE File(s),删除文件,,,ファイルを削除
sd-model-preview-xd,,,,sd-model-preview-xd
reference_only,图像参考（无需模型，仅注意力层图像链接）,,图像参考（无需模型，注意力链接）,
"Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.",添加一个按钮以将 NovelAI 中使用的提示词转换为在 WebUI 中使用。此外，添加一个按钮，让你可以调用以前使用过的提示词,添加一个按钮以将 NovelAI 中使用的提示词转换为在 WebUI 中使用。此外，添加一个按钮，让你可以调用以前使用过的提示词,添加一个按钮以将 NovelAI 中使用的提示词转换为在 WebUI 中使用。此外，添加一个按钮，让你可以调用以前使用过的提示词,NovelAI で使用されているプロンプトをWebUI で使用するためのボタンを追加します。 さらに、以前に使用したプロンプトを呼び出すためのボタンを追加します。
Open output directory,打开输出目录,打开输出目录,打开输出目录,
Delete list(-1 for all),删除预约（-1表示全选）,,,
alpha threshold,α阈值（被视为前景的蒙版的透明度）,,,
Draw legend,显示轴类型和值,显示轴类型和值,显示轴类型和值,凡例を描く
Method,算法,,算法,
Update directory names in database,,,在数据库中更新路径名称,デ`タベ`スのディレクトリ名を更新
HED Resolution,HED 分辨率（HED Resolution）,HED 分辨率（HED Resolution）,HED 分辨率（HED Resolution）,
Threshold A,阈值A（此值根据预处理器选项不同发生变化，滑动条不可用时代表此预处理器无该项设置）,阈值A（此值根据预处理器选项不同发生变化，滑动条不可用时代表此预处理器无该项设置）,阈值A（此值根据预处理器选项不同发生变化，滑动条不可用时代表此预处理器无该项设置）,しきい A
tile_colorfix+sharp,,,颜色修正+锐化（tile）,
Force image gallery to use temporary files,,,,画像ギャラリ`で一rファイルを使用するよう制する
Upscale latent space image when doing hires. fix,做高分辨率修复时，也放大潜空间图像,做高清修复时，也放大潜变量,做高清修复时，也放大潜变量,
verbose console output,将详细信息输出到控制台,将详细信息输出到控制台,将详细信息输出到控制台,
pt,,,,pt
Use old emphasis implementation. Can be useful to reproduce old seeds.,使用旧的强调符实现。可用于复现旧随机种子,使用旧的强调符实现。可用于复现旧随机种子,使用旧的强调符实现。可用于复现旧随机种子,古い{のg装を使う。古い生成物を再Fするのに使えます。
Create flipped copies,创建镜像副本,创建镜像副本,创建镜像副本,反画像を生成する
Show generated images in ui,在用户界面上显示生成了的图像,在用户界面上显示生成了的图像,在用户界面上显示生成了的图像,生成された画像を Ui で表示する
DPM2 a,DPM2 a,,,DPM2 a
Enable Region 7,启用此区域,,启用区域 7,
Use EMA Weights for Inference,,,,推にEMA（指数移悠骄）のウェイトを使用する
Directory for detected maps auto saving,探测模式图(detected maps)保存路径,探测模式图(detected maps)保存路径,探测模式图(detected maps)保存路径,食訾丹欷骏蕙氓驻蜃颖４妞工毳钎％欹トリ
The current workflow is [text prompt]->[object detection]->[segmentation]. Semantic segmentation support is in Auto SAM panel.,当前的工作流程是[文本提示]->[对象检测]->[分割]，使用语义分割协议请转到“Auto SAM”页面。,,当前的工作流是[文本提示词]->[物体识别]->[分割蒙版],
Save metadata (.safetensors only),,,保存元数据（仅限.safetensors ）,
Randomize Steps,随机化 采样迭代步数,随机化 采样迭代步数,随机化 采样迭代步数,
su,,,,su
You may configurate automatic sam generation. See,点击,,您可以在这里对Auto SAM进行设置。各项参数具体含义可以在“,
ControlNet v1.1.227,扩散控制网络(ControlNet),,,
"Class token(s) to swap, can be comma-separated",要互换的类的词元(Token)，可以是以英文逗号分割的,要互换的类的词元(Token)，可以是以英文逗号分割的,要互换的类的词元(Token)，可以是以英文逗号分割的,
Preview automatically when add/remove points,动态预览,,增加或减少标注点时自动更新预览,
Shift + wheel,,,Shift + 滚轮,
Region 5,区域 5,区域 5,区域 5,
Prompts negative,,,,ネガティブプロンプト
"Restarts noise scheduler, or linear",,,,Noise scheduler、またはlinearを再起婴筏蓼
Replace Text,替换文本,,,テキストを置きQえ
Cond.fix: Medium,修复时调节：中,修复时调节：中,修复时调节：中,Cond.fix: 中
Create the danged model already.,创建一个本就很牛的模型,创建一个本就很牛的模型,创建一个本就很牛的模型,
ControlNet v1.1.178,扩散控制网络(ControlNet),,,
Pooling Avg,,,,平均ポ`リング
Usage strategies,,,,Usage strategies
Experimental features (May be solve the problem of erratic training and difficult to reproduce [set EMA to 0.97]),实验性功能（可能解决训练不稳定和难以重现的问题 [将 EMA 设置为 0.97]）,实验性功能（可能解决训练不稳定和难以重现的问题 [将 EMA 设置为 0.97]）,实验性功能（可能解决训练不稳定和难以重现的问题 [将 EMA 设置为 0.97]）,gY的なC能（不安定なトレ`ニングや再F性の低い}を解Qする可能性があります。[EMAを0.97にO定]）
clip_vision,风格转移（CLIP Vision，配合style模型）,风格转移（CLIP Vision，配合style模型）,风格转移（CLIP Vision，配合style模型）,clip_vision
fill it with latent space noise,于潜空间填充噪声,于潜空间填充噪声,于潜空间填充噪声,潜在空g(latent space)におけるノイズで埋める
Copy to Inpaint Upload,将蒙版 >>局部重绘(上传蒙版),,复制蒙版到局部重绘（上传蒙版）,
ControlNet v1.1.204,扩散控制网络(ControlNet),,,
Send to openOutpaint,,,>>外扩插件,OpenOutpaintへ送
while: Loops content until the condition returns false.,,,,whileの条件が false を返すまで内容をル`プします。
ControlNet Unit 2,控制单元 2,,ControlNet单元2,
Stable Horde Worker,,,,Stable Horde Worker
ControlNet v1.1.189,扩散控制网络(ControlNet),,,
haku-img,,,,haku-img
File type,输出文件格式,,,
ka,,,,ka
logSNR,,,,logSNR
Conditioning Highres,,,,コンディショニングHighres.fix
Model cache size (requires restart),模型缓存数量（需要保存设置并重启）,模型缓存数量（需要保存设置并重启）,模型缓存数量（需要保存设置并重启）,モデルのキャッシュサイズ (再起婴必要)
Drop out tags when creating prompts.,,创建提示词时丢弃标签(tags),创建提示词时丢弃标签(tags),プロンプト作成rにタグをドロップアウトする
Apply settings,保存设置,保存设置,保存设置,O定をm用
"Select Enable translation and wait until you the label shows ready. Once the label has Ready on it, select the prompt language, write the prompt in the prompt field then press generate. The script will translate the prompt and generate the text.",选择“启用翻译”并等待加载，日志详见控制台。 下方提示 “ready” 后，选择语言即可。,,,
Shapes,图形样例,图形,图形,
Video Depth,,,,深度の踊
Show Additional Generation Info,,,显示额外的生成信息,
Until condition ? until,,,,Until condition <unk> until
date,日期,日期,日期,日付
Pause After N Epochs,,,,N エポック後に一r停止
SuperMerger,,,,SuperMerger
Control Model number,控制单元编号,,,
mci,,运动补偿,运动补偿,
Make Zip when Save?,保存时创建zip压缩文件?,保存时创建zip压缩文件?,保存时创建zip压缩文件?,
Search and Replace,搜索/替换,,,仕鳏戎Q
Include Separate Images,生成图表时，保留每一张图像,生成图表时，保留每一张图像,生成图表时，保留每一张图像,
case sensitive,区分大小写,区分大小写,区分大小写,大文字と小文字を区e
Elements,元素,,,
(S2) Inter-Method,,(S2) 插值方法,(S2) 插值方法,
Extra,,,,その他
Show extra networks,显示附加网络面板,显示附加网络面板,显示附加网络面板,
Sampling method,采样方法(Sampler),采样方法(Sampler),采样方法(Sampler),サンプリング方法
General,通用设置,,,一般
In Frame Count,,,,フレ`ム数で
Input directory,输入目录,输入目录,输入目录,入力ディレクトリ
File format for images,图像的文件格式,图像的文件格式,图像的文件格式,画像ファイルの保存形式
tp__baidu,,,,tp__baidu
Meta Tags,,属性标签(Tags),属性标签(Tags),
Only use Random seeds (Unless comparing paths),只用随机种子 (除非需要对比变迁轨迹),只用随机种子 (除非需要对比变迁轨迹),只用随机种子 (除非需要对比变迁轨迹),ランダムシ`ドのみを使用 (パスの比^を除く)
ja,,,,ja
Layer2 opacity,,,,Layer2 不透明度
Sample extension. Allows you to use __name__ syntax in your prompt to get a random line from a file named name.txt in the wildcards directory. Also see Dynamic Prompts for similar functionality.,扩展示例。允许你在提示词中使用 __name__ 语法时，会从 wildcards 目录中一个名为 name.txt 的文件中随机获取一行作为输入。动态提示词扩展也有类似功能,扩展示例。允许你在提示词中使用 __name__ 语法时，会从 wildcards 目录中一个名为 name.txt 的文件中随机获取一行作为输入。动态提示词扩展也有类似功能,扩展示例。允许你在提示词中使用 __name__ 语法时，会从 wildcards 目录中一个名为 name.txt 的文件中随机获取一行作为输入。动态提示词扩展也有类似功能,
Make a backup copy of the model being edited when saving its metadata.,保存元数据时，备份正在编辑的模型,保存元数据时，备份正在编辑的模型,保存元数据时，备份正在编辑的模型,モデルの集されたメタデ`タが保存されたときに、バックアップコピ`を作成する
Disable all extensions,禁用所有插件,,禁用插件,すべてのC能のo炕
User interface,用户界面,用户界面,用户界面,ユ`ザ`インタ`フェ`ス
h,高,,,
Split oversized images,分割过大的图像,分割过大的图像,分割过大的图像,巨大な画像を分割する
fill right,,,,右に
Hands,手部样例,手部,手部,
Steps,采样迭代步数(Steps),采样迭代步数(Steps),采样迭代步数(Steps),ステップ数
),,,,)
Tokenizer,词元分析器(Tokenizer),词元分析器(Tokenizer),词元分析器(Tokenizer),ト`クナイザ`
Search Booru,,搜 Booru,搜 Booru,
Calcutation Mode,合并算法（详见GitHub页面）,,,
superfast,,,,非常に速い
Component,组件,,,
Size of the face when recreating,,,面部重绘时的尺寸,
"Number of sampling steps for upscaled picture. If 0, uses same as for original.",设置进行高分辨率修复时的采样迭代次数，0表示沿用原始采样迭代次数,设置进行高清修复时的采样迭代次数，0表示沿用原始采样迭代次数,设置进行高清修复时的采样迭代次数，0表示沿用原始采样迭代次数,アップスケ`ルした画像のサンプリングステップ数です。0の龊悉媳纠搐违攻匹氓资と同じになります。
Input Directory,图像输入目录,,输入路径,
Sample Prompt Template File,,,,サンプルプロンプトのテンプレ`トファイル
"Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.",,,,さまざまなショ`トコ`ドをプロンプトに含めることができます。 ファイルからテキストを取り出して、独自の涫をO定したり、条件付きv数を通じてテキストをI理したり、またそれ以上のことができます。いわば化されたワイルドカ`ドのようなものです。これは、hard-prompts made eary、ControlNet、txt2img2imgやtxt2maskのy合C能が含まれています。
scribbles,,,,らくがき
ControlNet v1.1.140,扩散控制网络(ControlNet),,,
Catppuccin Theme,Catppuccin 个性主题,Catppuccin 个性主题,Catppuccin 个性主题,Catppuccin Theme
"With img2img, do exactly the amount of steps the slider specifies.",,,图生图时，实际采样步数和滑块一致,
Gradient Clipping,,,,グラデ`ションのクリッピング
Y type,Y轴类型,Y轴类型,Y轴类型,YSのN
Magic prompt,魔法提示词,魔法提示词,魔法提示词,Magic prompt
ControlNet number,ControlNet 编号 ,,ControlNet单元编号,ControlNet number
for your animation (leave blank to ignore).,,,,アニメ`ションにして使用する（oする龊悉峡瞻驻韦蓼蓼摔筏皮ださい）。
Output directory for img2img images,图生图的输出目录,图生图的输出目录,图生图的输出目录,img2img画像の出力ディレクトリ
Instance Token,,,,インスタンスト`クン
(B7) Secondary,,(B7) 第二,(B7) 第二,
Video Settings File,,,,踊のO定ファイル
Preset Utilities,,,,Preset Utilities
Interrogate: include ranks of model tags matches in results (Has no effect on caption-based interrogators).,将置信度作为tag权重写入结果（对基于生成自然语言描述的反推没有影响）,将置信度作为tag权重写入结果（对基于生成自然语言描述的反推没有影响）,将置信度作为tag权重写入结果（对基于生成自然语言描述的反推没有影响）,Interrogate: モデルタグがY果に一致するランクを含みます (キャプションベ`スのInterrogateには影しません)。
Hide annotator result,隐藏预处理预览,隐藏预处理预览,隐藏预处理预览,アノテ`ションY果をLす
LLuL Downscaler,,,,LLuLダウンスケ`ラ`
Use deepbooru for caption,使用 deepbooru 生成说明文字(tags),使用 deepbooru 生成说明文字(tags),使用 deepbooru 生成说明文字(tags),deepbooruでh明をつける
ControlNet v1.1.171,扩散控制网络(ControlNet),,,
"Upscale image normally, split result into tiles, improve each tile using img2img, merge whole image back",正常放大图像，将结果分割成图块(tiles)，用图生图改进每个图块，最后将整个图像合并回来,正常放大图像，将结果分割成图块(tiles)，用图生图改进每个图块，最后将整个图像合并回来,正常放大图像，将结果分割成图块(tiles)，用图生图改进每个图块，最后将整个图像合并回来,
"Check console log window for detail, after clicking Scan button",开始扫描后，请打开控制台以获得详细信息和日志，如遇报错，请先访问C站网页确认C站是否崩溃，C站恢复访问后，可再次开始扫描，扫描继承之前的进度，其他详细信息见插件GitHub页面,开始扫描后，请打开控制台以获得详细信息和日志，如遇报错，请先访问C站网页确认C站是否崩溃，C站恢复访问后，可再次开始扫描，扫描继承之前的进度，其他详细信息见插件GitHub页面,开始扫描后，请打开控制台以获得详细信息和日志，如遇报错，请先访问C站网页确认C站是否崩溃，C站恢复访问后，可再次开始扫描，扫描继承之前的进度，其他详细信息见插件GitHub页面,
≥ 0 tagged,,,,0以上のタグがあります
Skip steps,,跳过刚开始噪声过多的n步,跳过刚开始噪声过多的n步,
Save style,将当前的提示词(prompt)保存为模板风格,将当前的提示词(prompt)保存为模板风格,将当前的提示词(prompt)保存为模板风格,スタイルを保存
Author of this model,此模型的作者,此模型的作者,此模型的作者,モデルの作成者
IN_A_09,,模型A 输入层09,模型A 输入层09,
Database,,,,デ`タベ`ス：
Randomize CLIP skip,随机化 在 CLIP 模型的最后哪一层停下 (Clip skip),随机化 在 CLIP 模型的最后哪一层停下 (Clip skip),随机化 在 CLIP 模型的最后哪一层停下 (Clip skip),
3D Model&Pose Loader,,,,3D Model&Pose Loader
Split image threshold,图像分割阈值,图像分割阈值,图像分割阈值,分割する大きさのしきい
Insert selected styles into prompt fields,在提示词中插入选定的模版风格,在提示词中插入选定的模版风格,在提示词中插入选定的模版风格,
"Apply: remove style text from prompt, always replace styles dropdown value with found styles (even if none are found).",,,应用：从提示词中移除样式，并将检测到的样式应用即使检测到的是“无”,
Source,来源,来源,来源,入力
Enable optimized monocular depth estimation,启用优化单色深度估算(optimized monocular depth estimation),启用优化单色深度估算(optimized monocular depth estimation),启用优化单色深度估算(optimized monocular depth estimation),最m化されたg眼深度推定を有郡摔工
A negative prompt for the generic sample image.,,,,一般的なサンプル画像にするのプロンプト。
spaceship-black-white,,,,宇宙船 モノクロ
Training Steps,训练迭代步数,训练迭代步数,训练迭代步数,
Upscale and Resize,放大并调整大小,放大并调整大小,放大并调整大小,アップスケ`ルとサイズ涓
Move VAE and CLIP to RAM when training hypernetwork. Saves VRAM.,训练超网络(Hypernetwork)时将 VAE 和 CLIP 从显存(VRAM)转移至内存(RAM)，节省显存(VRAM),训练超网络(Hypernetwork)时将 VAE 和 CLIP 从显存(VRAM)转移至内存(RAM)，节省显存(VRAM),训练超网络(Hypernetwork)时将 VAE 和 CLIP 从显存(VRAM)转移至内存(RAM)，节省显存(VRAM),
Grid layout,,,,グリッドのレイアウト
Area lower bound,,,面积最小值,面e(幅×高さ)の下限
Warn if changes in caption is not saved,注释信息发生变化但未保存时发送警告信息,,,キャプションの涓が保存されていない龊悉司告
Padding token (ID or single token),填充通配符（输入 token ID 或者单个符号）,,,め替えるト`クン (IDまたはg一のト`クン)
Image Processing,,,,画像I理
Blur amount:,模糊量：,模糊量：,模糊量：,ぼかしのさ
ema-only,仅保留ema信息,仅保留ema权重,仅保留ema权重,
ControlNet - 6,扩散控制网络(ControlNet) - 6,,,
ControlNet v1.1.253,扩散控制网络(ControlNet),,,
Aesthetic Scorer,,,,Aesthetic Scorer
img2img_denoising_strength,重绘幅度(Denoising),,,
Send to Recipe,,>> 配方,>> 配方,
Always,,,总是,
minimum aesthetic_score,美学评分下限,美学评分下限,美学评分下限,最小美的スコア
Reload checkpoint,刷新模型列表,刷新模型列表,刷新模型列表,
Cache Latents,,,,履sのキャッシュ
Set ranking to,,,设置评级为,
mlsd, 线条检测（mlsd 模型，M-LSD 算法）,M-LSD 线条检测（M-LSD line detection）, 线条检测（mlsd，M-LSD 算法）,mlsd
Approx cheap,,,,超易NN
sign,sign,,,
installed,已安装,已安装,已安装,インスト`ルg
Negative Filter,负面筛选条件,,,のフィルタ`
Interrogators,使用的反推算法,,,Interrogators
tp_argos,,,,tp_argos
wd-v1-4-vit-tagger,,,,wd-v1-4-vit-tagger
"red, blue",,,,"red, blue"
filelist,,,,filelist
hires_fix,,,高清修复,高解像度修正
Note:,注意：,,,淇:
Class Batch Size,类每批数量(Class Batch Size),类每批数量(Class Batch Size),类每批数量(Class Batch Size),クラスのバッチサイズ
RIFE v4.6 and FILM.,,,,RIFE v4.6 と FILM.
Fusion,,,,Fusion
Smoothing generated images by skipping a few very last steps and averaging together some images before them.,,,,最後の数ステップをスキップし、それ以前のいくつかの画像をまとめて平均化することで生成された画像を平滑化します。
Colorerrorborder,Colorerrorborder,,,
Clip Interrogator,,,,Clip Interrogator
Classifier Free Guidance Scale - how strongly the image should conform to prompt - lower values produce more creative results,无分类器指导信息影响尺度(Classifier Free Guidance Scale) - 图像应在多大程度上服从提示词 - 较低的值会产生更有创意的结果,无分类器指导信息影响尺度(Classifier Free Guidance Scale) - 图像应在多大程度上服从提示词 - 较低的值会产生更有创意的结果,无分类器指导信息影响尺度(Classifier Free Guidance Scale) - 图像应在多大程度上服从提示词 - 较低的值会产生更有创意的结果,Classifier Free Guidance Scale - 画像がプロンプトに兢Χ群悉ぁを低くするほど、より造的なY果が得られます。
ControlNet v1.1.222,扩散控制网络(ControlNet),,,
Random number generator source.,,,随机数产生源,
|,,,,|
Token Merging - Merge mlp layers,合并前馈神经网络层(mlp layers),,,
loss_simple,,,,loss_simple
Pages: ,页码：,页码：,页码：,
(3) Recreate the Faces,,,(3) 面部重建,
Dataset directory,数据集目录,数据集目录,数据集目录,デ`タセットディレクトリ
Hypernetworks,超网络(Hypernetwork),超网络(Hypernetwork),超网络(Hypernetwork),Hypernetworks
"eval: Parses the content using the simpleeval library, returning the result. Particularly useful for arithmetic.",,,,eval: simpleevalライブラリでコンテンツをパ`スし、Y果を返します。算g演算に便利です。
Region 7,区域 7,区域 7,区域 7,
Info and links,,资讯和链接,资讯和链接,
. Visit,分隔，点击,,号分隔。你可以点击“,
Parse Result,,剖析结果,剖析结果,
hardshrink,hardshrink,,,hardshrink
Discard,,,丢弃,
Return the sentence count ? sentence_count,,,,文の数を返す ? sentence_count
Colorfill,Colorfill,,,
Send to Layer5,,,,レイヤ`5に送
3D settings,,3D 设定,3D 设定,
Area,,,,
img2img_restore_faces,是否启用面部修复,,,
elemental,元素,,,
ControlNet v1.1.126,扩散控制网络(ControlNet),,,
Minimum batch size,,,最小批处理大小,
Graph Smoothing Steps,,,,グラフスム`ジングのステップ
TEnc Weight 4,Text Encoder 权重 4,Text Encoder 权重 4,Text Encoder 权重 4,TEncの重み4
The string to evaluate ? str,,,,uする文字列 ? str
deepbooru: filter out those tags,,,deepbooru: 过滤如下tags,
Create animation sequence from denoised intermediate steps.,,,,デノイズされた中gステップからアニメ`ションシ`ケンスを作成します。
max,,,,最大
https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git,,,,https://github.com/KohakuBlueleaf/a1111-sd-webui-haku-img.git
(when reading generation parameters from text into UI)),,,(当从外部复制生成参数的时候),
Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Related to Latent Couple extension.,,启用使用 AND 关键字（composable diffusion）将 LoRA 的作用范围限制在一部分提示词上。 与潜变量成对扩展相关。,启用使用 AND 关键字（composable diffusion）将 LoRA 的作用范围限制在一部分提示词上。 与潜变量成对扩展相关。,
Lineart,,,线稿,
Default scoring type,默认打分模式,,默认评分类型,
Target size type,,,,タ`ゲットサイズのN
Shortcodes,,,,ショ`トコ`ド
ga,,,,ga
Prior Loss,,,,正t化のp失
limit,,,,制限
Lanczos,Lanczos,,,Lanczos
Output Model Name,输出模型文件名,输出模型文件名,输出模型文件名,
ControlNet v1.1.271,扩散控制网络(ControlNet),,,
(M5) Multiplier,,(M5) 倍率,(M5) 倍率,
Learning Rate Scheduler,学习率调度器(Scheduler),学习率调度器(Scheduler),学习率调度器(Scheduler),学率スケジュ`ラ
reference_adain,图像参考（无需模型，AdaIN 算法）,,图像参考（无需模型，AdaIN风格转移）,
Ctrl + wheel,,,Ctrl + 滚轮,
<,<,,,
Minimum learning rate,,,,最小学レ`ト
Inpaint model B detections before model A runs,在模型 A 运行之前，先局部重绘模型 B 的检测,在模型 A 运行之前，先局部重绘模型 B 的检测,在模型 A 运行之前，先局部重绘模型 B 的检测,
img2img_height,高度,,,
Resume Animation,,,,アニメ`ションを再_
tp__iflyrec,,,,tp__iflyrec
(O10) Output ckpt Name,,(O10) ckpt 输出名,(O10) ckpt 输出名,
Keyframes: depth warping,,,,キ`フレ`ム: 深度ワ`ピング
Control Model - 1,控制模型-1,,,
AddNet Model 2,[附加网络] 模块 2,[可选附加网络] 模型 2,[可选附加网络] 模型 2,モデル 2(AddNet)
(if not: sort by score),,,（如果没有按照得分排序的话）,
S. Attn.,,,,S. Attn.
Maximum number of times the replacement may occur ? _count,,,,置Qを行う最大回数 ? _count
See,查看,查看,查看,なh明については
Distance Threshold ? distance_threhsold,,,,距xのしきい ? distance_threhsold
Use BLIP for caption,使用 BLIP 生成说明文字(自然语言描述),使用 BLIP 生成说明文字(自然语言描述),使用 BLIP 生成说明文字(自然语言描述),BLIPでh明をつける
GroundingDINO batch progress status,GroundingDINO 批量处理执行状态,,GroundingDINO运行状态,
Add Lora hashes to infotext,,,在生成信息中添加Lora的hash值,
Roll Channels,色彩通道轮替,色彩通道轮替,色彩通道轮替,ロ`ルチャンネル
ControlNet v1.1.263,扩散控制网络(ControlNet),,,
"Crop: top, left, bottom, right",,,,クロップ: 上、左、下、右
Clip Skip,,,,Clip Skip
Model Types,模型类型,模型种类,模型种类,
unprompted,非文本（代码化）提示词,非文本（代码化）提示词,非文本（代码化）提示词,プロンプトされていない
"If this values is non-zero, it will be added to seed and used to initialize RNG for noises when using samplers with Eta. You can use this to produce even more variation of images, or you can use this to match images of other software if you know what you are doing.",如果这个值不为零，它将被添加到随机种子中，并在使用带有 Eta 的采样器时用于初始化随机噪声。你可以使用它来产生更多的图像变化，或者你可以使用它来模仿其他软件生成的图像，如果你知道你在做什么,如果这个值不为零，它将被添加到随机种子中，并在使用带有 Eta 的采样器时用于初始化随机噪声。你可以使用它来产生更多的图像变化，或者你可以使用它来模仿其他软件生成的图像，如果你知道你在做什么,如果这个值不为零，它将被添加到随机种子中，并在使用带有 Eta 的采样器时用于初始化随机噪声。你可以使用它来产生更多的图像变化，或者你可以使用它来模仿其他软件生成的图像，如果你知道你在做什么,このが0以外の龊稀シ`ドに追加され、Etaでサンプラ`を使用するHのノイズ用の乱数生成器を初期化するのに使用されます。これを利用して、さらにバリエ`ションNかな画像を作成したり、他のソフトの画像に合わせたりすることができます。
(5) Blend the entire image,,,(5) 融合整个图像,
swish,swish,,,swish
ControlNet v1.1.170,扩散控制网络(ControlNet),,,
This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt,这是在运行时重新实现的局部重绘图像调节蒙版强度(相对于重绘强度)的扩展。这对于局部重绘专用的模型(例如 sd-v1-5-inpainting.ckpt)很有用,这是在运行时重新实现的局部重绘图像调节蒙版强度(相对于重绘强度)的扩展。这对于局部重绘专用的模型(例如 sd-v1-5-inpainting.ckpt)很有用,这是在运行时重新实现的局部重绘图像调节蒙版强度(相对于重绘强度)的扩展。这对于局部重绘专用的模型(例如 sd-v1-5-inpainting.ckpt)很有用,InpaintingのコンディショニングマスクのさをDenoisingのさにしてg行rに相的にきQえるためのExtensionです。sd-v1-5-inpainting.ckptのようなInpaintingモデルで有用です。
Dimension upper bound,,,边长最大值,寸法（幅、高さ）の上限
Gamma,,,,ガンマ
Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.,,,,Web UI が LoRA (1.X および 2.X) を使用して画像を生成できます。また、.safetensors ネットワ`クを集してメタデ`タをプロンプトできます。
"Restore Faces, Tiling & more",,,,の修正、タイリング、その他
Preview DFI Map,,,,マッププレビュ`
Fix clip,,,修复clip,
Seams fix:,,,,シ`ム修正:
output,输出,,,
OUT_A_04,,模型A 输出层04,模型A 输出层04,
Guidance End (T),引导退出时机（End）,引导退出时机（End）,引导退出时机（End）,ガイダンスK了 (T)
ControlNet-6,控制网络-6,,,
ControlNet v1.1.122,扩散控制网络(ControlNet),,,
"download these files, and select these files in the ""Create inspiration images"" script UI",,,,これらのファイルをダウンロ`ドし、「インスピレ`ションイメ`ジの作成」スクリプトUIでこれらのファイルをxkします
GFPGAN,面部修复(GFPGAN),面部修复(GFPGAN),面部修复(GFPGAN),
Import CSS file,导入 CSS 文件,导入 CSS 文件,导入 CSS 文件,
ControlNet v1.1.166,扩散控制网络(ControlNet),,,
Aesthetic,,,,美的
use spaces for tags in deepbooru,deepbooru 反推结果中使用空格替代下划线（推荐开启）,deepbooru 反推结果中使用空格替代下划线（推荐开启）,deepbooru 反推结果中使用空格替代下划线（推荐开启）,deepbooruのタグでスペ`スを使う
resize: from,从 ,从 ,从 ,
Max number of tags,,,,最大タグ数
hires_scale,,,,高解像度比率
Extract EMA Weights,,,,EMAウェイトを抽出
Return the count of a custom substring ? string_count,,,,カスタム部分文字列のカウントを返す ? string_count
CodeFormer weight parameter; 0 = maximum effect; 1 = minimum effect,CodeFormer 权重参数；为 0 时效果最大；为 1 时效果最小,CodeFormer 权重参数；为 0 时效果最大；为 1 时效果最小,CodeFormer 权重参数；为 0 时效果最大；为 1 时效果最小,CodeFormerの重みパラメ`タ`;0が最大で1が最小
Limiting value,,,,限界
Sampler schedule,,,,サンプラ`のスケジュ`ル
Ground Color,,,,地面の色
- or -,,,,- または -
Stop at CLIP layers,在 CLIP 模型的最后哪一层停下 (Clip skip),在 CLIP 模型的最后哪一层停下 (Clip skip),在 CLIP 模型的最后哪一层停下 (Clip skip),CLIP レイヤ`の停止I理
DPM++ 2S a Karras,DPM++ 2S a Karras,,,DPM++ 2S a Karras
Embedding to Shareable PNG,将 Embedding 转换为可分享的 PNG 图片文件,将 Embedding 转换为可分享的 PNG 图片文件,将 Embedding 转换为可分享的 PNG 图片文件,
Hypernetwork,超网络(Hypernetwork),超网络(Hypernetwork),超网络(Hypernetwork),Hypernetwork
booru2prompt,booru转提示词,booru转提示词,booru转提示词,booru2prompt
Save init images when using img2img,保存 图生图 中输入的 原始图片,,图生图时保存初始图片,
File format for grids,宫格图的文件格式,宫格图的文件格式,宫格图的文件格式,グリッド画像の保存形式
The directory containing training images.,包含训练图像的目录,包含训练图像的目录,包含训练图像的目录,
once,,单次复用,单次复用,一度のみ
Auto focal point crop,自动焦点裁切,自动焦点裁切,自动焦点裁切,自婴墙沟悚颔ロップ
Do not add watermark to images,不要给图像加水印（建议开启）,不要给图像加水印（建议开启）,不要给图像加水印（建议开启）,子透かしを画像に追加しない
(C7) Thertiary,,(C7) 第三,(C7) 第三,
Polynomial Power,,,,多式累\
Leftpannelwidth,Leftpannelwidth,,,
hi-res images,,,,高解像度画像
haku_output,,,,プレビュ`
Delete,删除,删除,删除,削除
ControlNet v1.1.164,扩散控制网络(ControlNet),,,
Edit,,,编辑,
Firstpass width,首次宽度,首次宽度,首次宽度,
Mask mode,蒙版模式,蒙版模式,蒙版模式,マスクの方式
Apply horizontal Flip,应用水平翻转,应用水平翻转,应用水平翻转,
uppercase,,,,大文字
stable-diffusion-webui,界面个性化设置,,,
Leave blank to use instance prompt. Optionally use [filewords] to base sample captions on instance images.,,,,インスタンスプロンプトを使用する龊悉峡瞻驻韦蓼蓼摔筏皮ださい。必要に辘袱啤[filewords] を使用してインスタンス画像を基にしたサンプルキャプションを使用できます。
"Comma-separated list of tags (""artist, style, character, 2d, 3d..."")","此模型的标签，逗号分隔（如、""艺术家、风格、角色、2D、3D等""）","此模型的标签，逗号分隔（如、""艺术家、风格、角色、2D、3D等""）","此模型的标签，逗号分隔（如、""艺术家、风格、角色、2D、3D等""）","カンマで区切られたタグのリスト (""artist, style, character, 2d, 3d..."")"
"For inpainting, include masked composite in results for web",局部重绘时，在结果中一并显示蒙版复合内容,,局部重绘时，在输出结果中显示复合蒙版,inpaintingで、WebUI上のY果にマスクされた合成w所を表示する
"When using [filewords], this is the class to use when building prompts.",,,,[filewords] を使用する龊稀プロンプトをBするときに使用するクラスです。
Step count,步数 (梯度模式),步数 (梯度模式),步数 (梯度模式),
Unload models,,,,モデルをアンロ`ド
Inpainting conditioning mask strength,局部重绘时图像调节的蒙版屏蔽强度,局部重绘时图像调节的蒙版屏蔽强度,局部重绘时图像调节的蒙版屏蔽强度,インペイントでのマスク度の{整
This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.,,,,This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.
Min Learning Rate,,,,最低学率
DPMSolverMultistep,,,,DPMSolverMultistep
sl,,,,sl
https://github.com/hnmr293/sd-webui-llul.git,,,,https://github.com/hnmr293/sd-webui-llul.git
Use Space Instead Of _,使用空格替换下划线,,,
Latent tile overlap,潜空间图块(Latent tile)重叠,潜变量分块(Latent tile)重叠,潜变量分块(Latent tile)重叠,Latentタイルの重なり幅
IN00,,输入层00,输入层00,
NSFW,,成人内容,成人内容,
Save sample per step,,,,ステップごとにサンプルを保存する
random: Returns a random number between 0 and a given max value (inclusive),,,,random: 0から指定された最大（含む）の欷钎楗螗昆啶适を返します。
Generate a .ckpt file when training completes.,,,,トレ`ニングが完了したら.ckptファイルを生成します。
Enable,启用,启用,启用,有炕
AddNet Model 1,[附加网络] 模块 1,[可选附加网络] 模型 1,[可选附加网络] 模型 1,モデル 1(AddNet)
Filename,文件名,,文件名,
sd-extension-system-info,系统信息面板,系统信息面板,系统信息面板,
UniPC,,,,UniPC
String delimiter when returning more than one choice ? _sep,,,,}数のxk肢を返す龊悉挝淖至星切り文字 <unk> _sep
only affects the 'Blend',,,,「ブレンド」だけに抗をかける
Tertiary model (C),模型 C,模型 C,模型 C,3つ目のmodel (C)
Preview Segmentation,预览蒙版,,预览蒙版分割结果,
Default view for Extra Networks,附加网络默认视图,附加网络默认视图,附加网络默认视图,追加ネットワ`クの既定ビュ`
(2) Crop and Resize the Faces,,,(2) 裁剪与缩放,
Check models' new version,检查模型版本,检查模型更新,检查模型更新,
down,下,下,下,下
Cross-attention,xattn优化方案,Xattn优化方案,Xattn优化方案,
ControlNet v1.1.160,扩散控制网络(ControlNet),,,
en2,,,,en2
ControlNet - 7,扩散控制网络(ControlNet) - 7,,,
a1111-sd-webui-lycoris,LyCORIS插件(提供LyCORIS的独立调用形式，支持LBW),,,a1111-sd-webui-lycoris
Benchmarks...,性能基准,,,
AUTOMATIC/promptgen-majinai-unsafe,,,,AUTOMATIC/promptgen-majinai-unsafe
Motion parameters:,,运动参数：,运动参数：,
CFG scale schedule,,,,CFGスケ`ルのスケジュ`ル
"In this case, artist1 will be chosen twice as often as artist2.",,,,この龊稀artist1はartist2の2倍の_率でxばれます。
Use dropout,采用 dropout 防止过拟合,采用 dropout 防止过拟合,采用 dropout 防止过拟合,Dropoutを使う
Restore Faces,面部修复,面部修复,面部修复,の修正
Parseq,,,,Parseq
ControlNet v1.1.296,扩散控制网络(ControlNet),,,
Composable Lora,LoRA 修饰限制(Composable Lora)（防止LoRA相互污染，与 “画面分区(Latent Couple)” 联用）,可自组 LoRA,可自组 LoRA,
Resize seed from height,高度(Resize seed),高度(Resize seed),高度(Resize seed),元の高さと辘工毳珐`ドからのサイズ涓
depthmap2mask,,深度图转蒙版,深度图转蒙版,depthmap2mask
TEnc Weight 5,Text Encoder 权重 5,Text Encoder 权重 5,Text Encoder 权重 5,TEncの重み5
width,宽度,宽度,宽度,幅
Restore Last Scene,恢复上一个场景,,,
tp_youdao,,,,tp_youdao
synonyms: Replaces the content with one or more synonyms.,,,,xZ: コンテンツを 1 つ以上のxZに置きQえます。
constcase,,,,コンストケ`ス
IP2P,,,指令,
"Weight initialization seed, set -1 for default",,,,重み初期化シ`ド、デフォルトは-1にO定
"Remove results with the ""animated"" tag",,"删除带有""animated""(动图)标签的结果","删除带有""animated""(动图)标签的结果",
Allows users to set a global weight for the negative prompt.,,,,ネガティブプロンプト全体の重みをO定できるようにします。
Processed frames,,,,Processed frames
as a UI to define your animation schedules (see the Parseq section in the Keyframes tab).,,,,アニメ`ションスケジュ`ルを定xするためのUIとして (「キ`フレ`ム」タブの「Parseq」セクションを参照)。
ControlNet v1.1.124,扩散控制网络(ControlNet),,,
"Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.",,,,生成された画像の|を向上させ、(更に|の良い) 同の画像を近傍の既存画像から探索します。}数プロンプトgの切り替えよりも、g一プロンプトの最m化に焦点を当てています。
(if not: use underscores),,,（如果没有使用下划线的话）,
(A9) Primary,,(A9) 主要,(A9) 主要,
GroundingDINO Detection Prompt,GroundingDINO 探测提示词(Detection Prompt),,GroundingDINO探测提示词使用“.”分割,
ControlNet v1.1.256,扩散控制网络(ControlNet),,,
sets,,,,sets
Train an embedding or Hypernetwork; you must specify a directory with a set of 1:1 ratio images,训练嵌入式(Embedding)或者超网络(Hypernetwork)；必须指定一个具有一组 1:1 比例图像的目录,训练嵌入式(Embedding)或者超网络(Hypernetwork)；必须指定一个具有一组 1:1 比例图像的目录,训练嵌入式(Embedding)或者超网络(Hypernetwork)；必须指定一个具有一组 1:1 比例图像的目录,EmbeddingまたはHypernetworkを学します。k横比が1:1の画像があるディレクトリを指定する必要があります。
house-digipa-high-impact,,,,家-digipaハイインパクト
pt_BR Localization,,,,pt_BR Localization
Clear ALL filters,重置所有筛选条件,,,すべてのフィルタ`をクリア
Config Backup: Config,,,配置备份,
Video,视频,视频,视频,踊
Tokenize,词元拆分(Tokenize),词元拆分(Tokenize),词元拆分(Tokenize),ト`クン化
default.json,,,,default.json
Depth Warping & FOV,,,,深度ワ`ピングと野角
Seeds,随机种子,随机种子,随机种子,
(M2) Multiplier,,(M2) 倍率,(M2) 倍率,
ControlNet v1.1.130,扩散控制网络(ControlNet),,,
old localizations,过时的语言包,过时的语言包,过时的语言包,old localizations
"The alpha schedule controls overall alpha for video mix, whether using a composite mask or not.",,,,アルファスケジュ`ルは、コンポジットマスクの使用にvSなく、ビデオミックスの全体的なアルファを制御します。
(choose Unet model: Automatic = use one with same filename as checkpoint; None = use Unet from checkpoint),,,（自动=使用与checkpoint相同文件名的模型；无=使用checkpoint中的Unet模型）,
when they convert their models to lllyasviel format,但需要先转化为 control_v11p_sd15_seg 模型可以识别的格式,,转换到lllyasviel 的格式后支持,
Foreground threshold,前景阈值,,前景阈值,前景しきい
ControlNet v1.1.174,扩散控制网络(ControlNet),,,
Save tags (Windows only),,,,タグを保存(Windowsのみ)
"Separate prompts into parts using vertical pipe character (|) and the script will create a picture for every combination of them (except for the first part, which will be present in all combinations)",用竖线分隔符(|)将提示词分成若干部分，脚本将为它们每个可能的组合创建一个图像（始终保留提示的第一部分，使用相同的种子）,用竖线分隔符(|)将提示词分成若干部分，脚本将为它们每个可能的组合创建一个图像（始终保留提示的第一部分，使用相同的种子）,用竖线分隔符(|)将提示词分成若干部分，脚本将为它们每个可能的组合创建一个图像（始终保留提示的第一部分，使用相同的种子）,
"This will produce three prompts, one for each color. The prompt tag is used to mark the text that will be used as the prompt. If no prompt tag is present then only one prompt is assumed",会产生三条提示词，每个颜色各一条；\n prompt 标签用于标记作为提示词的文本；\n 如果没有 prompt 标签则默认为仅一条提示词,会产生三条提示词，每个颜色各一条；\n prompt 标签用于标记作为提示词的文本；\n 如果没有 prompt 标签则默认为仅一条提示词,会产生三条提示词，每个颜色各一条；\n prompt 标签用于标记作为提示词的文本；\n 如果没有 prompt 标签则默认为仅一条提示词,これにより、各色に1つずつ、3つのプロンプトが生成されます。プロンプトタグは、プロンプトとして使用されるテキストをマ`クするために使用されます。プロンプトタグが存在しない龊悉稀プロンプトは1つだけとみなされます。
ControlNet v1.1.194,扩散控制网络(ControlNet),,,
ControlNet v1.1.158,扩散控制网络(ControlNet),,,
Arbitrary arguments in variable=value format ? verbatim,,,,涫=の形式の任意の引数 ? verbatim
Extra text to add before <...> when adding extra network to prompt,"添加附加网络调用参数时，在""<...>""前自动填入的附加文本",添加额外的网络进行提示时，<...> 前的额外文本,添加额外的网络进行提示时，<...> 前的额外文本,追加ネットワ`クをプロンプトに付け加えるH、 <...> の前に追加するテキスト
Show image creation progress every N sampling steps. Set to 0 to disable. Set to -1 to show after completion of batch.,每 N 个采样迭代步数显示图像生成进度。设置 0 禁用，设置 -1 使预览在批量生成完成之后再显示,每 N 个采样迭代步数显示图像生成进度。设置 0 禁用，设置 -1 使预览在批量生成完成之后再显示,每 N 个采样迭代步数显示图像生成进度。设置 0 禁用，设置 -1 使预览在批量生成完成之后再显示,
"Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.",,,,入力プロンプトに基づき、送信された入力画像のハイライト部分を生成する。ト`クナイザ`エクステンションとMみ合わせて使用します。しくはReadmeをごEください。
Cancel training.,取消训练,取消训练,取消训练,
reroll,,,,再抽x
ControlNet v1.1.286,扩散控制网络(ControlNet),,,
Token Merging - Merge cross-attention,合并关交叉注层(cross-attention),,,
Concepts,,,,コンセプト
Include confident of tags matches in results,将置信度作为权重写入生成的Tags (不推荐勾选),将置信度作为权重写入生成的Tags (不推荐勾选),将置信度作为权重写入生成的Tags (不推荐勾选),マッチしたタグの信m度をY果に含める
Get Civitai Model Info by Model Page URL,使用 链接 为指定模型获取 Civitai 信息,,,
Upper Arm,大臂,,,
Show Textbox,显示文本框,显示文本框,显示文本框,
Caption File Ext,图片注释文件拓展名,,,キャプションファイル子
After,,,,後
Source Path,,,,ソ`スのパス
tp_papago,,,,tp_papago
"Optional, uses selected model's directory if blank",可选，若留空则使用默认目录,可选，若留空则使用默认目录,可选，若留空则使用默认目录,
AddNet UNet Weight 1,[附加网络] UNet 权重 1,[可选附加网络] UNet 权重 1,[可选附加网络] UNet 权重 1,UNetの重み 1(AddNet)
Step method,步进方法 (梯度模式),步进方法 (梯度模式),步进方法 (梯度模式),
You probably want this to be 'fp16'.,如果你想要设置为半精度(fp16)的话,如果你想要设置为半精度(fp16)的话,如果你想要设置为半精度(fp16)的话,
Only Selected Tags,仅已选择的 Tag,,,xkしたタグのみ
Noise scheduler,,,,ノイズスケジュ`ラ
Overwrite if output file exists,若输出文件已存在时，覆写该文件,,,出力ファイルが存在する龊悉仙き
"Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.",随机显示一位艺术家或某艺术流派的图像，选择后会显示更多该艺术家或艺术流派的图像。所以你不用担心在创作时难以选择出想要的艺术风格,随机显示一位艺术家或某艺术流派的图像，选择后会显示更多该艺术家或艺术流派的图像。所以你不用担心在创作时难以选择出想要的艺术风格,随机显示一位艺术家或某艺术流派的图像，选择后会显示更多该艺术家或艺术流派的图像。所以你不用担心在创作时难以选择出想要的艺术风格,ア`ティストのジャンルや芸gジャンルの典型的なスタイルの写真をランダムに表示し、xkした後にそのア`ティストやジャンルのより多くの画像が表示されます。 ゆえに、あなたが作するときに正しいスタイルのア`トをxkするのがどれほどyしいか心配する必要はありません。
Random choices,随机选择,随机选择,随机选择,ランダムxk
Hybrid Video Schedules,,,,ハイブリッドビデオスケジュ`ル
Copy metadata to other models in directory,将元数据复制到其他目录中的模型,将元数据复制到其他目录中的模型,将元数据复制到其他目录中的模型,ディレクトリ内の他のモデルにメタデ`タをコピ`する
lets you only match every N frames,,,,Nフレ`ムごとにマッチングさせます。
grid_rows,,宫格行数,宫格行数,
OUT06,,输出层06,输出层06,
"For inpainting, save a masked composite",局部重绘时，保存复合蒙版图像,,局部重绘时，保存一份复合蒙版,inpaintingで、マスクされた合成w所を保存する
cs,,,,cs
How many times to repeat processing an image and using it as input for the next iteration,重复处理图像并用作下次迭代输入的次数,重复处理图像并用作下次迭代输入的次数,重复处理图像并用作下次迭代输入的次数,
SwinIR_4x,SwinIR 4x,SwinIR 4x,SwinIR 4x,
(S6) Inter-Method,,(S6) 插值方法,(S6) 插值方法,
Saved main elements,,,,保存されたメイン要素
DPM2 Karras,DPM2 Karras,,,DPM2 Karras
Start batch process,开始批处理流程,,开始批量处理,
Norm type,,,,ノルムNe
ControlNet v1.1.282,扩散控制网络(ControlNet),,,
Please always keep values in math functions above 0.,,,,数学v数のは常に0以上にしてください。
persistent cond cache,,,持久化条件缓存,
"Provides connection to Discord RPC, showing a fancy table in the user profile.",,,,Discord RPCへの接Aを提供し、ユ`ザ`プロファイルにファンシ`テ`ブルを表示します。
A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.,,,,通常のvid2vidのrg的整合性と柔性を改善しようとするvideo2videoスクリプトです。
macchiato,macchiato/玛奇朵（深色）,macchiato/玛奇朵（深色）,macchiato/玛奇朵（深色）,
stable-diffusion-webui-inspiration,灵感,灵感,灵感,stable-diffusion-webui-inspiration
Text,文本,文本,文本,文字列
ID input,ID 输入,ID 输入,ID 输入,ID入力
ControlNet,扩散控制网络(ControlNet),,,ControlNet
hy,,,,hy
Get 1 Model Info from Civitai,从输入的 Civitai网址 获取上述选中的模型信息,,,
"Maximum image size, in megapixels",最大图像尺寸（单位：百万像素，高于此值会被认定为DoS攻击并报错，运行X/Y/Z表格脚本时请尽量设置为一个大于1000的值）,,最大图片尺寸，单位是百万像素,最大画像サイズ (メガピクセルg位)
SubSeed,,,,サブシ`ド
Compatibility,兼容性设置,兼容性,兼容性,互Q性
Apply Logo,应用 Logo,应用 Logo,应用 Logo,
sd-webui-controlnet,扩散控制网络(ControlNet插件),ControlNet 插件,ControlNet 插件,sd-webui-controlnet
mr,,,,mr
color mode,,,,カラ`モ`ド
Only show models that have/don't have user-added metadata,仅显示具有/无有用户自行添加元数据的模型,仅显示(有/无)用户自行添加元数据的模型,仅显示(有/无)用户自行添加元数据的模型,ユ`ザ`が追加したメタデ`タがある/ないモデルのみを表示する
(C1) Thertiary,,(C1) 第三,(C1) 第三,
Unet Learning rate,,,,Unet 学率
"Range of stepped values (min, max, step)","含步幅的随机范围 (最小, 最大, 步幅)","含步幅的随机范围 (最小, 最大, 步幅)","含步幅的随机范围 (最小, 最大, 步幅)",ステップの (最小、最大、ステップ幅)
model_B,模型B,,,
I know what I am doing.,开启高级设置（慎用）,我知道我在做什么。,我知道我在做什么。,自分が何をしているか分かっています。
youtube,,,,youtube
"(""When searched"" option will only show the item when the search string has 4 characters or more)",,,"""当被搜索时""选项要求搜索时至少4个字符匹配",
Erase BG,移除背景,,,
https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git,,,,https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients.git
file,,,,file
Reconstruct prompt from existing image and put it into the prompt field.,从现有的图像中重构出提示词，并将其放入提示词的输入文本框,从现有的图像中重构出提示词，并将其放入提示词的输入文本框,从现有的图像中重构出提示词，并将其放入提示词的输入文本框,既存の画像からプロンプトを再Bし、プロンプト冥朔从长筏蓼埂
Stable Diffusion Plugin,,,,Stable Diffusionのプラグイン
to (full path),,,到（完整路径）,to (full path)
Current Model,当前模型,,,
Attention Map,,,,アテンションマップ
Subject class to crop (leave blank to auto-detect),要裁剪的主体类别(Subject class)（留空以自动检测）,要裁剪的主体类别(Subject class)（留空以自动检测）,要裁剪的主体类别(Subject class)（留空以自动检测）,クロップするサブジェクトクラス（自食訾工龊悉峡瞻驻韦蓼蓼摔筏皮ださい）
"Seamless Image Fusion, along with vram efficient tiled vae script.",,无缝图像融合，配合显存(VRAM)优化过的 分块 VAE 脚本,无缝图像融合，配合显存(VRAM)优化过的 分块 VAE 脚本,シ`ムレスな画像融合、Vram柯胜瘟激ぅ骏ぅ胱搐VAEスクリプトと共に
# Training Epochs,训练多少期(Epochs),训练多少期(Epochs),训练多少期(Epochs),
Clear tag filters,重置 Tag 筛选条件,,,タグフィルタ`をクリア
"Maximum number of samples, used to determine which folders to skip when continue running the create script",,,,作成スクリプトのg行をAけるときにスキップするフォルダをQ定するために使用されるサンプルの最大数
Character Tags,,角色标签(Tags),角色标签(Tags),
Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.,,,,O定可能なドロップダウンを追加すると、txt2img および img2img タブの UI プリセットO定を涓できます。
KaimingNormal,Kaiming 正态,Kaiming 正态,Kaiming 正态,He正分布
Load from JSON,从 JSON文件 加载,从 JSON文件 加载,从 JSON文件 加载,JSONからiみzむ
ControlNet v1.1.129,扩散控制网络(ControlNet),,,
seg_ofade20k,语义分割（seg 模型，OneFormer 算法，ADE20k 协议）,,语义分割（seg，OneFormer 算法，ADE20k 协议）,
AddNet Weight 3,[附加网络] 权重 3,[可选附加网络] 权重 3,[可选附加网络] 权重 3,重み 3(AddNet)
"The difference between the last two models will be added to the first. Requires three models; A, B and C. The result is calculated as A + (B - C) * M",将模型B与C的差值添加到模型A，需要同时填入模型A、B和C，公式：A + (B-C)×M，倍率(M)为添加的差值比例,将模型B与C的差值添加到模型A，需要同时填入模型A、B和C，公式：A + (B-C)*M，倍率(M)为添加的差值比例,将模型B与C的差值添加到模型A，需要同时填入模型A、B和C，公式：A + (B-C)*M，倍率(M)为添加的差值比例,
ControlNet-2,控制网络-2,,,
Set,导入,设为,设为,
norm,,,,
Basic,基础,,,基本
String to include before the filename ? pre,,,,ファイル名の前に含める文字列 ? pre
Enable clip model change. This will be triggered from next model changes.,,,,Clipモデルの涓を有郡摔筏蓼埂￥长欷稀⒋韦违猊钎毪涓からトリガされます。
note,备注,,,
Tile size for ESRGAN upscalers.,,,ESRGAN放大时的潜变量分块（tile）大小,
Cond.fix: Low,修复时调节：小,修复时调节：小,修复时调节：小,Cond.fix: 低
auto-sd-paint-ext,画图工具扩展,画图工具扩展,画图工具扩展,auto-sd-paint-ext
"For negative prompts, please write your positive prompt, then --neg ugly, text, assymetric, or any other negative tokens of your choice. OR:",,,,"ネガティブプロンプトについては、まず正のプロンプトをき、次に --neg ugly, text, assymetric、または他のxkしたネガティブト`クンを述してください。または："
"Determines how little respect the algorithm should have for image's content. At 0, nothing will change, and at 1 you'll get an unrelated image. With values below 1.0, processing will take less steps than the Sampling Steps slider specifies.",决定算法对图像内容的影响程度。设置 0 时，什么都不会改变，而在 1 时，你将获得不相关的图像。\n值低于 1.0 时，处理的迭代步数将少于“采样迭代步数”滑块指定的步数,决定算法对图像内容的影响程度。设置 0 时，什么都不会改变，而在 1 时，你将获得不相关的图像。\n值低于 1.0 时，处理的迭代步数将少于“采样迭代步数”滑块指定的步数,决定算法对图像内容的影响程度。设置 0 时，什么都不会改变，而在 1 时，你将获得不相关的图像。\n值低于 1.0 时，处理的迭代步数将少于“采样迭代步数”滑块指定的步数,アルゴリズムが画像の内容をどの程度oするかをQ定します。0にすると全く浠せず、 1にするとovSな画像になります。1.0未氦では、スライダ`で指定したサンプリングステップ数よりも少ないステップ数でI理が行われます。
read metadata,读取元数据,,,
Travel mode,变迁模式,变迁模式,变迁模式,
seed_schedule,,种子调度(seed_schedule),种子调度(seed_schedule),
All,全部,全部,全部,All
Denoising strength (Inpaint),重绘幅度 (局部重绘),重绘幅度 (局部重绘),重绘幅度 (局部重绘),
Mask sorting method ? mask_sort_method,,,,マスクのソ`ト方法 ? mask_sort_method
Renoise kernel size,Renoise 内核尺寸,,,
Math keyframing explanation docs.google.com/document/d/1pfW1PwbDIuW0cv-dnuyYj1UzPqe23BlSLTJsqazffXM/edit?usp=sharing,,数学关键帧(Math keyframing)解释 docs.google.com/document/d/1pfW1PwbDIuW0cv-dnuyYj1UzPqe23BlSLTJsqazffXM/edit?usp=sharing,数学关键帧(Math keyframing)解释 docs.google.com/document/d/1pfW1PwbDIuW0cv-dnuyYj1UzPqe23BlSLTJsqazffXM/edit?usp=sharing,
Search...,搜索...,搜索...,搜索...,仕...
unsorted,,,,Kべ替えない
Randomize Height,随机化 高度,随机化 高度,随机化 高度,
IN_A_06,,模型A 输入层06,模型A 输入层06,
Abysz LAB,,,,Abysz LAB
Syntax cheatsheet,,,,文チ`トシ`ト
Stretch pixels at border,延伸边缘的像素,延伸边缘的像素,延伸边缘的像素,境界のピクセルを冥菠
Tag filename,词库文件,词库文件,词库文件,タグのファイル名
The rate at which the model learns. Default is 0.000005. Use a lower value like 0.000002 or 0.000001 for more complex subjects...like people.,模型的学习速率。默认为 0.000005。对于更复杂的主体......比如人物，使用较低的值，如 0.000002 或 0.000001,模型的学习速率。默认为 0.000005。对于更复杂的主体......比如人物，使用较低的值，如 0.000002 或 0.000001,模型的学习速率。默认为 0.000005。对于更复杂的主体......比如人物，使用较低的值，如 0.000002 或 0.000001,
Allowed categories for random artists selection when using the Roll button,使用抽选艺术家按钮时将会随机的艺术家类别,使用抽选艺术家按钮时将会随机的艺术家类别,使用抽选艺术家按钮时将会随机的艺术家类别,
RIFE,,,,RIFE
Search for wildcards,使用通配符,使用通配符,使用通配符,ワイルドカ`ドを仕
(O8) Output ckpt Name,,(O8) ckpt 输出名,(O8) ckpt 输出名,
text2video,,,,text2video
Readable Model Info file,使用高可读性模型信息文件,,,
Swap Prompt,,,,プロンプトの入れ替え
"img2pez: Optimize a hard prompt using the PEZ algorithm and CLIP encoders, AKA Hard Prompts Made Easy.",,,,img2pez: PEZアルゴリズムとCLIPエンコ`ダ`を使用して、ハ`ドプロンプトを最m化することで、ハ`ドプロンプトの作成がgになる、とも呼ばれる。
Resizing objective,,,调整的目标,サイズ涓の目
Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models,,,,散モデルの高速サンプリングのためのy合予y器a正フレ`ムワ`ク
Resolution,分辨率,分辨率,分辨率,解像度
Multiplier,权重,,,
Matching value ? str,,,,一致する ? str
Training Wizard (Person),训练配置器 (人物),训练配置器 (人物),训练配置器 (人物),トレ`ニングウィザ`ド (人)
lineart,线稿提取（lineart 模型）,,,
Preview amount. 0 = Quick shoot,,,,Preview amount. 0 = Quick shoot
Install from URL,从网址安装,从网址安装,从网址安装,URLからインスト`ル
Enable ExtraNetwork sidebar,将 附加网络面板 移动到 侧边栏,,,
Mask overlay blur,,,,マスクオ`バ`レイのぼかし
Humans Masking,,,,マスキングしている人
vertical split num,垂直分区数量,,,
artists.csv,,,,artists.csv
normal_map,法线贴图（Normal map）,法线贴图（Normal map）,法线贴图（Normal map）,normal_map
Generate layout for batch process,生成批量处理的图片布局,,开始拆分（批量）,
Key word,,,,キ`ワ`ド
hires_denoising_strength,,,,高解像度ノイズ除去度
Loops,迭代次数,迭代次数,迭代次数,ル`プ数
Use mid-layer control on highres pass (second pass),进行高分辨率修复时使用中间层控制(mid-control),进行高清修复时使用中间层控制(mid-control),进行高清修复时使用中间层控制(mid-control),
Minimum Prior Loss Weight,,,,最小の正t化のp失の重み
runwayml/stable-diffusion-v1-5,,,,runwayml/stable-diffusion-v1-5
Attention Heatmap,,,,ヒ`トマップ
translate prompt.,,,,プロンプトを翻U
Prompt template file,提示词模版文件,提示词模版文件,提示词模版文件,プロンプトテンプレ`トファイル
Type,区域类型,,类型,N
ControlNet v1.1.4,扩散控制网络(ControlNet),,,
after,,,,後
"Resizes image to this width. If 0, width is inferred from either of two nearby sliders.",将宽度调整到此值，0表示根据目标高度或放大倍率自适应调整,将宽度调整到此值，0表示根据目标高度或放大倍率自适应调整,将宽度调整到此值，0表示根据目标高度或放大倍率自适应调整,画像をこの幅にリサイズする。0 の龊稀⒎は近くにある２つのスライダ`のいずれかから推定される。
Open config file...,打开配置文件,,,
need input your want to translate,输入需要被翻译的 UI界面文本,,,
ads,含广告,含广告,含广告,诟
"Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\nDon't forget to increase the 'Batch count'/'Batch size' value accordingly.\n	\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.",组合生成从给定的字符串中生成所有可能的提示词，而非随机其中一个\n'I {love|hate} {New York|Chicago} in {June|July|August}' 总共会生成 12 句提示词变体\n别忘记相应地增加 “批次（Batch count）” 和 “批量（Batch size）” 值\n	\n“随机种子” 的值只用于第一图像，可在 “高级选项” 中的 “固定随机种子” 修改此行为,组合生成从给定的字符串中生成所有可能的提示词，而非随机其中一个\n'I {love|hate} {New York|Chicago} in {June|July|August}' 总共会生成 12 句提示词变体\n别忘记相应地增加 “批次（Batch count）” 和 “批量（Batch size）” 值\n	\n“随机种子” 的值只用于第一图像，可在 “高级选项” 中的 “固定随机种子” 修改此行为,组合生成从给定的字符串中生成所有可能的提示词，而非随机其中一个\n'I {love|hate} {New York|Chicago} in {June|July|August}' 总共会生成 12 句提示词变体\n别忘记相应地增加 “批次（Batch count）” 和 “批量（Batch size）” 值\n	\n“随机种子” 的值只用于第一图像，可在 “高级选项” 中的 “固定随机种子” 修改此行为,
"For inpainting, include the greyscale mask in results for web",局部重绘时，在结果中一并显示灰度蒙版,,局部重绘时，在输出结果中显示灰度蒙版,inpaintingで、WebUI上のY果にグレ`スケ`ルマスクを表示する
Tiled Diffusion,分块扩散(Tiled Diffusion)（仅超大图生效，尺寸过小时自动关闭）,,,
Number of columns on the page,每页列数,每页列数,每页列数,ペ`ジ上の列数
Disable negative prompt,禁用负面提示词,禁用反向提示词,禁用反向提示词,
Generate Skeleton/Depth/Normal/Canny Map,生成 OpenPose + 手脚部位的深度图、法线贴图、硬边缘检测图,,,
Add emphasis to a randomly selected keyword in the prompt.,在提示词中随机选择一个关键字加上强调符,在提示词中随机选择一个关键字加上强调符,在提示词中随机选择一个关键字加上强调符,プロンプトの中からランダムにxばれたキ`ワ`ドに{を加えます。
upperkebabcase,,,,アッパ`ケバブケ`ス
- Fullscreen mode,,,- 全屏模式,
Additional Generation Info,附加生成信息,,额外的生成信息,追加の生成情
Seed behavior,,,,シ`ドの幼
ControlNet v1.1.107,扩散控制网络(ControlNet),,,
models,模型相关,模型,模型,モデル
Comp mask auto contrast cutoff high schedule,,,,コンポジットマスクの自鹰偿螗去楗攻趣紊舷蕙攻饱弗濠`ル
Loaded Model:,,,,ロ`ドされたモデル:
Use local groundingdino to bypass C++ problem,,,使用本地groundingdino来绕过C++编译问题,
tk,,,,tk
Half tile offset pass + intersections,,,,Half tile offset pass + intersections
Frames per second,每秒多少帧,每秒多少帧,每秒多少帧,フレ`ム/秒
[ControlNet] Pre Threshold A,[ControlNet] 预处理器 阈值A,[ControlNet] 预处理器 阈值A,[ControlNet] 预处理器 阈值A,[ControlNet] 事前しきい A
Descending,降序,,,降
Output type,,输出类型,输出类型,
https://github.com/p1atdev/stable-diffusion-webui-blip2-captioner,,,,https://github.com/p1atdev/stable-diffusion-webui-blip2-captioner
Stop At last layers of CLIP model,在 CLIP 模型的最后哪一层停下 (Clip skip),在 CLIP 模型的最后哪一层停下 (Clip skip),在 CLIP 模型的最后哪一层停下 (Clip skip),
Waves color,状态栏颜色,,,
Hypernetwork-Monkeypatch-Extension,,,,Hypernetwork-Monkeypatch-Extension
Strength schedule,,,,度のスケジュ`ル
Image Init,,,,画像の初期
Number of times to repeat the content ? int,,,,コンテンツをRり返す回数 ? int
Pykrita Folder Location,,,,ログ出力先フォルダの鏊
Prompt matrix,提示词矩阵,提示词矩阵,提示词矩阵,プロンプトマトリックス
Minimum pixels of at least one dimension ? target,,,,最低でも一つの次元の最小ピクセル数 <unk> タ`ゲット
stable-diffusion-webui-two-shot,画面分区(Latent Couple/two-shot)插件,潜变量成对(双人特写),潜变量成对(双人特写),stable-diffusion-webui-two-shot
Weight sum:A*(1-alpha)+B*alpha,加权和（ A×(1-α) + B×α ）,,,
VAE,,,,VAE
Add,添加,添加,添加,追加
openpose_hand,姿态检测（openpose 模型，OpenPose 算法，姿态+手部）,OpenPose 姿态及手部检测（Openpose hand）,姿态检测（OpenPose 算法，身体+手部）,openpose_hand
Custom weight per option ? _weighted,,,,オプションごとのカスタムウェイト（重み） <unk> _weighted
SKip NSFW Preview images,跳过色情预览图,跳过成人内容预览图,跳过成人内容预览图,
Converted checkpoints will be saved in your,转化换后的模型(checkpoint)将会保存在,转化换后的模型(checkpoint)将会保存在,转化换后的模型(checkpoint)将会保存在,
(A2) Primary,,(A2) 主要,(A2) 主要,
Add background image,添加背景参考图片,添加背景图片,添加背景图片,
This fork for auto1111's webui github.com/deforum-art/deforum-for-automatic1111-webui,,此克隆用于 auto1111 的 webui github.com/deforum-art/deforum-for-automatic1111-webui,此克隆用于 auto1111 的 webui github.com/deforum-art/deforum-for-automatic1111-webui,
Source embedding to convert,用于转换的源 Embedding,用于转换的源 Embedding,用于转换的源 Embedding,
lowercase,,,,小文字
Max number of dataset folders to show,要显示的最大数据集文件夹数,要显示的最大数据集文件夹数,要显示的最大数据集文件夹数,表示するデ`タセットフォルダの最大数
Caption max length,,,,キャプションの最大L
Corruption Refresh:,,,,Corruption Refresh:
Min-max,,,从小到大,
XYZ plot,X/Y/Z 图表,,,
Frame Interpolation will *not* run if any of the following are enabled: 'Store frames in ram' / 'Skip video for run all'.,,,,フレ`ムagは、以下のいずれかが有郡摔胜盲皮い龊悉g行されません：「フレ`ムをRAMに保存する」/「全てg行するためにビデオをスキップする」。
ht,,,,ht
queue:,,,队列:,
"Backup original text file (original file will be renamed like filename.000, .001, .002, ...)",备份原始文本文件（原始文件将重命名为 <文件名>.000、.001、.002…）,,,"元のテキストファイルをバックアップします (元のファイル名は次のように涓 filename.000, .001, .002, ...)"
template: This is used by the Wizard to instantiate a custom template UI. It is bypassed by the normal shortcode parser.,,,,テンプレ`ト: これは、ウィザ`ドによってカスタムテンプレ`トUIをインスタンス化するために使用されます。通常のショ`トコ`ドパ`サによってバイパスされます。
cosineA,余弦A（仅“加权和”可用）,,,
Training Steps Per Image (Epochs),,,,1つの画像あたりのトレ`ニングステップ数（エポック数）
Enable uploading manually created mask to SAM.,,,启用手动上传蒙版,
Current Booru,,当前的 Booru,当前的 Booru,
sum Twice:(A*(1-alpha)+B*alpha)*(1-beta)+C*beta,二次求和（ (A×(1-α) + B×α)×(1-β) + C×β ）,,,
UNet Weight 4,UNet 权重 4,UNet 权重 4,UNet 权重 4,UNetの重み 4
Page Number,,页数,页数,
[hash:<algorithms>],,[hash:<算法>],[hash:<算法>],[hash:<algorithms>]
NOTE,,,,メモ
Output Caption Extension,,,,出力キャプションの子
"If an image is too large, crop it from the center.",如果图像太大，裁掉边缘,如果图像太大，裁掉边缘,如果图像太大，裁掉边缘,
Top-p (Nucleus),,,,Top-p (Nucleus)
Mixture of Diffusers,混合扩散(Mixture of Diffusers),,,
Quick start,,,,Quick Start
ControlNet v1.1.167,扩散控制网络(ControlNet),,,
controlnet m2m,扩散控制网络-视频转绘,ControlNet-视频转绘,ControlNet-视频转绘,
Gradient Checkpointing,梯度进度记录(Gradient Checkpointing) - 以时间换显存,梯度进度记录(Gradient Checkpointing) - 以时间换显存,梯度进度记录(Gradient Checkpointing) - 以时间换显存,Gradient Checkpointing
ControlNet v1.1.279,扩散控制网络(ControlNet),,,
Colorerroractive,Colorerroractive,,,
Check for updates,检查更新,检查更新,检查更新,アップデ`トを_J
from_img2img_instead_of_link,,,,from_img2img_instance_of_link
lineart_standard (from white bg & black line),线稿提取（lineart 模型，针对白底线稿）,,线稿提取-标准（lineart_standard，处理白底线稿）,
Thai localization,,,,タイZ翻U
Composite video with previous frame init image in,,,,前のフレ`ムの初期化画像を使用してビデオを合成する
Classification Steps,分类(Classification)迭代步数,分类(Classification)迭代步数,分类(Classification)迭代步数,分のステップ
cy,,,,cy
PNG Info,图片信息,图片信息,图片信息,PNG内の情螭虮硎
Region 6,区域 6,区域 6,区域 6,
sd-webui-tunnels,,,,sd-webui-tunnels
ControlNet is more important,以 扩散控制网络干涉 为主,,更关注ControlNet,
https://github.com/hnmr293/sd-webui-cutoff.git,,,,https://github.com/hnmr293/sd-webui-cutoff.git
ControlNet - 2,扩散控制网络(ControlNet) - 2,,,
Move File(s),移动文件,,,ファイルを移
wd14-swinv2-v2,,,,wd14-swinv2-v2
Final denoising strength,,,,最K的なノイズ除去度
it_IT Localization,,,,it_IT Localization
deepbooru: score threshold,,,deepbooru: 得分阈值,
Resblock,,,,残差ブロック
Ctrl+up/down word delimiters,,,Ctrl + ↑/↓功能识别的分隔符,
Concept 4,,,,コンセプト 4
Variable to test against ? verbatim,,,,テスト象の涫 ? verbatim
Negative prompt for hires fix pass.\nLeave empty to use the same negative prompt as in first pass.,,,高清修复过程-反向提示词\n留空则使用和修复前同样的反向提示词,
mediapipe_face,姿态检测（openpose 模型，MediaPipe 算法，仅面部）,,面部检测（MediaPipe 算法）,
veryslow,,,,とてもWい
no metadata(not safetensors),无元数据（非 safetensors 格式）,,,
Drop Image Here,拖拽图像到此处,拖拽图像到此处,拖拽图像到此处,ここに画像をドロップ
"Tile overlap, in pixels for SwinIR. Low values = visible seam.",SwinIR 的图块重叠(Tile overlap)像素。较小时可见接缝,SwinIR 的图块重叠(Tile overlap)像素。较小时可见接缝,SwinIR 的图块重叠(Tile overlap)像素。较小时可见接缝,SwinIRのタイルの重}部分のピクセル数。少なくするとつなぎ目がえやすくなる。
Error,错误,错误,错误,エラ`
Color coherence,,,,色の一性
batch_size,,,,バッチサイズ
Debug level,,,调试级别,
Prompt,提示词,提示词,提示词,プロンプト
Note: Each model will download between 300mb and 1.4gb of data on first use.,,,,注: 各モデルは、初期使用rに300MB ~ 1.4GBのデ`タをダウンロ`ドします
Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.,,,,解像度512の深度画像モデルで廊下を生成します。他のモデル/解像度で幼鳏工毪瑜Δ苏{整することができます。
Minimum Score for DeepDanbooru Tags,,,,DeepDanbooruタグの最小スコア
Weight 3,权重 3,权重 3,权重 3,重み 3
Cancel,取消,取消,取消,取消
ControlNet v1.1.154,扩散控制网络(ControlNet),,,
color_coherence,,,,ColorCoherenceVectorアルゴリズム
----not work----,----以下内容无法被翻译，Bug----,----以下内容无法被翻译，Bug----,----以下内容无法被翻译，Bug----,
Send to img2img:, >> 图生图（按钮与插件面板模型1-5对应）,将模型发送到图生图页面\n（数字按钮1-5对应模型1-5）,将模型发送到图生图页面\n（数字按钮1-5对应模型1-5）,Img2Imgに送:
Delimiter string between outputs ? _sep,,,,出力gの区切り文字列 ? _sep
"Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.",,,,画像C能。ブレンド、レイヤ`、色{、色{、スケッチエフェクト、基本的なピクセル化が可能です。
override:,,,,上き:
Use LORA,,,,LORAを使う
Write raw prompt to image,,,,画像にそのままのプロンプトをく
Emphasis: use (text) to make model pay more attention to text and [text] to make it pay less attention,强调符：使用 (文字) 使模型更关注该文本，使用 [文字] 使其关注被减少,强调符：使用 (文字) 使模型更关注该文本，使用 [文字] 使其关注被减少,强调符：使用 (文字) 使模型更关注该文本，使用 [文字] 使其关注被减少,{: (text)とするとモデルはtextをよりくQい、[text]とするとモデルはtextをより弱くQいます。
X,,,,X
tp_myMemory,,,,tp_myMemory
"Original Text = ""A, B, C, D, E""?Common Tags = ""A, B, D""?Edit Tags = "", X, ""","　　原始文本：“A, B, C, D, E”，共有 Tag：“A, B, D”，编辑为：“,X,”",,,"元のテキスト= ""A、B、C、D、E"" 共通のタグ= ""A、B、D"" タグを集= "", X、"""
Batch count,生成批次,生成批次,生成批次,バッチ回数
Save & Restart,保存,保存并重启,保存并重启,
invert (from white bg & black line),反色处理（仅针对 白色背景黑色线条 的图像）,,反色（针对白色背景、黑色线条的图像）,
Resize,缩放比例,缩放比例,缩放比例,倍率
https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git,,,,https://github.com/AUTOMATIC1111/stable-diffusion-webui-pixelization.git
Content,,,,内容
Show hidden directories,,,显示隐藏的文件夹,
Train an embedding or Hypernetwork; you must specify a directory,,,,EmbeddingまたはHypernetworksをします。ディレクトリを指定する必要があります
Add to / replace in saved directroies,从已保存的目录中 添加/替换,,,
portrait-n,,,,肖像画-n
"Using pre-trained models, produce pixel art out of images in the extras tab.",,,,事前に学させたモデルを使って、extrasタブの画像からピクセルア`トを作成します。
Preprocess images,图像预处理,图像预处理,图像预处理,画像の前I理
Sampling mode,,,,サンプリングモ`ド
"Changes are not applied to the text files until the ""Save all changes"" button is pressed.",在按下“保存所有更改”按钮之前，更改不会应用于文本文件,,,「全ての涓を保存」ボタンを押すまで、涓はテキストファイルにm用されません。
Expected encoding ? _encoding,,,,Expected encoding <unk> _encoding
Send pose to /openpose_editor_index for edit.,,,打开姿态编辑器进行修改,
Always discard next-to-last sigma,始终舍弃倒数第二个sigma,始终舍弃倒数第二个sigma,始终舍弃倒数第二个sigma,常に最後から一つ手前のsigmaを破する
Manual Class Generation,,,,手婴扦违ラス生成
Use CPU for SAM,,,使用CPU计算SAM,
How many results to load at once,单次加载的结果数量,单次加载的结果数量,单次加载的结果数量,一度にiみzむタグの数
ControlNet v1.1.268,扩散控制网络(ControlNet),,,
Embeddings: loaded,嵌入式模型(Embeddings):已加载,嵌入式(Embeddings):已加载,嵌入式(Embeddings):已加载,
img2img alternative test,图生图的另一种测试,图生图的另一种测试,图生图的另一种测试,img2img alternative test
Colorprimaryborder,Colorprimaryborder,,,
nsp,,,,nsp
Grid margins (px),宫格图边框（像素）,宫格图边框（像素）,宫格图边框（像素）,グリッドのg隔 (px)
Merge to Checkpoint,将LoRA合并到ckpt,,,
Created at:,保存时间：,,创建于,
most_similar,最相似,最相似,最相似,
Compute on,,,,算
"'add_soundtrack' and 'soundtrack_path' aren't being honoured in ""Interpolate an existing video"" mode. Original vid audio will be used instead with the same slow-mo rules above.",,,,「既存のビデオをagする」モ`ドでは、 'add_soundtrack'および'soundtrack_path'は尊重されません。代わりに、元のビデオのオ`ディオが上と同じスロ`モ`ションのル`ルで使用されます。
Light,,,,ライト
pa,,,,pa
tp_iflyrec,,,,tp_iflyrec
https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git,,,,https://github.com/space-nuko/a1111-stable-diffusion-webui-vram-estimator.git
Run Python code. Advanced user only. Must run program with --allow-code for this to work,运行 Python 代码。仅限老手使用。必须以 --allow-code 来开启程序，才能使其运行,运行 Python 代码。仅限老手使用。必须以 --allow-code 来开启程序，才能使其运行,运行 Python 代码。仅限老手使用。必须以 --allow-code 来开启程序，才能使其运行,
Translation filename,词库翻译文件,词库翻译文件,词库翻译文件,ファイル名の翻U
Kohya-ss Additional Networks,,,,Kohya-ss Additional Networks
Prepend value(s) to the array ? _prepend,,,,配列にを先^に追加する ? _prepend
to, 调整至 , 调整至 , 调整至 ,
Multiplier for extra networks,附加网络默认倍率,附加网络默认倍率,附加网络默认倍率,追加ネットワ`クのための\算
tp__qqFanyi,,,,tp__qqFanyi
"Due to the limitation of Segment Anything, when there are point prompts, at most 1 box prompt will be allowed; when there are multiple box prompts, no point prompts are allowed.",由于 Segment Anything 的限制，当有提示点时，最多允许1个文本提示；当有多个文本提示时，不可使用提示点。,,由于分割万物（Segment Anything）的局限性，如果使用了多个包围盒标注，提示词将不起作用；如果你想要你的提示词生效，最多只能使用一个包围盒,
Use v2 CLIP Model,,,,V2 CLIP Modelを使用
interactive splines and Bezier curves,,,,型のスプラインとベジェ曲
Ref image (for conviently locate regions),参考图(方便快速区域定位),,参考图（用于方便定位区域）,
portrait-digipa-high-impact,,,,肖像画-digipaハイインパクト
Embeddings: skipped,嵌入式模型(Embeddings):已跳过,嵌入式(Embeddings):已跳过,嵌入式(Embeddings):已跳过,
"When using [filewords], this is the subject to use when building prompts.",,,,[filewords] を使用する龊稀プロンプトをBするときに使用するサブジェクトです。
I love red roses,I love red roses,,,I love red roses
Restart debug,,,重启调试,
https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git,,,,https://github.com/innightwolfsleep/stable-diffusion-webui-randomize.git
Simplified Chinese localization,简体中文本地化,简体中文本地化,简体中文本地化,
subseed,,差异随机种子,差异随机种子,
Native Diffusers,,,,Native Diffusers
Remove from saved directories,从已保存的目录中 移除,,从已保存的目录移除,保存したディレクトリから削除
Save to Presets,保存为预设,,,プリセットに保存
Threshold (Use only when basis is absolute),,,,しきい (基胜~の龊悉韦呤褂)
Unload,卸载,,,アンロ`ド
Colorfilltertiary,Colorfilltertiary,,,
Slow-Mo X,,,,スロ`モ`ションX
repeat,,,,Rり返し
Time taken:,,,,U^rg
array,,,,配列
"Before your text is sent to the neural network, it gets turned into numbers in a process called tokenization. These tokens are how the neural network reads and interprets text. Thanks to our great friends at Shousetsu for inspiration for this feature.",在你的文本被发送到神经网络之前，它在一个称为词元化(tokenization)的过程中被转化为数字。这些词元(tokens)是神经网络阅读和解释文本的方式。感谢我们伟大的朋友 Shousetsu 为这个功能带来的灵感,在你的文本被发送到神经网络之前，它在一个称为词元化(tokenization)的过程中被转化为数字。这些词元(tokens)是神经网络阅读和解释文本的方式。感谢我们伟大的朋友 Shousetsu 为这个功能带来的灵感,在你的文本被发送到神经网络之前，它在一个称为词元化(tokenization)的过程中被转化为数字。这些词元(tokens)是神经网络阅读和解释文本的方式。感谢我们伟大的朋友 Shousetsu 为这个功能带来的灵感,テキストはニュ`ラルネットワ`クに送られる前に、ト`クン化と呼ばれるプロセスで数にQされます。このト`クンによってニュ`ラルネットワ`クはテキストをiみ解くことができるのです。このC能のインスピレ`ションを与えてくれた、私たちのゴ螭视讶摔扦る Shousetsu に感xします。
Expanded Mask,,,外扩后蒙版,
Invert Input Color,反色模式,反色模式,反色模式,入力の色を反
Copy image to: ,将图片发动到:,将图片发送到:,将图片发送到:,
Train U-Net,,,,U-Net を学
ControlNet v1.1.149,扩散控制网络(ControlNet),,,
Log directory,日志目录,日志目录,日志目录,ログディレクトリ
AddNet Model 4,[附加网络] 模块 4,[可选附加网络] 模型 4,[可选附加网络] 模型 4,モデル 4(AddNet)
Moved or deleted images will be unloaded.,被移动或删除的图像将自动从被卸载,,,移婴蓼郡舷鞒された画像はアンロ`ドされます。
Aspect Ratio Helper,,,,Aspect Ratio Helper
Found a bug or want to ask for a feature ? Please use,如需汇报bug或请求加入新特性，请访问,,,
Maximize area,,,最大面积,面eの最大化
Top percentile of latents to clamp,钳位TP覆盖率（Top percentile of latents to clamp，CFG较高时设100%，较温和时设95%）,,,
X/Y plot,X/Y 图表,X/Y 图表,X/Y 图表,
MBW,分层设置权重(MBW),分块设置权重(MBW),分块设置权重(MBW),
6 units,,,启用了6个单元,
Recipe,,配方,配方,
Delete value(s) from the array by index ? _del,,,,インデックスで配列からを削除する ? _del
img2img: Runs an img2img task inside of an [after] block.,,,,img2img: [after] ブロック内で img2img タスクをg行します。
"Interrogate: minimum description length (excluding artists, etc..)",最小描述长度（不包括艺术家等）,最小描述长度（不包括艺术家等）,最小描述长度（不包括艺术家等）,Interrogate: 最低限のh明のLさ(ア`ティストなどを除く)
Filename keyword search,文件名检索,,文件名搜索,ファイル名 キ`ワ`ド仕
This will randomly choose one of the three colors.,会随机从三种颜色中选一个,会随机从三种颜色中选一个,会随机从三种颜色中选一个,これにより、3色の中からランダムに1色がxばれます。
Dilation factor (A),扩张(Dilation)因子 (A),扩张(Dilation)因子 (A),扩张(Dilation)因子 (A),
EulerAncestralDiscrete,,,,EulerAncestralDiscrete
Neck,,,项链,
Swap Y/Z axes,YZ互换,YZ互换,YZ互换,Y/ZSを入れ替える
Inpaint at full resolution,全分辨率局部重绘,全分辨率局部重绘,全分辨率局部重绘,
Divisions,分区方式（列数:行数，每段 子提示词 的分区逗号分隔）,分割,分割,分割
Setting file name,,,,O定ファイル名
Lion,,,,Lion
ControlNet v1.1.165,扩散控制网络(ControlNet),,,
Class Images Per Instance Image,,,,インスタンス画像あたりのクラス画像数
nearest,,,,一番近い
uniform,均匀,均匀,均匀,一分布
"To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.",,,,"To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh."
Refresh,刷新,刷新,刷新,リフレッシュ
"How often, in seconds, to flush the pending tensorboard events and summaries to disk.",将挂起的 tensorboard 事件和摘要刷新到磁盘的频率（次/每秒）。,将挂起的 tensorboard 事件和摘要刷新到磁盘的频率 (单位：秒),将挂起的 tensorboard 事件和摘要刷新到磁盘的频率 (单位：秒),ディスクに保留中のテンソルボ`ドイベントとサマリ`をフラッシュするl度 (秒)
The,,,,The
hybrid_comp_mask_type,,,,hybrid_comp_mask_type
Create embedding,创建 Embedding,创建 Embedding,创建 Embedding,Embeddingを作成
Tagging Confidence Threshold,置信度阈值,,,
pidinet,软边缘检测（PiDiNet算法）,PiDiNet 边缘检测（像素差分网络，配合HED模型）,PiDiNet 边缘检测（像素差分网络，配合HED模型）,pidinet
#,,,,#
Use kohya-ss's finetuning metadata json,使用 kohya-ss 的微调元数据 json,,,Kohya-ssのfinetuningメタデ`タjsonを使用します
Tile overlap,图块重叠的像素(Tile overlap),图块重叠的像素(Tile overlap),图块重叠的像素(Tile overlap),境界の重なり具合
Captions,描述文本,描述文本,描述文本,キャプション
AddNet UNet Weight 4,[附加网络] UNet 权重 4,[可选附加网络] UNet 权重 4,[可选附加网络] UNet 权重 4,UNetの重み 4(AddNet)
ControlNet v1.1.109,扩散控制网络(ControlNet),,,
ControlNet v1.1.211,扩散控制网络(ControlNet),,,
Ultimate SD Upscale,,,,Ultimate SD Upscale
Send to img2img,>> 图生图,>> 图生图,>>图生图,img2imgに送
sd-webui-lora-block-weight,LoRA 权重分层设置插件,,,
Vertical,按列分区,,,垂直方向
Tone Curve,,,,ト`ンカ`ブ
Gallery Controls Bar,图库控件,,,
and,与,,,
"Add extended info (seed, prompt) to filename when saving grid",保存宫格图时，将扩展信息（随机种子、提示词）添加到文件名,保存宫格图时，将扩展信息（随机种子、提示词）添加到文件名,保存宫格图时，将扩展信息（随机种子、提示词）添加到文件名,保存するグリッド画像のファイル名に追加情(シ`ド、プロンプト)を加える
Learning Rate Warmup Steps,学习率的预热步数,学习率的预热步数,学习率的预热步数,学率ウォ`ムアップのステップ
1. Create your wildcard library by copying a collection using the dropdown below.,,,,1. 下のドロップダウンからコレクションをコピ`してワイルドカ`ドライブラリを作成します。
Font size,字号,,,
Keywords,关键词,关键词,关键词,キ`ワ`ド
Frame Interoplation,,,,フレ`ムag
Only copy to models with no metadata,仅复制到没有元数据的模型（不覆盖原有元数据）,仅复制到没有元数据的模型（不覆盖原有元数据）,仅复制到没有元数据的模型（不覆盖原有元数据）,メタデ`タのないモデルにのみコピ`
(4) Paste the Faces,,,(4) 粘贴面部,
Show Grid,,,,グリッドを表示
Save Scene,保存场景,,,
Discord - Dynamic Rich Presence,,,,Discord - Dynamic Rich Presence
Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize,,,,txt2img 生成中にランダムなパラメ`タをS可します。このスクリプトは他のものと同にC能します。オリジナルの作者: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize
Keep Imgs,,,,画像を保持
deepbooru: escape (\) brackets,,,deepbooru: 转义括号,
flavors,,,,フレ`バ`
"List of setting names, separated by commas, for settings that should go to the quick access bar at the top, rather than the usual setting tab. See modules/shared.py for setting names. Requires restarting to apply.",设置项名称的列表，以英文逗号分隔，该设置会移动到顶部的快速访问栏，而不是默认的设置选项卡。有关设置名称，请参见 modules/shared.py。需要保存设置并重启才能应用,设置项名称的列表，以英文逗号分隔，该设置会移动到顶部的快速访问栏，而不是默认的设置选项卡。有关设置名称，请参见 modules/shared.py。需要保存设置并重启才能应用,设置项名称的列表，以英文逗号分隔，该设置会移动到顶部的快速访问栏，而不是默认的设置选项卡。有关设置名称，请参见 modules/shared.py。需要保存设置并重启才能应用,上部のクイックアクセスバ`に置くO定のO定名をカンマで区切って入力。O定名については modules/shared.py を参照してください。m用するには再起婴必要です。
= ',,,,= '
Camera Focal Length,焦距,,,
(14589 tags total),,,,(合14589タグ)
The generated file is a slugified version of the prompt and can be found in the same directory as the generated images.\nE.g. in ./outputs/txt2img-images/.,生成的文件包含处理过的提示词，和生成的图像在同一目录\n例如 ./outputs/txt2img-images/,生成的文件包含处理过的提示词，和生成的图像在同一目录\n例如 ./outputs/txt2img-images/,生成的文件包含处理过的提示词，和生成的图像在同一目录\n例如 ./outputs/txt2img-images/,生成されたファイルは、プロンプトのスラグ化されたバ`ジョンであり、生成されたイメ`ジと同じディレクトリにあります。\n例 ./outputs/txt2img-images/.
Model name (do not include extension) ? model,,,,モデル名 (子を含まない) → モデル
Shoulder To Hip,肩-胯,,,
effective chekcer settings,有效元素筛查设置,,,
edit,当前使用滑动条编辑的值,,,
ControlNet v1.1.229,扩散控制网络(ControlNet),,,
Hypernetwork strength,超网络(Hypernetwork) 强度,超网络(Hypernetwork) 强度,超网络(Hypernetwork) 强度,
Use 8bit Adam,使用 8bit Adam,使用 8bit Adam,使用 8bit Adam,
Comma-separated list of tab names; tabs listed here will appear in the extra networks UI first and in order lsited.,,,,カンマで区切られたタブ名のリスト; ここにリストされているタブは、追加のネットワ`ク UI の最初の序で表示されます。
"Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size.",通过 GPU 数量、梯度累加步数(gradient accumulation steps)和每批数量(batch size)来缩放学习率,通过 GPU 数量、梯度累加步数(gradient accumulation steps)和每批数量(batch size)来缩放学习率,通过 GPU 数量、梯度累加步数(gradient accumulation steps)和每批数量(batch size)来缩放学习率,
Save generation params text,,,,生成されたパラメ`タテキストを保存
cascadePSP,CascadePSP 算法设置,,,
Extra filename (for small sets of custom tags),附加词库文件（用于少量自定义标记）,附加词库文件（用于少量自定义标记）,附加词库文件（用于少量自定义标记）,追加ファイル名 (小模なカスタムタグ用)
General Settings File,,,,一般O定ファイル
tp__deepl,,,,tp__deepl
Show predefined percentage buttons,,,,事前定xされたパ`セントボタンを表示します
Schedule to use for official training stuff.,选择要用于训练官方东西的调度器,选择要用于训练官方东西的调度器,选择要用于训练官方东西的调度器,
disable convert 'AND' to 'BREAK',,,,'AND' から 'BREAK' へのQをo炕
dog-nudity,,,,犬-ヌ`ド
? Save,,,? 保存,
ControlNet-7,控制网络-7,,,
Image Browser,图库浏览器,图库浏览器,图库浏览器,画像ブラウザ`
Paste available values into the field,,,,利用可能なをフィ`ルドにNり付ける
Generate lora weights when training completes.,,,,トレ`ニング完了rにLoRAの重みを生成します。
stable-diffusion-webui-text2prompt,,,,stable-diffusion-webui-text2prompt
(S10) Inter-Method,,(S10) 插值方法,(S10) 插值方法,
I want to preview GroundingDINO detection result and select the boxes I want.,预览 GroundingDINO 探测结果并选择特定选区,,预览GroundingDINO探测结果并选择所需要的包围盒,
tp__myMemory,,,,tp__myMemory
Save metadata as caption,将图片注释作为元数据存储,,,メタデ`タをキャプションとして保存
"Prompt, will append to your t2i prompt",输入区域提示词(Prompt),,正向提示词，会附加到原始正向提示词中,
Generate a checkpoint at the current training level.,,生成当前训练级别的模型权重进度(ckpt),生成当前训练级别的模型权重进度(ckpt),
Add number to filename when saving,储存的时候在文件名里添加数字,储存的时候在文件名里添加数字,储存的时候在文件名里添加数字,保存rにファイル名に番号を付加する
Preprocessor Preview,预处理结果预览,,预处理结果预览,
Multiplication (2^N),放大指数 N（放大倍率为2^N）,放大指数（2^N）,放大指数（2^N）,倍率(2^N)
a1111-sd-webui-locon,LoCon插件(允许LyCORIS以LoRA的形式调用),LoCon 插件,LoCon 插件,a1111-sd-webui-locon
"Reload custom script bodies (No ui updates, No restart)",重新加载自定义脚本主体（无用户界面更新，无重启）,重新加载自定义脚本主体（无用户界面更新，无重启）,重新加载自定义脚本主体（无用户界面更新，无重启）,カスタムスクリプトを再iz (UIは涓されず、再起婴猡筏蓼护蟆)
model-keyword,,,,model-keyword
Colorbglayout,Colorbglayout,,,
Reset zoom and canvas positon,,,重置缩放和画布位置,
Select your favorite boxes:,选择效果最好的选区,,选择你想保留的包围盒,
OUT_A_10,,模型A 输出层10,模型A 输出层10,
This string will be used to join split words into a single line if the option above is enabled.,如果启用了上述选项，则此处的字符会用于将拆分的单词接合为同一行,如果启用了上述选项，则此处的字符会用于将拆分的单词接合为同一行,如果启用了上述选项，则此处的字符会用于将拆分的单词接合为同一行,この文字列は、上のオプションが有郡龊悉恕⒎指瞍丹欷gZを1行にY合するために使用されます。
CFG scale,提示词相关性(CFG Scale),提示词相关性(CFG Scale),提示词相关性(CFG Scale),
Colorbgelevated,Colorbgelevated,,,
Memory Attention,,内存注意,内存注意,メモリに注意
Convert to ONNX,,,转换到ONNX,
tabs,,,,タブ
Upload prompt inputs,上传提示词输入文件,上传提示词输入文件,上传提示词输入文件,入力プロンプトをアップロ`ドする
Denoising Diffusion Implicit Models - best at inpainting,Denoising Diffusion Implicit models - 最擅长局部重绘,Denoising Diffusion Implicit models - 最擅长局部重绘,Denoising Diffusion Implicit models - 最擅长局部重绘,Denoising Diffusion Implicit Models - inpaintingに最m
"NOTE: If the 'Generate' button doesn't work, go in Settings and click 'Restart Gradio and Refresh...'.",,注意：如果“生成”按钮不起作用，请进入“设置”并单击“重启 Gradio 及刷新...”。,注意：如果“生成”按钮不起作用，请进入“设置”并单击“重启 Gradio 及刷新...”。,
https://github.com/jtydhr88/sd-3dmodel-loader.git,,,,https://github.com/jtydhr88/sd-3dmodel-loader.git
model_C,模型C,,,
Move ControlNet tensor to CPU (if applicable),将 扩散控制网络张量(ControlNet tensor) 转移到CPU运算,,尝试用CPU计算ControlNet,
Kernel schedule,,,,カ`ネルスケジュ`ル
p value,,,,p の
Move to directory,将图片移动到目标路径,将图片移动到目标路径,将图片移动到目标路径,ディレクトリへ移
Show Width/Height and Batch sliders in same row,将批次与批量设置整合到长宽设置的右侧,将批次与批量设置整合到长宽设置的右侧,将批次与批量设置整合到长宽设置的右侧,幅/高さとバッチスライダ`を同じ行に表示する
name,文件名,名称,名称,名前
Load,载入,载入,载入,iみzみ
Colortexttertiary,Colortexttertiary,,,
Enter a subject ? subject,,,,件名を入力 ? subject
Experimental Settings,,,,gY的なO定
Starting Control Step,干涉起始步数,,干涉开始位置,
There is *no* Batch mode like in vanilla deforum. Please Use the txt2img tab for that.,,,,vanilla deforumのようなバッチモ`ドはありません。txt2imgタブを使用してください。
Restore faces,面部修复,面部修复,面部修复,の修
Hires fix: show hires sampler selection,,,高清修复：显示高清修复采样器选项,
sd-webui-llul,"局部细化(Local Latent upscaLer, LLuL)插件",潜变量局部放大器,潜变量局部放大器,sd-webui-llul
spaceship-ukioe,,,,宇宙船 浮世}
A negative prompt to use when generating preview images.,生成预览图像时使用的负面提示词,生成预览图像时使用的反向提示词,生成预览图像时使用的反向提示词,
copy to clipboard,复制,复制,复制,クリップボ`ドにコピ`
Colorbordersecondary,Colorbordersecondary,,,
Apply selection filter,将选择结果添加到筛选条件,,,xkフィルタ`をm用
Iterations ? iterations,,,,イテレ`ション数 ? iterations
Close,关闭,关闭,关闭,
Colorerrortext,Colorerrortext,,,
Active in img2img (Requires restart),在图生图页面启用（需要保存设置并重启）,在图生图页面启用（需要保存设置并重启）,在图生图页面启用（需要保存设置并重启）,img2imgで有 (再起婴必要)
Prev batch,上一批,上一批,上一批,
Stop XY,终止XY队列,,,
Edit Tags,编辑为：,,,タグの集
Magic prompt model,,,,Magic prompt モデル
System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.,,,,サ`バ`のリアルタイム情螭虮硎兢工WebUIのシステム情螗骏帧％プションとしてクラウドソ`スの推デ`タを送信することもできます。
(M6) Multiplier,,(M6) 倍率,(M6) 倍率,
X offset (A),X 偏移 (A),X 偏移 (A),X 偏移 (A),
Enable postprocessing operations in txt2img and img2img tabs,在文生图/图生图选项卡中启用后处理操作,在文生图/图生图选项卡中启用后处理操作,在文生图/图生图选项卡中启用后处理操作,Txt2img および img2img タブで後I理操作を有郡摔工
Segment Anything status,执行状态,,运行状态,
Just resize (latent upscale),仅调整大小 (潜空间放大),直接缩放 (放大潜变量),直接缩放 (放大潜变量),湫(latent アップスケ`ル)
Delete num :,被删除的预约序号：,,,
New Scribble Drawing Height,草图画布高度,,,
img2img_autosize: Automatically adjusts the width and height parameters in img2img mode based on the proportions of the input image.,,,,img2img_autosize: 入力画像の比率に基づいて、img2imgモ`ドで幅と高さのパラメ`タを自拥膜苏{整します。
sigma,,,,sigma
"In the window that appears, click",,,,表示されるウィンドウで次のように入力します。
B,,,,B
Auto-include this in prompt,,,,プロンプトに自拥膜撕める
Start drawing,开始绘制,开始绘制,开始绘制,
spaceship-anime,,,,宇宙船-アニメ
ControlNet - 5,扩散控制网络(ControlNet) - 5,,,
Tags,,标签(Tags),标签(Tags),タグ
tp__lingvanex,,,,tp__lingvanex
keyword,搜索,搜索,搜索,
DPM++ 2S a,DPM++ 2S a,,,DPM++ 2S a
difference,,,,差の~
am,,,,am
default = 0.99,,,,既定 = 0.99
Extra steps,额外基准步骤,,,
tp_mglip,,,,tp_mglip
X/Y/Z plot,X/Y/Z 图表,X/Y/Z 图表,X/Y/Z 图表,X/Y/Zプロット
"Path to classifier ckpt, can be empty",分类器的路径，可留空,分类器的路径，可留空,分类器的路径，可留空,分モデルckptのパス。空白にすることもできます。
Send to Layer4,,,,レイヤ`4に送
Copy collection,,,,コレクションをコピ`
CLIP_test,,,,CLIP_test
Y Types,X轴类型,,,
softplus,softplus,,,softplus
Use same sampler,,,使用高清修复前同样的方法（不可用时使用DDIM）,
INVISIBLE,,,,非表示
"Multiplication (x0.5, x1.5)",,,,"比率 (x0.5, x1.5)"
/,根目录,,,/
Remember that each generation overwrites previous frames in the same folder.,,,,Remember that each generation overwrites previous frames in the same folder.
Open new canvas,,,打开新建画布设置,
You can also download generated pictures from here:,,,,ここから生成された画像をダウンロ`ドすることもできます:
"Skip negative prompt for steps where image is already mostly denoised; the higher this value, the more skips there will be; provides increased performance in exchange for minor quality reduction.",,,在图像已经大部分去噪的步骤中跳过负面提示词的处理；这个值越高，跳过的步骤就越多；以轻微的质量降低，换取了更高的性能。,
Preset_Weights,预设权重,预设权重,预设权重,
Triple sum:A*(1-alpha-beta)+B*alpha+C*beta,三项和（ A×(1-α-β) + B×α + C×β ）,,,
Use minimal area for face selection (for multiple faces),,,多张人脸时，使用较小的识别区域,
Upscale ratio,,,,アップスケ`ル比
Checkpoint Format,模型格式,模型格式,模型格式,
https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git,,,,https://github.com/Coyote-A/ultimate-upscale-for-automatic1111.git
"Recommended settings: Use from inpaint tab, inpaint at full res ON, denoise <0.5",推荐设置：于局部重绘选项卡使用，开启全分辨率局部重绘，重绘幅度(Denoising) < 0.5,推荐设置：于局部重绘选项卡使用，开启全分辨率局部重绘，重绘幅度(Denoising) < 0.5,推荐设置：于局部重绘选项卡使用，开启全分辨率局部重绘，重绘幅度(Denoising) < 0.5,
Latent (antialiased),Latent（抗锯齿）,潜变量 (抗锯齿),潜变量 (抗锯齿),Latent (アンチエイリアスag)
Automatically update your prompt with interesting modifiers. (Runs slowly the first time),使用有趣的修饰符自动更新你的提示词。（第一次运行会比较慢）,使用有趣的修饰符自动更新你的提示词。（第一次运行会比较慢）,使用有趣的修饰符自动更新你的提示词。（第一次运行会比较慢）,面白い修子で自拥膜衰抓恁螗抓趣蚋新します。(最初はゆっくりとg行)
AdamW weight decay parameter,,,,AdamW weight decay パラメ`タ
Inpaint masked,重绘蒙版内容,重绘蒙版内容,重绘蒙版内容,マスクの欷inpaint
Search and Replace for all images displayed.,搜索/替换（所有当前显示的图像）,,,表示されているすべての画像にして仕鳏筏浦Qします。
History,历史记录,历史记录,历史记录,履s
Copy caption from selected images automatically,自动从选中图像复制注释信息,,,xkした画像からキャプションを自婴钎偿冤`
Sequential Merge Parameters,合成参数队列,,,
pix2pix_zero: A diffusion-based image-to-image approach that allows users to specify the edit direction on-the-fly.,,,,pix2pix_zero: ユ`ザ`がオンザフライで集方向を指定できる、散ベ`スの画像から画像へのアプロ`チ。
IN01,,输入层01,输入层01,
Booru Score Threshold,DeepBooru 置信阈值下限,,,Booruスコアのしきい
k value,,,,k の
instance2mask: Creates an image mask from instances of types specified by the content for use with inpainting.,,,,instance2mask: inpaintingで使用するために、コンテンツで指定されたタイプのインスタンスからイメ`ジマスクを作成します。
This panel is for those who want to upload mask to ControlNet inpainting. It is not part of the SAM feature. It might be removed someday when ControlNet support uploading image and mask. It serves as a temporarily workaround to overcome the unavailability of image with mask uploading feature in ControlNet extension.,,,这个页面是为那些想要上传蒙版到ControlNet重绘中的用户提供的。它不是SAM功能的一部分。当ControlNet支持上传蒙版时，这哥功能可能会被移除。它是解决ControlNet中没有上传蒙版功能的临时解决方案。,
Enabling the Krita Plugin,,,,Krita プラグインを有郡摔工
hidden_idx_next,hidden_idx_next,,,hidden_idx_next
". filename cannot have ',' inside, and files should be splitted by ','.",,,,". ファイル名には「,」を含めることはできず、ファイルは「,」で区切られる必要があります。"
display both english and target language,显示双语对照界面翻译（使用汉化包时请关闭，会引起界面臃肿）,,,英Zと翻U先の言ZのI方を表示
Segment Anithing & CLIP,Segment Anithing 与 CLIP 设置,,,
Preserves the UI state after reload/restart.,,,,リロ`ド/再起俞幛UI状Bを保持します。
(O)Output Model Name,输出模型文件名,输出模型文件名,输出模型文件名,
ControlNet v1.1.224,扩散控制网络(ControlNet),,,
ControlNet Unit 9,控制单元 9,,,
deepbooru: sort tags alphabetically,,,deepbooru: tag字母表排序,
Saving,,,,保存中
Quicksettings list,"快捷设置列表（将显示在页面最上方，建议填入""sd_model_checkpoint,sd_vae""）","快捷设置列表（将显示在页面最上方，建议填入""sd_model_checkpoint,sd_vae""）","快捷设置列表（将显示在页面最上方，建议填入""sd_model_checkpoint,sd_vae""）",クイックO定
OUT04,,输出层04,输出层04,
(M3) Multiplier,,(M3) 倍率,(M3) 倍率,
Image for img2img,图生图的图像,图生图的图像,图生图的图像,img2imgで使用する画像
Save Pose,保存动作,保存动作,保存动作,
Upscaler 2,放大算法 2 (Upscaler 2),放大算法 2 (Upscaler 2),放大算法 2 (Upscaler 2),アップスケ`ラ` 2
Region 4,区域 4,区域 4,区域 4,
UniPC order (must be < sampling steps),UniPC 阶数（必须小于采样迭代次数）,UniPC 阶数 (推荐有提示词时使用2阶，无提示词使用3阶),UniPC 阶数 (推荐有提示词时使用2阶，无提示词使用3阶),UniPC 次数 (サンプリングステップ数未氦扦胜堡欷肖胜辘蓼护)
Enable thumbnail tooltips,启用缩略图工具提示,,启用缩略图提示,
You cannot preview segmentation because you have not added dot prompt.,未添加提示点，无法预览,,,
The number of steps to use when generating classifier/regularization images.,生成分类/规范化图像时使用的步数,生成分类/规范化图像时使用的步数,生成分类/规范化图像时使用的步数,
Stop processing current image and continue processing.,停止处理当前图像，并继续处理下一个,停止处理当前图像，并继续处理下一个,停止处理当前图像，并继续处理下一个,F在行っているI理を中断し、その次以降のI理を@A
ControlNet v1.1.141,扩散控制网络(ControlNet),,,
Lerp,,线性插值,线性插值,形ag
"Instead of generating random prompts from a template, combinatorial generation produces every possible prompt from the given string.\nThe prompt 'I {love|hate} {New York|Chicago} in {June|July|August}' will produce 12 variants in total.\n\nThe value of the 'Seed' field is only used for the first image. To change this, look for 'Fixed seed' in the 'Advanced options' section.",,,,テンプレ`トからランダムなプロンプトを生成する代わりに、M合せ生成は与えられた文字列から生成される可能性のある、あらゆるプロンプトを生成します。\n 'I {love|hate} {New York|Chicago} in {June|July|August}' というプロンプトは、全部で12Nのバリエ`ションが生成されます。
Output directory for img2img grids,图生图宫格的输出目录,图生图宫格的输出目录,图生图宫格的输出目录,img2imgグリッド画像の出力ディレクトリ
Select shortcode:,,,,ショ`トコ`ドをxk:
Randomly selects a keyword from the prompt and adds emphasis to it. Try this with Fixed Seed enabled.,随机强调提示词中的一个关键词，尝试前要启用固定随机种子,随机强调提示词中的一个关键词，尝试前要启用固定随机种子,随机强调提示词中的一个关键词，尝试前要启用固定随机种子,ランダムにプロンプトからキ`ワ`ドをxkし、{します。固定シ`ドを有郡摔筏皮撙皮ださい。
display_samples,,显示样本,显示样本,display_samples
Delete 0-entries from exif cache,,,,exif キャッシュから 0 エントリを削除
Version,版本信息,版本信息,版本信息,バ`ジョン
Total Images,,,,t画像数
All Reste,全部重置,全部重置,全部重置,
Background,背景,背景,背景,
Strength,,,,度
Disable prompt token counters,,,禁用提示词token计数,
Add a random artist to the prompt.,随机添加一个艺术家到提示词中,随机添加一个艺术家到提示词中,随机添加一个艺术家到提示词中,
float,储存为float32,,,
Open New Scribble Drawing Canvas,创建空白画布绘制草图,,,
String to prepend to the variable ? _before,,,,涫の先^に追加する文字列 ? _before
"Enter relative to webui folder or Full-Absolute path, and make sure it ends with something like this: '20230124234916_%05d.png', just replace 20230124234916 with your batch ID. The %05d is important, don't forget it!",,,,Webuiフォルダにして相パスを入力するか、完全な~パスを入力し、最後に次のような形式になるようにしてください：'20230124234916_%05d.png'。gに20230124234916をバッチIDに置きQえてください。%05dは重要ですので、忘れないでください！
Predefined percentage display format,,,,定xgみパ`セント表示形式
To enable seed schedule select seed behavior ― 'schedule',,要启用种子调度，请选择随机种子行为――“调度”,要启用种子调度，请选择随机种子行为――“调度”,
Use EMA for prediction,,,,予yにEMAを使用する
-->,,,,-->
Original frames folder,,,,オリジナルフレ`ムフォルダ
Insert before,在前面插入,在前面插入,在前面插入,前に啡
Advanced options,高级选项,高级选项,高级选项,高度なO定
Show previews of all images generated in a batch as a grid,以宫格图的形式，预览批量生成的所有图像（建议开启）,以宫格图的形式，预览批量生成的所有图像（建议开启）,以宫格图的形式，预览批量生成的所有图像（建议开启）,バッチで生成されたすべての画像のプレビュ`をグリッドとして表示する
Live preview file format,,,实时预览文件的格式,
also delete off-screen images,同时删除屏幕外的图,,即时未显示的图片也会被删除,画面外の画像も削除します
and generate images according to random segmentation which preserve image layout.,,,使用的。,
silueta,,,,シルエット
(A7) Primary,,(A7) 主要,(A7) 主要,
tags from the images displayed., Tags（已显示的范围内）,,,画像からタグが表示されます。
Lower Leg,小腿,,,
Post Processing,后处理设置,,,
"Restart Gradio and Refresh components (Custom Scripts, ui.py, js and css only)",重启 Gradio 及刷新组件（仅限自定义脚本、ui.py、js 和 css）,重启 Gradio 及刷新组件（仅限自定义脚本、ui.py、js 和 css）,重启 Gradio 及刷新组件（仅限自定义脚本、ui.py、js 和 css）,
In FPS,,,,FPSで
Embedding token,Embedding 的词元(Token) / 关键词,Embedding 的词元(Token) / 关键词,Embedding 的词元(Token) / 关键词,
Date to,日期至,日期至,日期至,
List-Up checkpoints,,列出模型(ckpts),列出模型(ckpts),
Other,,,,その他
tokenizer,词元分析器(tokenizer),词元分析器(tokenizer),词元分析器(tokenizer),tokenizer
depth,深度信息估算（MiDaS 算法）,MiDaS 深度信息估算（MiDaS depth estimation）,MiDaS 深度信息估算（MiDaS depth estimation）,深度
", port for AUTOMATIC1111's webui maintained by",,,,、 AUTOMATIC1111 の webui のためのポ`トは整浃丹欷皮い:
Options can be given weights:,,,,オプションでweightを与えられます
"Color coherence may be used with hybrid composite off, to just use video color.",,,,カラ`コヒ`レンスは、ビデオカラ`を使用するために、ハイブリッドコンポジットオフで使用することができます。
number of images to delete consecutively next,接下来要连续删除的图像数,接下来要连续删除的图像数,接下来要连续删除的图像数,
Negative mask prompt ? negative_mask,,,,ネガティブマスクプロンプト ? negative_mask
ControlNet v1.1.259,扩散控制网络(ControlNet),,,
Normal background threshold,背景识别阈值（Normal background threshold）,背景识别阈值（Normal background threshold）,背景识别阈值（Normal background threshold）,
n,,,,n
Nothing here. Add some content to the following directories:,无内容，请将模型添加到以下目录:,无内容，请将模型添加到以下目录:,无内容，请将模型添加到以下目录:,ここには何もありません。以下のディレクトリにコンテンツを追加してください。
sd-webui-model-converter,模型格式转换插件,模型格式转换插件,模型格式转换插件,
extras history,附加功能选项卡的历史记录,附加功能选项卡的历史记录,附加功能选项卡的历史记录,
Weight,权重（Weight）,权重（Weight）,权重（Weight）,重み
Disable for Negative prompt.,为负面提示词(Negative prompt)禁用色彩分离,,不对反向提示词生效,ネガティブプロンプトではo炕
Swap hotkey combinations for Zoom and Adjust brush resize,,,交换缩放和调整画笔大小的快捷键,
Write template into image metadata.,,,,テンプレ`トを画像メタデ`タにきzむ。
Comp mask contrast schedule,,,,コンポジットマスクのコントラストスケジュ`ル
Overwrite existing,,,,既存の内容を上き
Face,,,面部,
Saved elements from img2img,,,,img2img から保存された要素
Mask Init,,,,マスクの初期
Minimum attention,,,,Attentionの最小
Enable Dynamic Thresholding (CFG Scale Fix),启用动态阈值(CFG Scale Fix),启用动态阈值(提示词相关性修复 - CFG Scale Fix),启用动态阈值(提示词相关性修复 - CFG Scale Fix),
Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.,,,,Pose2Image用の推定画像生成ツ`ルです。このC能により、openposeのフィギュアを3D空gで婴すことができます。
Models,Stable Diffusion 模型(ckpt),模型,模型,
"Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids.",允许你在提示词中包含各种短代码。 你可以从文件中提取文本、设置自己的变量、通过条件函数处理文本等等 - 就像是增强版的通配符,允许你在提示词中包含各种短代码。 你可以从文件中提取文本、设置自己的变量、通过条件函数处理文本等等 - 就像是增强版的通配符,允许你在提示词中包含各种短代码。 你可以从文件中提取文本、设置自己的变量、通过条件函数处理文本等等 - 就像是增强版的通配符,
ControlNet v1.1.114,扩散控制网络(ControlNet),,,
Auto SAM Config,Auto SAM 选项,,Auto SAM设置,
left,左侧,左,左,左
[extension],,,,[extension]
Force CFG scale to this value ? cfg_scale,,,,CFGスケ`ルをこのに制する ? cfg_scale
Paste the folder location below.,,,,フォルダの鏊を以下にNり付けます。
"Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.",,,,"Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well."
ControlNet v1.1.265,扩散控制网络(ControlNet),,,
Sampler parameters,采样器参数,采样器参数,采样器参数,サンプラ`のパラメ`タ
Append Medium tags from CLIP,,,,CLIPからミディアムタグを追加
a1111-stable-diffusion-webui-vram-estimator,显存评估插件(VRAM Estimator),显存评估插件(VRAM Estimator),显存评估插件(VRAM Estimator),a1111-stable-diffusion-webui-vram-estimator
Extra generation params,从生成参数的文本提取潜空间分区参数,从生成参数的文本提取潜空间分区参数,从生成参数的文本提取潜空间分区参数,追加生成パラメ`タ
Local directory name,本地目录名,本地目录名,本地目录名,ロ`カルディレクトリ名
This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.,,,,This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.
https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git,,,,https://github.com/tsngo/stable-diffusion-webui-aesthetic-image-scorer.git
Ignore selected VAE for stable diffusion checkpoints that have their own .vae.pt next to them,对于拥有同名 .vae.pt 的模型，忽略掉选中的 VAE,对于拥有同名 .vae.pt 的模型，忽略掉选中的 VAE,对于拥有同名 .vae.pt 的模型，忽略掉选中的 VAE,Checkpointに辘工毳榨ˉぅ朊の.vae.ptがあるなら、xkされたVAEをoする
Filter NSFW content,过滤成人内容(NSFW)（不建议开启）,过滤成人内容(NSFW)（不建议开启）,过滤成人内容(NSFW)（不建议开启）,
eta (noise multiplier) for ancestral samplers,ancestral 采样器的 eta (噪声乘数，建议值0.67),ancestral 采样器的 eta (噪声乘数，建议值0.67),ancestral 采样器的 eta (噪声乘数，建议值0.67),Ancestralサンプラ`で用いるeta (noise multiplier)
Existing Prompt Contents,现存的提示词内容,现存的提示词内容,现存的提示词内容,
Disable dynamic prompts by unchecking this box.,取消勾选来禁用动态提示词,取消勾选来禁用动态提示词,取消勾选来禁用动态提示词,このボックスのチェックを外すと、ダイナミックプロンプトがo郡摔胜辘蓼埂
Concept 1,,,,コンセプト 1
Process,,,,プロセス
Deactivate Selected Script,停用所选脚本,停用所选脚本,停用所选脚本,
Number of beams (0 = no beam search),,,,ビ`ム幅 (0 = ビ`ムサ`チしない)
Adam Epsilon,Adam Epsilon (替代 0 的常量，防止直接除以 0),Adam Epsilon (替代 0 的常量，防止直接除以 0),Adam Epsilon (替代 0 的常量，防止直接除以 0),
"else: Returns content if a previous conditional shortcode failed its check, otherwise discards content.",,,,else: 前の条件付きショ`トコ`ドがチェックに失・筏龊稀コンテンツを返します。そうでなければ、コンテンツを破します。
ControlNet v1.1.249,扩散控制网络(ControlNet),,,
a1111-sd-webui-haku-img,,,,a1111-sd-webui-haku-img
Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.,,,,ANDキ`ワ`ド（Composable diffusion）を使って、LoRAをサブプロンプトに限定できるようになります。Latent Couple extensionとMみ合わせると便利です。
Civitai URL or Model ID,Civitai网址 或 模型ID,,,
Load from subdirectories,从子目录加载,,,サブディレクトリからiみzむ
xh,,,,xh
sd-parseq,,,,sd-parseq
Replace order,取代顺序,取代顺序,取代顺序,
"Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.",,,,ここでは、それらのパラメ`タにするモ`ションマップの例を_Jすることができます。例えば、不要な粒状性を食訾筏龊稀ノイズを{整するのに有郡扦埂￥くまで2フレ`ムgの婴であることを意Rしてください。
Literals,字面量,字面量,字面量,リテラル
Enable Tag Autocompletion,启用Tag自动补全,启用Tag自动补全,启用Tag自动补全,自鹰骏把a完を有炕
?,?,,,
Maximum number to be returned ? _max,,,,返される最大数 ? _max
keep whatever was there originally,保留原来的图像，不进行预处理,保留原来的图像，不进行预处理,保留原来的图像，不进行预处理,もともとあったものをそのままにする
Low VRAM (8GB or below),显存优化,"低显存（8GB以下）模式（需配合启动参数""--lowvram""）","低显存（8GB以下）模式（需配合启动参数""--lowvram""）",
UNet Weight 3,UNet 权重 3,UNet 权重 3,UNet 权重 3,UNetの重み 3
txt2img_hires_steps,高分辨率修复-采样次数,,,
Categorical mask status,执行状态,,语义分割运行状态,
number of -1,将 “-1” 替换为,,,
Bulk process frames with chosen outfill method,使用选定的填充方法批量处理截取的帧,使用选定的填充方法批量处理截取的帧,使用选定的填充方法批量处理截取的帧,
Reset,清空画面,清空画面,清空画面,リセット
debug,,,,デバッグ
la,,,,la
Remove duplicate tags,移除重复的 Tag,,,重}するタグを削除
Y Values,X轴值,,,
CLIP Skip,,,,CLIP スキップ
ControlNet v1.1.152,扩散控制网络(ControlNet),,,
wd-v1-4-convnext-tagger-v2,,,,wd-v1-4-convnext-tagger-v2
With confidence,将置信度作为Tag的权重,,,
Force convert half to float on interpolation (for some platforms),插值时强制将半精度转化为单精度浮点（对于某些平台有效，详见GitHub页面）,插值时强制将半精度转化为单精度浮点（对于某些平台有效，详见 GitHub）,插值时强制将半精度转化为单精度浮点（对于某些平台有效，详见 GitHub）,制的に半分を float にQします(一部のプラットフォ`ム向け)
ControlNet v1.1.155,扩散控制网络(ControlNet),,,
Prompt Translator,机翻提示词(Prompt Translator),,,Prompt Translator
MiDaS weight,,,,MiDaSの重み
sd_smartprocess,智能预处理,智能预处理,智能预处理,sd_smartprocess
prompt-bracket-checker,提示词括号匹配检测,,提示词括号检查,prompt-bracket-checker
-50%,,,,-50%
BLIP,,,,BLIP
DFI Tolerance:,,,,S容:
Card height for Extra Networks (px),缩略预览图高度（像素，推荐设置为106，保持预览图为2:3比例显示）,,自定义卡片高度，像素,追加ネットワ`クのカ`ドの高さ (px)
(S7) Inter-Method,,(S7) 插值方法,(S7) 插值方法,
IN07,,输入层07,输入层07,
Drag Mouse,,,鼠标拖动,
CLIP: maximum number of lines in text file,,,CLIP: 文本文件最大行数,
Target ControlNet number,接收此图像的 扩散控制网络(ControlNet) 编号,接收此图像的 ControlNet 编号,接收此图像的 ControlNet 编号,タ`ゲットのControlNet number
Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator,,,,Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator
"symbol:color-hex, symbol:color-hex, ...","文字:颜色代码, 文字:颜色代码, ...","文字:颜色代码, 文字:颜色代码, ...","文字:颜色代码, 文字:颜色代码, ...","symbol:color-hex, symbol:color-hex, ..."
Create txt2img canvas,创建空白画布作为参考（可手动上传图片作为参考图）,,创建文生图画布,
Source Checkpoint,源 Stable Diffusion 模型(ckpt),源模型(ckpt),源模型(ckpt),Source Checkpoint
Select Tags,选择 ,,,タグのxk
tile_colorfix,,,颜色修正（tile）,
Weight for latent match,用于匹配潜空间(latent)的权重,用于匹配潜变量(latent)的权重,用于匹配潜变量(latent)的权重,
The model to train.,要训练的模型,要训练的模型,要训练的模型,
Multi Merge,,多重合并,多重合并,
Some instructions,操作说明（非常重要）,一些操作说明,一些操作说明,
"Read parameters (prompt, etc...) from txt2img tab when making previews",进行预览时，从文生图选项卡中读取参数（提示词等）,进行预览时，从文生图选项卡中读取参数（提示词等）,进行预览时，从文生图选项卡中读取参数（提示词等）,プレビュ`の作成にtxt2imgタブからiみzんだパラメ`タ(プロンプトなど)を使う
color_burn,,,,きこみカラ`
Generate inputframes,,,,入力フレ`ムを生成する
jw,,,,jw
STAND BY...,,,,STAND BY...
"Prompt, will be appended to your t2i prompt)",输入区域提示词(Prompt),,,
Token Merging - Stride X,步幅 X,,,
Localization (requires restart),本地化翻译（需要保存设置并重启）,本地化翻译（需要保存设置并重启）,本地化翻译（需要保存设置并重启）,言ZO定 (再起婴必要)
filename(option),文件名（选填）,,,
Generate ImageReward Scores for all images,,,为所有图片计算ImageReward Scores,
| License: Attribution 4.0 International (CC BY 4.0),,,,| License: Attribution 4.0 International (CC BY 4.0)
Order compared to other [after] blocks ? int,,,,他の [after] ブロックと比^した命令 → int
spaceship-nudity,,,,宇宙船演算子(nudity)
Anime-inclined great guide (by FizzleDorf) with lots of examples:,,,,アニメにA斜のある素晴らしいガイド(FizzleDorfによる) の例がたくさんあります:
Set the preprocessor to [invert] If your image has white background and black lines.,使用有白色背景、黑色线条的图像，请将预处理器设置为“反色”,,将白色背景黑色线条转成黑色背景白色线条请使用[反色]预处理器,
State to restore,需要恢复的内容,,要还原的项目,
Resume & Run from file,,,,中断後にファイルから再_してg行
CLIP Text models. Set to empty to not change.,,,,CLIPテキストモデル。涓しない龊悉显O定しないでください。
Generate video from inpainted mesh.,,,,Inpaint meshからビデオを生成します。
Dolly,,,,小さな人形
Filter models by path name,下面的模型列表将仅显示此路径下的模型,下面的模型列表将仅显示此路径下的模型,下面的模型列表将仅显示此路径下的模型,パス名でモデルをフィルタ`する
Add WD14 Tags to Caption,,,,WD14タグをキャプションに追加
? Save & Restart,?保存并重启,,,
Angle,,,,角度
(This is a demanding algorithm),,,,(これは要求の高いアルゴリズムです)
Plot the LoRA weight in all steps,绘制 LoRA 动态权重调度函数图像（常与 “#xxx” 语法联用，详见GitHub自述文件）,,,
Crop Images,剪裁图像,剪裁图像,剪裁图像,画像のクロップ
Select images from the left gallery.,对左侧图库中的图像进行操作：,,,左のギャラリ`から画像をxk
ControlNet v1.1.139,扩散控制网络(ControlNet),,,
Search Mode,搜索模型,,,
Copy to Inpaint Upload & img2img ControlNet Inpainting,,,将蒙版复制到局部重绘（上传蒙版）和图生图ControlNet重绘,
Effects (on until refresh),效果（重启后开启）,效果（重启后开启）,效果（重启后开启）,
Multiplier (M) - set to 0 to get model A,倍率(M) - 设为0时输出模型与A完全相同,倍率(M) - 设为0时输出模型与A完全相同,倍率(M) - 设为0时输出模型与A完全相同,Multiplier (M) 0にすると完全にmodel Aとなります (Toolstips参照)
"Configure Hotkeys. For possible values, see https://www.w3.org/TR/uievents-key, or leave empty / set to 'None' to disable. Must be valid JSON.",快捷键设置，留空或设置为“None”可禁用，必须是有效的JSON格式，详情参见https://www.w3.org/TR/uievents-key,,,
Search negative prompt,检索范围是否包含负面提示词,检索范围是否包含负面提示词,检索范围是否包含负面提示词,ネガティブプロンプトを仕
The directory containing classification/regularization images.,包含分类/规范化图像的目录,包含分类/规范化图像的目录,包含分类/规范化图像的目录,
Gradient clip value,,,,勾配クリッピングO定
Balanced,均衡,,均衡,
Activate Selected Script,激活所选的脚本,激活所选的脚本,激活所选的脚本,
midas,深度信息估算（MiDaS 算法）,MiDaS 深度信息估算（MiDaS depth estimation）,MiDaS 深度信息估算（MiDaS depth estimation）,
Original Weights,原始权重,,,
Inversion steps,反转步数,,,
Fast Encoder Color Fix,启用快速编码颜色修正,,快速编码色彩修复,
Ignore faces larger than specified size,,,如果原尺寸超过此值，则忽略,
Unload Optimizer when generating preview(hypernetwork),,,,プレビュ`の生成r(hypernetwork) にオプティマイザをアンロ`ドします
running benchmark may take a while. extensive tests may result in gpu out-of-memory conditions.,运行基准测试可能需要一段时间。 扩大基准测试可能会导致显存不足的情况。,,,
"Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.",,,,カスタムディフュ`ジョンは、要するに、モデル全体をチュ`ニングするのではなく、TIを使ったfinetuning-liteなのです。TIと同のスピ`ドとメモリが必要ですが、より少ないステップでより良いY果を得られるとされています。
"Uscale the image in latent space. Alternative is to produce the full image from latent representation, upscale that, and then move it back to latent space.",放大潜空间中的图像。而另一种方法是，从潜变量表达中直接解码并生成完整的图像，接着放大它，然后再将其编码回潜空间,放大潜空间中的图像。而另一种方法是，从潜变量表达中直接解码并生成完整的图像，接着放大它，然后再将其编码回潜空间,放大潜空间中的图像。而另一种方法是，从潜变量表达中直接解码并生成完整的图像，接着放大它，然后再将其编码回潜空间,
Interpolated Vid FPS,,,,agされたビデオのFPS
Remove selected,移除已选中图形,移除已选中的,移除已选中的,
"Made by deforum.github.io, port for AUTOMATIC1111's webui maintained by kabachuha",,由 deforum.github.io 制作，AUTOMATIC1111 的 webui 移植版本由 kabachuha 维护,由 deforum.github.io 制作，AUTOMATIC1111 的 webui 移植版本由 kabachuha 维护,
tp__alibaba,,,,tp__alibaba
Swap Negative Prompt,,,,ネガティブプロンプトの入れ替え
Merge!,仅合并,,,
fill,填充,填充,填充,埋める
Visualize,预览分区结果（权重越高，颜色越浅，分区参数具体用法详见插件GitHub页面）,预览,预览,可化
Effective Block Analyzer,有效层分析工具,,,
ControlNet v1.1.203,扩散控制网络(ControlNet),,,
Beginning index of the substring ? start,,,,部分文字列の_始インデックス ? start
Save and Test Webhook,,,,Webフォ`クの保存とテスト
ControlNet v1.1.172,扩散控制网络(ControlNet),,,
Check system info for validity,,,检查系统信息的有效性,
Return the filename ? filename,,,,ファイル名を返す ? filename
System data,系统信息,系统信息,系统信息,
(normally you'd do less with less denoising),,,（默认情况下实际采样步数=滑块显示值×重绘幅度）,
IN_B_03,,模型B 输入层03,模型B 输入层03,
batch,,,batch,
Save images to a subdirectory,将图像保存到子目录,将图像保存到子目录,将图像保存到子目录,画像をサブディレクトリに保存する
Get Images,,,,画像を取得
Send to extras,>> 附加功能,>> 附加功能,>>附加功能,その他に送
IN_A_01,,模型A 输入层01,模型A 输入层01,
Weights,分区权重（每段 子提示词 的权重用逗号分隔）,权重,权重,重み
Save ranking in image's pnginfo,将分级保存到 PNG 文件信息,将分级保存到 PNG 文件信息,将分级保存到 PNG 文件信息,画像のpnginfo にランキングを保存
Use common prompt,使用公共提示词（插入每一段开头，以 ADDCOMM 分隔）,,,共通のプロンプトを使用
Save the foreground masks,,,,前面マスクを保存する
Skip/Reset CLIP position_ids,跳过或重置CLIP position_ids键值,跳过或重置CLIP position_ids键值,跳过或重置CLIP position_ids键值,
Weights setting,权重预设设置,,,
Show Axis,,,,Sを表示
Erode size,侵蚀量,,侵蚀量,浸食サイズ
The Classifier-Free Guidance Scale to use for classifier/regularization images.,用于分类/规范化图像的提示词相关性(CFG Scale - 无分类器指导信息影响尺度(Classifier-Free Guidance Scale)),用于分类/规范化图像的提示词相关性(CFG Scale - 无分类器指导信息影响尺度(Classifier-Free Guidance Scale)),用于分类/规范化图像的提示词相关性(CFG Scale - 无分类器指导信息影响尺度(Classifier-Free Guidance Scale)),
else,,,,その他に
fr,,,,fr
en,,,,en
Simplified Chinese localization.,,,,体字中国Zの翻U
sampler,采样方法(Sampler),采样方法(Sampler),采样方法(Sampler),サンプラ`
Save Metadata,保存元数据,保存元数据,保存元数据,メタデ`タを保存
Checkpoint B,模型B,,,
"Blocks:Element:Ratio,Blocks:Element:Ratio,...","按<Blocks:Element:Ratio,Blocks:Element:Ratio,...>的格式输入信息",,,
Generate Stereo anaglyph image (red/cyan),,,,アナグリフ式立体画像(赤/青) を生成する
Favorites path from settings: log/images,,,,O定からのお荬巳毪辚靴: ログ/画像
Enable Region 8,启用此区域,,启用区域 8,
"To see favicon take affect, you will need to add `favicon_path=""favicon.svg""` to webui.py","想要 网页图标 设置生效，必须在 webui.py 中加入 'favicon_path=""favicon.svg""'","想要 网页图标 设置生效，必须在 webui.py 中加入 'favicon_path=""favicon.svg""'","想要 网页图标 设置生效，必须在 webui.py 中加入 'favicon_path=""favicon.svg""'",
"(directory is hidden if its name starts with ""."".)",,,（以‘.’开头的文件夹将默认为隐藏）,
Use base prompt,使用全局提示词（作用于整个画面，以 ADDBASE 分隔）,,,ベ`スプロンプトを使用
"When reading generation parameters from text into UI (from PNG info or pasted text), do not change the selected model/checkpoint.",从 图片信息 或 粘贴文本 自动读取并填写生成参数时，不要更改选定的 Stable Diffusion 模型(ckpt)（建议开启）,从 图片信息 或 粘贴文本 自动读取并填写生成参数时，不要更改选定的模型(ckpt)（建议开启）,从 图片信息 或 粘贴文本 自动读取并填写生成参数时，不要更改选定的模型(ckpt)（建议开启）,テキストからUIに生成パラメ`タをiみzむ龊(PNG情螭蓼郡腺Nり付けられたテキストから)、xkされたmodel/checkpointは涓しない。
View changes,,,预览修改,
FILM,,,,FILM
img2img_batch_size,每批数量,,,
Annotator resolution,预处理器分辨率（Annotator resolution）,预处理器分辨率（Annotator resolution）,预处理器分辨率（Annotator resolution）,Annotatorの解像度
Info,,,,情
Blurred & stretched overlay,模糊拉伸的叠加层,模糊拉伸的叠加层,模糊拉伸的叠加层,ぼかしと伸ばし加工されたオ`バ`レイ
latte,latte/拿铁（浅色）,latte/拿铁（浅色）,latte/拿铁（浅色）,
ultimate-upscale-for-automatic1111,,,,ultimate-upscale-for-automatic1111
Interrogate: deepbooru score threshold,deepbooru 最低置信度阈值（仅摘录高于此置信度的tag）,deepbooru 最低置信度阈值（仅摘录高于此置信度的tag）,deepbooru 最低置信度阈值（仅摘录高于此置信度的tag）,Interrogate: deepbooruで拾うgZのスコアしきい
"Keyframes: animation settings (animation mode, max frames, border)",,,,キ`フレ`ム: アニメ`ションのO定 (アニメ`ションモ`ド、最大フレ`ム、)
Open Url At Client Side,在客户端打开网址,,在客户端打开网址,
https://github.com/yownas/seed_travel.git,,,,https://github.com/yownas/seed_travel.git
DreamArtist,梦作家,梦作家,梦作家,DreamArtist
kmeans with dithering,,,,k平均法とディザリング
append,放后面,放后面,放后面,末尾に加える
Scale Position,,,,スケ`ルの位置
Concepts List,概念列表,概念列表,概念列表,コンセプトリスト
Action on existing caption,,,现有标题的操作,既存のキャプションにする幼
ControlNet Unit 4,控制单元 4,,ControlNet单元4,
ControlNet v1.1.180,扩散控制网络(ControlNet),,,
Extra network card width,附加网络缩略图宽度,,,
fi_FI Localization,,,,fi_FI Localization
Model Name,模型名称,模型名称,模型名称,
Token Merging - Max downsample,最大向下采样,,,
Set Gradients to None When Zeroing,,,,勾配をゼロにするときにNoneにO定する
Video to Upscale,,,,アップスケ`ルするビデオ
"Output directory for grids; if empty, defaults to two directories below",宫格图的输出目录； 如果为空，则默认为以下两个目录,宫格图的输出目录； 如果为空，则默认为以下两个目录,宫格图的输出目录； 如果为空，则默认为以下两个目录,グリッド画像の出力ディレクトリ(空冥龊稀⒁韵陇2つのディレクトリが定の保存先になります)
Denoising strength change factor,重绘幅度的调整系数,重绘幅度的调整系数,重绘幅度的调整系数,
ScuNET GAN,ScuNET GAN,,,ScuNET GAN
Area 7 Weight,蒙版 7 的权重(Weight),,,
Active,激活,,启用,有炕
Testing,,,,テスト中
Replace underscores with spaces,,用空格替换下划线'_',用空格替换下划线'_',
hue,,,,色相
Always Display Buttons,总是显示额外的按钮,,总是显示本插件按钮,
Denoise,,,,ノイズ除去
Number of samples to generate,要生成的样本数,要生成的样本数,要生成的样本数,
Randomize Highres. Denoising Strength,随机化 高分辨率修复的重绘幅度(Denoising),随机化 高清修复的重绘幅度(Denoising),随机化 高清修复的重绘幅度(Denoising),
ControlNet v1.1.209,扩散控制网络(ControlNet),,,
(extra text to add before <...> when adding extra network to prompt),,,（在<xxxx>之前添加的文本）,
Run from Settings file,,,,O定ファイルからg行
Unlink seed from prompt,将随机种子与提示词解绑,将随机种子与提示词解绑,将随机种子与提示词解绑,シ`ドをプロンプトからリンク解除
leakyrelu,leakyrelu,,,leakyrelu
load,加载,,,iみzみ
Weight values,权重值(手动输入),权重值,权重值,
values,权重值,,,
Init,,初始,初始,初期化
Load model paramters from the last training session.,从上次训练中加载模型参数,从上次训练中加载模型参数,从上次训练中加载模型参数,
Generates image when every cycle finishes,,,,各サイクルK了rに画像を生成する
house-scribbles,,,,家-落き
[ControlNet] Guidance Start,,,,[ControlNet] ガイダンス_始
Perlin persistence,,,,パ`リンノイズのさ
Enable Maintenance tab,启用 维护 选项卡,启用 维护 选项卡,启用 维护 选项卡,メンテナンス タブを表示
"3. If you change some tags into blank, they will be erased.",3.如果一些 Tag 被改为空白，它们将被删除,,,3. タグを空白に浃à毪取⑾去されます。
Max Gradient norms.,最大梯度范数(Max Gradient norms),最大梯度范数(Max Gradient norms),最大梯度范数(Max Gradient norms),
Image for Auto Segmentation,需要使用 Auto SAM 处理的图像,,上传要分割的图片,
(1) Face Detection,,,(1) 面部检测,
z-a,首字母降序,,,z-a（降）
Save options:,,,,オプションの保存
spaceship,,,,宇宙船
Step Ratio of Text Encoder Training,,,,テキストエンコ`ダトレ`ニングのステップ比率
Sampling settings,,采样设置,采样设置,
webui-user.bat,,,,webui-user.bat
Latent (bicubic antialiased),Latent（双立方抗锯齿）,潜变量 (bicubic 抗锯齿),潜变量 (bicubic 抗锯齿),Latent (バイキュ`ビック アンチエイリアスag)
controlnet input,,,ControlNet输入,
Live previews,实时预览,实时预览,实时预览,ライブプレビュ`
Append the content to the variable's current value ? _append,,,,涫のF在のにコンテンツを追加? _append
Unload model after running,完成后从显存中卸载模型 (推荐勾选),完成后从显存中卸载模型 (推荐勾选),完成后从显存中卸载模型 (推荐勾选),g行後にモデルをアンロ`ドする
ps,,,,ps
Batch,批量处理,批量处理,批量处理,バッチ
t2ia_style_clipvision,风格转移（t2iadapter_style 模型，Clip Vision 算法),,t2ia自适应 - 风格转移（style_clipvision),
Model Converter,模型格式转换,模型格式转换,模型格式转换,Model Converter
Latent tile width,潜空间图块(Latent tile)宽度,潜变量分块(Latent tile)宽度,潜变量分块(Latent tile)宽度,Latentタイルの幅
Previous Page,,前一页,前一页,
succinctly/text2image-prompt-generator,,,,succinctly/text2image-prompt-generator
"It takes time, just wait. Check console log for detail",用时较长，请打开控制台查看详细日志,这将会花费一些时间，请在控制台中查看详细信息,这将会花费一些时间，请在控制台中查看详细信息,
grad_min,最小梯度,最小梯度,最小梯度,
Sigma Churn,Sigma Churn,,,Sigma Churn
gd,,,,gd
Destination Directory,目标目录,,,出力ディレクトリ
Output directory for masks,蒙版输出目录,蒙版输出目录,蒙版输出目录,
Layer3,,,,Layer3
"Guess what - this will be incredibly slow, but it will work for < 8GB GPUs.",你猜怎么着 - 这将非常地慢我的老伙计，但它适用于 < 8GB 显存(VRAM)的 GPU,你猜怎么着 - 这将非常地慢我的老伙计，但它适用于 < 8GB 显存(VRAM)的 GPU,你猜怎么着 - 这将非常地慢我的老伙计，但它适用于 < 8GB 显存(VRAM)的 GPU,
Don't outfill,不进行填充,不进行填充,不进行填充,Tりつぶさない
Proxy,代理服务器,,,
Label,标记,标记,标记,ラベル
Select joining char,选择分隔符,选择分隔符,选择分隔符,Y合の区切り文字をxk
Filter Images by Tags,按 Tag 筛选出的图片,,,タグで画像をフィルタ`
Filename join string,文件名连接用字符串,文件名连接用字符串,文件名连接用字符串,ファイル名のY合子
img2img_autosize,,,,img2img 自鹰单ぅ
ControlNet v1.1.145,扩散控制网络(ControlNet),,,
Sample Prompt File,,,,サンプルプロンプトファイル
ControlNet-8,控制网络-8,,,
"Ids for tokenization (example: 9061, 631, 736)","用于词元化的 ID (例： 9061, 631, 736)","用于词元化的 ID (例： 9061, 631, 736)","用于词元化的 ID (例： 9061, 631, 736)","IDのト`クン化 (例: 9061, 631, 736)"
Translation X,,,,XS方向の移
Enable Pixel Perfect from lllyasviel. Configure your target width and height on txt2img/img2img default panel before preview if you wish to enable pixel perfect.,自动设置预处理器分辨率（需要提前设置好生成图像的画布尺寸作为输入）,,启用ControlNet中的对齐预处理和输出图片分辨率,
Rating confidents,分级信息置信度,分级信息置信度,分级信息置信度,レ`ティングの信m度
"Prompt, will be appended to your t2i prompt",输入区域提示词(Prompt),,,
seed_schedule should start and end on the same seed.,,,,seed_schedule は同じシ`ドで_始およびK了する必要があります。
"LoRAname1:ratio1:Blocks1,LoRAname2:ratio2:Blocks2,...("":blocks"" is option, not necessary)","合并信息（格式：<LoRAname1:ratio1:Blocks1,LoRAname2:ratio2:Blocks2,...>，“block”为可选项）",,,
Add inpaint batch mask directory to enable inpaint batch processing.,,,要使用重绘批量处理的话，需要输入输入重绘批处理蒙版所在目录,inpaintバッチI理を有郡摔工毪摔稀inpaintバッチマスクディレクトリを追加してください。
"Regular expression; if weights's name matches it, the weights is not written to the resulting checkpoint. Use ^model_ema to discard EMA weights.","与写入内容名称匹配的权重信息将不会写入输出的模型（可以通过写入""^model_ema""以舍弃模型中的EMA信息）","与写入内容名称匹配的权重信息将不会写入输出的模型（可以通过写入""^model_ema""以舍弃模型中的EMA信息）","与写入内容名称匹配的权重信息将不会写入输出的模型（可以通过写入""^model_ema""以舍弃模型中的EMA信息）",正表F; Weightsの名前が一致する龊稀WeightsはCheckpointにきzまれません。^ model_ema を使用してEMA Weightsを破します。
bicubic,,,,バイキュ`ビック
https://github.com/animerl/novelai-2-local-prompt.git,,,,https://github.com/animerl/novelai-2-local-prompt.git
Installing...,安装中…,安装中…,安装中…,
Cutoff Targets,,,,Cutoff 象となるト`クン
"Path to directory containing annotator model directories (requires restart, overrides corresponding command line flag)",包含预处理器模型目录的目录的路径（需要重新启动，覆盖相应的命令行标志）,,预处理器的模型路径（需要重启，会覆盖命令行的路径设置参数）,
prelu,prelu,,,prelu
Override settings,临时覆盖性设置（从复制的完整生成参数读入）,覆盖设置,覆盖设置,O定を上き
Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.,,,,Hypernetworkのための追加学C能を提供するC能です。また、推のための}数のHypernetworksの使用もサポ`トします。
lighten,,,,比^ 明
"(0 = default (7 for karras, 1 for polyexponential); higher values result in a more steep noise schedule (decreases faster))",,,（0 = 默认值（karras为7，多项式指数为1）；更高的值会导致强烈的噪声调度（收敛更快））,
Create masks for img2img based on a depth estimation made by MiDaS.,,,,MiDSの深度推定に基づいてimg2img用のマスクを作成します。
Colorerrorhover,Colorerrorhover,,,
Send to Layer2,,,,レイヤ`2に送
tanh,tanh,,,tanh
effective elemental checker,有效元素筛查,,,
Search by alias,使用别称搜索,使用别称搜索,使用别称搜索,エイリアスで仕
title,,标题,标题,
Show description of how to edit tags,显示 Tag 编辑的说明,,,タグを集する方法のh明を表示
/path/to/images/* or /path/to/images/**/*,,/图像/的/路径/* 或 /图像/的/路径/**/*,/图像/的/路径/* 或 /图像/的/路径/**/*,
Cond.fix: Empty,修复时调节：空掉,修复时调节：空掉,修复时调节：空掉,Cond.fix: なし
Enable Tiled Diffusion,启用 分块扩散(Tiled Diffusion),,启用Tiled Diffusion,
Preprocessor,"预处理器（直接上传模式图或草稿时可选""无""）","预处理器（直接上传模式图或草稿时可选""无""）","预处理器（直接上传模式图或草稿时可选""无""）",プリプロセッサ
Config Name,,,配置名称,
Batch img2img,批量图生图,批量图生图,批量图生图,
Max steps,最大迭代步数,最大迭代步数,最大迭代步数,最大ステップ数
The code for this extension:,,,,このC能のコ`ド:
color_dodge,,,,覆いきカラ`
Download,下载至本地,,,
u2net_cloth_seg,,,,u2net 衣装区分
Prompt Travel,提示词变迁,提示词变迁,提示词变迁,
Source directory,源目录,源目录,源目录,元となるディレクトリ
Shows a gallery of generated pictures by artists separated into categories.,将艺术家按类别划分，并显示其生成出来的图像,将艺术家按类别划分，并显示其生成出来的图像,将艺术家按类别划分，并显示其生成出来的图像,カテゴリに分けられたア`ティストが生成した画像のギャラリ`を表示します。
Append Caption to File Name,把描述文本接在文件名后面,把描述文本接在文件名后面,把描述文本接在文件名后面,
Saved elements from txt2img,,,,txt2imgから保存された要素
{2$$__artist__},{2$$__艺术家__},{2$$__艺术家__},{2$$__艺术家__},{2$$__artist__}
Hypernetwork Learning rate,超网络学习率,超网络学习率,超网络学习率,Hypernetworkの学率(Learning rate)
Subseed controls & More,,,,サブシ`ドコントロ`ルとその他のC能
in,,,,in
(M8) Multiplier,,(M8) 倍率,(M8) 倍率,
Transformer,,,,湫
Important notes:,,,,重要な注意事
Allows you to manually edit textual inversion embeddings using sliders.,让你可以手动用滑条编辑风格迁移 Embeddings 的参数,让你可以手动用滑条编辑风格迁移 Embeddings 的参数,让你可以手动用滑条编辑风格迁移 Embeddings 的参数,スライダ`を使用してtextual inversionの埋めzみを手婴蔷集できます。
ControlNet v1.1.168,扩散控制网络(ControlNet),,,
Position/Rotate Y,,,,位置/yS回
https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git,,,,https://github.com/AUTOMATIC1111/stable-diffusion-webui-tokenizer.git
space,空格,空格,空格,スペ`ス
yi,,,,yi
Specify different prompts for different regions; an alternative method and potential improvement to latent couple.,,,,なるI域になるプロンプトを指定します。Latent Coupleに代わる方法であり、改善の可能性があります。
"Negative Prompt, will also be appended",输入区域负面提示词(Negative Prompt),,反向提示词，同样会附加到原始反向提示词中,
ignore,无视,无视,无视,oする
"View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547",,,,なるレイヤ`を表示し、U-Netの特榨蕙氓驻蛴Q察します。各ブロックになるプロンプトを与えることで画像を生成します。: https://note.com/kohya_ss/n/n93b7c01b0547
File editor,,,,ファイルエディタ`
Save Setting,保存设置,,保存设置,O定を保存
Filename format,,,,ファイル名の形式
Custom Config File,自定义配置文件,,配置文件,
Tile size for SCUNET upscalers. 0 = no tiling.,,,使用SCUNET upscalers时的Tile size，取0的话表示不分块,
"Result = ""Y, Y, X, C""?(B->X, A->Y)","　　结果：“Y, Y, X, C”（ B->X，A->Y ）",,,"Y果= ""Y、Y、X、C"" (B->X、A->Y)"
Model Pre?views,,,,モデルのプレビュ`
Status,,,,ステ`タス
Enable tensorboard logging.,启用 tensorboard 日志记录,启用 tensorboard 日志记录。,启用 tensorboard 日志记录。,テンソルボ`ドのログを有郡摔筏蓼埂
Affected areas,,,生效区域,
Max prompt words for [prompt_words] pattern,[prompt_words] 格式的最大提示词数量,[prompt_words] 格式的最大提示词数量,[prompt_words] 格式的最大提示词数量,[prompt_words] パタ`ンのプロンプトワ`ドの最大
overwrite,覆写模型,,,
LLuL Apply to,,,,LLuLm用先
"4. If you add some tags to the end, they will be added to the end/beginning of the text file.",4.在末尾添加的 Tag 将被添加到文本文件的末尾/开头,,,4. タグを最後に追加すると、テキストファイルの最後/最初に追加されます。
This extension works well with text captions in comma-separated style (such as the tags generated by DeepBooru interrogator).,此扩展可以很好地与逗号分隔样式的文本标题配合使用（例如 DeepBooru 反推算法生成的 Tag）,,,このC能は、カンマ区切りスタイル(DeepBooru interrogatorによって生成されたタグなど) のテキストキャプションでうまく幼鳏筏蓼埂
CodeFormer visibility,CodeFormer 可见度,CodeFormer 可见度,CodeFormer 可见度,CodeFormeの表示
positive,正面,正面,正面,ポジティブ
MP4 path,,,,MP4のパス
CLiP model,CLiP模型,CLiP模型,CLiP模型,
grad_max,最大梯度,最大梯度,最大梯度,
auto,自动,自动,自动,
AddNet Weight 4,[附加网络] 权重 4,[可选附加网络] 权重 4,[可选附加网络] 权重 4,重み 4(AddNet)
Force CPU (Requires Custom Script Reload),,,,制的に CPU (カスタムスクリプトの再iみzみが必要)
Show progress indicator,显示进度条,,显示进度条,
softedge_pidinet,边缘检测（softedge 模型，PiDiNet 算法）,,软边缘检测（softedge，PiDiNet 算法）,
!,,,,!
Path relative to the webui folder,,webui文件夹的相对路径,webui文件夹的相对路径,
Pick Subfolder and Model Version,选自子文件夹与模型版本,选择子文件夹和模型版本,选择子文件夹和模型版本,
Name matching rule for preview files,,,,プレビュ`ファイルのネ`ムマッチングt
ro,,,,ro
Reflect image around border,从边缘镜像图像内容,从边缘镜像图像内容,从边缘镜像图像内容,境界の周りの画像を反映する
spaceship-digipa-high-impact,,,,宇宙船演算子(digipa-high-impact)
tp__modernMt,,,,tp__modernMt
sd_model_hash,,,,sdモデルハッシュ
veryfast,,,,とても速い
Minimum Score for WD14 Tags,,,,WD14 タグの最小スコア
https://github.com/journey-ad/sd-webui-bilingual-localization.git,,,,https://github.com/journey-ad/sd-webui-bilingual-localization.git
Single,,,,g一
Magic prompt creativity,魔法提示词创意,魔法提示词创意,魔法提示词创意,Magic prompt の造性
PNG info,PNG 图片信息,,,
DPM fast,DPM fast,,,DPM fast
Control Weight,干涉权重(Weight),,干涉权重,
Add difference,添加差分,加上差值,加上差值,差を加える
ControlNet - 3,扩散控制网络(ControlNet) - 3,,,
translated text,译文,,,翻Uされた文字列
(0 = default (~0.03); minimum noise strength for k-diffusion noise scheduler),,,（0 = 默认值（~0.03）；k-diffusion噪声调度器的最小噪声强度）,
Use wildcards for negative prompts,,,通配符（wildcards）对于反向提示词也生效,
SLerp,,球面线性插值,球面线性插值,球面形ag
Extract to frame,,,,フレ`ムへの抽出
Saves when every cycle finishes,,,,各サイクルK了rに保存する
case: Use within [switch] to run different logic blocks depending on the value of a var.,,,,例：var のに辘袱飘なるロジックブロックをg行するには [switch] 内で使用します。
ceb,,,,ceb
UniPC order,,,UniPC阶数,
restore_faces,,,,修
Save Preview(s) Frequency,保存预览的频率,保存预览的频率,保存预览的频率,
Use grid (output to grid dir),,,,グリッドを使用 (グリッドdirに出力)
hyponyms,,,,下位概念
Result delimiter ? _delimiter,,,,Y果の区切り文字 ? _delimiter
Save Intermediate Images,,,,Save Intermediate Images
"Path to JSON file with concepts to train, or a JSON string.",包含要训练的概念的 JSON 文件的路径，或 JSON 字符串,包含要训练的概念的 JSON 文件的路径，或 JSON 字符串,包含要训练的概念的 JSON 文件的路径，或 JSON 字符串,
Please use smaller tile size when got CUDA error: out of memory.,,,如果显存溢出（out of memory）的话，请使用更小的Tile Size,
Pix2Pix img CFG schedule,,,,Pix2Pix img CFG スケジュ`ル
uk,,,,uk
Reset Pose,重置动作,重置动作,重置动作,
A&B,A&B,,,
latent noise,潜空间噪声,潜变量噪声,潜变量噪声,潜在空gでのノイズ
img2img,图生图,图生图,图生图,img2img
(changes seeds drastically; use CPU to produce the same picture across different videocard vendors),,,(GPU的话可能会因为显卡不同而导致图片不能复现，使用CPU的话可以较高的保证图片复现),
c,,,,c
DEIS,,,,DEIS
Checkpoint schedule,,,,Checkpoint schedule
ControlNet v1.1.169,扩散控制网络(ControlNet),,,
"Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.",,,,"Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability."
Waifu,,,,Waifu
Uses your,,,,　人用O定を使用
softmin,softmin,,,softmin
Sanity Sample Prompt,,,,正常性_J用サンプルのプロンプト
Favorites,收藏夹(已保存),收藏夹(已保存),收藏夹(已保存),お荬巳毪
Drop File Here,拖拽文件到此处,拖拽文件到此,拖拽文件到此,ここにファイルをドロップ
deforum.github.io,,,,deforum.github.io
Disable image generation. Useful if you only want to generate text prompts.,禁用图像生成。如果你只想生成文本提示词的话,禁用图像生成。如果你只想生成文本提示词的话,禁用图像生成。如果你只想生成文本提示词的话,
wd14-swinv2-v2-git,,,,wd14-swinv2-v2-git
Top p,,,,Top p
Print warning logs to the console,将警告信息输出到控制台（不建议开启）,将警告信息输出到控制台,将警告信息输出到控制台,警告ログをコンソ`ルに出力
Apply Favicon (edit webui.py to see),应用网页图标（编辑 webui.py 后可见）,应用网页图标（编辑 webui.py 后可见）,应用网页图标（编辑 webui.py 后可见）,
Training Epochs,,训练多少期(Epochs),训练多少期(Epochs),
save_sample_per_step,,每步都储存样本,每步都储存样本,
sn,,,,sn
Advanced,高级,高阶,高阶,高度なO定
extra,附加,,外部的,外部C能
Run settings,,运行设置,运行设置,
Set Random Pose,使用随机动作,,,
German localization,,,,ドイツZ翻U
Don't apply to negative prompts,,,,ネガティブプロンプトにはm用しない
ControlNet v1.1.5,扩散控制网络(ControlNet),,,
Finnish localization,,,,フィンランドZ翻U
Provide Simplified Chinese localization for the WebUI,提供简体中文本地化翻译,提供简体中文本地化翻译,提供简体中文本地化翻译,
linear_dodge,,,,linear_dodge
Save training setting,,,,トレ`ニングO定を保存
ControlNet v1.1.230,扩散控制网络(ControlNet),,,
Artist or styles name list. '.txt' files with one name per line,,,,ア`ティスト名やスタイル名のリスト。1行に1つの名前を含む'.txt'ファイル
ControlNet v1.1.201,扩散控制网络(ControlNet),,,
webui,WebUI 本体,,,
img2img DDIM discretize,图生图 DDIM 离散化,图生图 DDIM 离散化,图生图 DDIM 离散化,img2img DDIM discretize
Use spaces instead of underscore,使用空格替代下划线 (推荐勾选),使用空格替代下划线 (推荐勾选),使用空格替代下划线 (推荐勾选),アンダ`スコアの代わりにスペ`スを使用する
Reset Aspect Ratio,重置纵横比,重置纵横比,重置纵横比,アスペクト比をリセット
"Search for ""Command Prompt"" in the Start Menu, right-click and click ""Run as Administrator..."", paste the follow commands and hit Enter:",,,,スタ`トメニュ`で「コマンドプロンプト」を仕鳏贰⒂谣リックして「管理者としてg行...」をクリックし、以下のコマンドをNり付けてEnterを押します。
nl,,,,nl
sd-webui-enable-checker,,,,sd-webui-enable-checker
"Prompts are stored in JSON format. If you've got an error, check it in validator,",,,,プロンプトは JSON 形式で保存されます。エラ`がk生した龊悉稀バリデ`タで_Jしてください。
Inpaint,局部重绘,局部重绘,局部重绘,inpaint
Sigma schedule,,,,Sigma schedule
polynomial,多项式(polynomial),多项式(polynomial),多项式(polynomial),多式
cosine,余弦(cosine),余弦(cosine),余弦(cosine),コサイン
Update instructions:,,更新指引（英文）：,更新指引（英文）：,
IN_A_08,,模型A 输入层08,模型A 输入层08,
OUT_B_08,,模型B 输出层08,模型B 输出层08,
Leave empty to use txt2img batch controlnet input directory,留空默认使用 文生图 扩散控制网络 的输入目录,,,
Control Type,,,控制类型,
ControlNet v1.1.151,扩散控制网络(ControlNet),,,
(not for Video Input mode),,,,(ビデオ入力モ`ドではない)
Prevent empty spots in grid (when set to autodetect),启用自动检测时，宫格图中不用空位填充（不开启时3张图会以2×2的形式排列，其中第四幅图为空，开启后行列仅可能为图片数量的因数）,启用自动检测时，宫格图中不用空位填充（不开启时3张图会以2*2的形式排列，其中第四幅图为空，开启后行列仅可能为图片数量的因数）,启用自动检测时，宫格图中不用空位填充（不开启时3张图会以2*2的形式排列，其中第四幅图为空，开启后行列仅可能为图片数量的因数）,(自釉O定のとき)グリッドに空隙が生じるのを防ぐ
Generate,生成,生成,生成,生成
"Total number of classification/regularization images to use. If no images exist, they will be generated. Set to 0 to disable prior preservation.",要使用的分类/规范化图像总数。如果没有图像，就生成一些。设置为 0 以禁用先验存留(prior preservation),要使用的分类/规范化图像总数。如果没有图像，就生成一些。设置为 0 以禁用先验存留(prior preservation),要使用的分类/规范化图像总数。如果没有图像，就生成一些。设置为 0 以禁用先验存留(prior preservation),
"The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.",Deforum 的官方移植，一个用于 2D 和 3D 动画的扩展脚本，支持关键帧序列、动态数学参数（甚至可用于提示词内）、动态蒙版、深度预测和变形,Deforum 的官方移植，一个用于 2D 和 3D 动画的扩展脚本，支持关键帧序列、动态数学参数（甚至可用于提示词内）、动态蒙版、深度预测和变形,Deforum 的官方移植，一个用于 2D 和 3D 动画的扩展脚本，支持关键帧序列、动态数学参数（甚至可用于提示词内）、动态蒙版、深度预测和变形,"Deforumの公式ポ`ト, つまり2Dおよび3Dアニメ`ションのための诠なスクリプトで、 キ`フレ`ム可能なシ`ケンス、拥氖学パラメ`タ(プロンプト内でも)、拥磨蕙攻ング、深さ推定、およびワ`ピングをサポ`トしています。"
hypernyms: Replaces the content with one or more hypernyms.,,,,hypernyms: コンテンツを1つ以上の上位Zで置きQえます。
"Negative Prompt, will be appended too.",输入区域负面提示词(Negative Prompt),,,
ControlNet v1.1.108,扩散控制网络(ControlNet),,,
Others,其他,其他,其他,その他
de_DE Localization,,,,de_DE Localization
vivid_light,,,,ビビッドライト
(C3) Thertiary,,(C3) 第三,(C3) 第三,
Tag confidents,Tag置信度,标签置信度,标签置信度,タグの信m度
N Batch,,,,NバッチI理
"Uses the lexica.art API to create random prompts.\nThe prompt in the main prompt box is used as a search string.\nLeaving the prompt box blank returns a list of completely randomly chosen prompts.\nTry it out, it can be quite fun.",用 lexica.art API 生成随机提示词\n提示词框中的内容会作为搜索字符串\n留空提示词框会得到一组完全随机选择的提示词\n用用看，它会很有趣,用 lexica.art API 生成随机提示词\n提示词框中的内容会作为搜索字符串\n留空提示词框会得到一组完全随机选择的提示词\n用用看，它会很有趣,用 lexica.art API 生成随机提示词\n提示词框中的内容会作为搜索字符串\n留空提示词框会得到一组完全随机选择的提示词\n用用看，它会很有趣,Lexica.art API を使用してランダムなプロンプトを作成します。\nメインのプロンプトボックスのプロンプトは、仕魑淖至肖趣筏剖褂盲丹欷蓼埂\nプロンプトボックスを空白にすると、完全にランダムにxばれたプロンプトのリストが返されます。\nなかなかSしいのでしてみてください。
alpha,α 值,,,
Panorama Viewer,,,,Panorama Viewer
Inpaint not masked,重绘非蒙版内容,重绘非蒙版内容,重绘非蒙版内容,マスクの煲酝猡inpaint
Border,,,,境界
Favicon,网页图标,网页图标,网页图标,
BMBL,,,,BMBL
Separate UNet/Text Encoder weights,单独设置 UNet/Text Encoder 的权重,单独设置 UNet/Text Encoder 的权重,单独设置 UNet/Text Encoder 的权重,U-Net と Text Encoder の重みをe々に指定する
DDIM,DDIM,,,DDIM
Dominant image color,图像主色,图像主色,图像主色,主要画像色
Image for Recognition,识别分辨率（以处理时间换取准确性）,,,
Date,发布日期,,日期,
OUT_A_02,,模型A 输出层02,模型A 输出层02,
Remove,移除,移除,移除,削除
Mask size,,,蒙版尺寸,
Checkpoint A,模型A,,,
Weight_values,权重值(手动输入),权重值(手动输入),权重值(手动输入),
Use old karras scheduler sigmas (0.1 to 10).,使用旧的Karras调度器sigma值(0.1-10),使用旧的Karras调度器sigma值(0.1-10),使用旧的Karras调度器sigma值(0.1-10),古いKarras SchedulerのSigmaを使う (0.1 ~ 10)
txt2img_cfg_scale,提示词相关性(CFG Scale),,,
Attempt to automatically set training parameters based on total VRAM. Still under development.,尝试根据总显存(VRAM)自动设置训练参数。仍在开发中,尝试根据总显存(VRAM)自动设置训练参数。仍在开发中,尝试根据总显存(VRAM)自动设置训练参数。仍在开发中,
ControlNet v1.1.105,扩散控制网络(ControlNet),,,
Adam Beta 2,Adam Beta 2,,,
Mask by Category,按类别添加蒙版,,语义分割蒙版,
Tags To Ignore,,,,oするタグ
X/Y Plus-1.4.2,X/Y图表 Plus,X/Y图表 Plus,X/Y图表 Plus,
Path to directory where to write outputs,进行输出的目录路径,进行输出的目录路径,进行输出的目录路径,出力をきzむディレクトリへのパス
tp__papago,,,,tp__papago
canny,边缘检测（canny 模型，Canny 算法）,Canny 边缘检测（Canny edge detection）,硬边缘检测（canny，Canny 算法）,キャニ`法
Live preview subject,实时预览的主题,实时预览的主体,实时预览的主体,ライブプレビュ`象
Dataset Tag Editor,数据集 Tag 编辑器,数据集标签编辑器,数据集标签编辑器,Dataset Tag Editor
colors,,,,色数
Legacy hash,旧哈希值,旧哈希值,旧哈希值,纠搐违膝氓伐
image,图像,,,
Layer1 mask strength,,,,レイヤ`1のマスク不透明度
Save mask,保存蒙版,,保存蒙版,
Guide,,,,ガイド
Step size,步幅 (梯度模式),步幅 (梯度模式),步幅 (梯度模式),
Override `prompt` to the same value as `original prompt`?(and `negative prompt`),覆写 `提示词` 为 `初始提示词`?(`负面提示词` 同理),覆写 `提示词` 为 `初始提示词`?(`反向提示词` 同理),覆写 `提示词` 为 `初始提示词`?(`反向提示词` 同理),プロンプトをオリジナルプロンプトと同じに上きする(ネガティブプロンプトも同)
Save images with embedding in PNG chunks,保存图像，并在 PNG 图片文件中嵌入 Embedding 文件,保存图像，并在 PNG 图片文件中嵌入 Embedding 文件,保存图像，并在 PNG 图片文件中嵌入 Embedding 文件,保存する画像にembeddingを埋めzむ
Generate layout for single image,生成单张图像的图片布局,,开始拆分,
Strength 0 no init,,,,度0では初期化しない
Usage Guide,,,,利用案内
Reload Presets,重新加载预设,,,
Collect,收藏(保存),收藏(保存),收藏(保存),取得する
"Scan Exif-/.txt-data (slower, but required for exif-keyword-search)",扫描图片的 Exif 信息与同名 txt 文件（会拖慢读取速度，但使用搜索生成信息关键字的时候必须开启）,扫描图片的 Exif 信息与同名 txt 文件（会拖慢读取速度，但使用搜索生成信息关键字的时候必须开启）,扫描图片的 Exif 信息与同名 txt 文件（会拖慢读取速度，但使用搜索生成信息关键字的时候必须开启）,Exif-/.txt-data をスキャンします (低速ですが、EXIF キ`ワ`ド仕 に必要です)
ukioe,,,,浮世}
Save,保存,保存,保存,保存
ControlNet v1.1.163,扩散控制网络(ControlNet),,,
libraries,库信息,,,
Update Guide,,,,更新ガイド
* Paths can be relative to webui folder OR full - absolute,,,,* パスはwebuiフォルダにして相的な鏊でも、完全な~パスでも指定できます。
ranking,评分,评分,评分,ランキング
https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git,,,,https://github.com/7eu7d7/DreamArtist-sd-webui-extension.git
Remove Background %,背景排除（%）,背景排除（%）,背景排除（%）,
Sample Height,,,,サンプル高さ
editing,编辑相关,编辑,编辑,集中
selu,selu,,,selu
List of prompt inputs,提示词输入列表,提示词输入列表,提示词输入列表,入力プロンプトのリスト
GFPGAN visibility,GFPGAN 可见度,GFPGAN 可见度,GFPGAN 可见度,GFPGANの表示
OUT10,,输出层10,输出层10,
Y offset (A),Y 偏移 (A),Y 偏移 (A),Y 偏移 (A),
Multi ControlNet: Max models amount (requires restart),多网络联合扩散控制(Multi ControlNet)的最大网络数量（需要保存设置并重启，启用后可同时设置多个扩散控制网络，允许不同模型联合控制与相同模型叠加控制，可用于约束多人动作，也可用于多维度约束）,Multi ControlNet 的最大网络数量（需要保存设置并重启，启用后可同时设置多个 ControlNet，允许不同模型联合控制与相同模型叠加控制，可用于约束多人动作，也可用于多维度约束）,Multi ControlNet 的最大网络数量（需要保存设置并重启，启用后可同时设置多个 ControlNet，允许不同模型联合控制与相同模型叠加控制，可用于约束多人动作，也可用于多维度约束）,Multi ControlNet: 最大モデル数 (再起婴必要)
Current Cache,当前缓存,,,
ControlNet Unit 8,控制单元 8,,,
Step size ? step,,,,ステップサイズ ? step
LMS,LMS,,,LMS
"Set this or number of steps to train for, not both.",设置这个或者'训练迭代步数'，两者不能同时用,设置这个或者'训练迭代步数'，两者不能同时用,设置这个或者'训练迭代步数'，两者不能同时用,
UNet Weight 1,UNet 权重 1,UNet 权重 1,UNet 权重 1,UNetの重み 1
should be 2 or lower.,应小于等于2,应小于等于2,应小于等于2, は2以下にしてください。
Learning rate,学习率,学习率,学习率,
CFG Scale Scheduler,提示词相关性(CFG Scale) 调度函数,,,
Do not do anything special,什么都不做,什么都不做,什么都不做,特eなことをなにもしない
txt2img/img2img UI item order,文生图/图生图界面UI顺序,文生图/图生图界面UI顺序,文生图/图生图界面UI顺序,txt2img/img2img UI アイテムの序
Motion,,,,幼
"This panel is for those who want to upload mask to ControlNet inpainting. It is not part of SAM's functionality. By checking the box below, you agree that you will disable all functionalities of SAM.",此面板适用于那些希望将蒙版上传到 ControlNet 进行局部重绘的用户。这不是 Segment Anything Model 功能的一部分。勾选下面的框，表示您同意禁用 Segment Anything Model 的所有功能。,,这个子页是用于上传蒙版到ControlNet重绘，这不是SAM的功能，勾选下方的勾选框将禁用SAM所有功能（防止冲突）,
ControlNet v1.1.133,扩散控制网络(ControlNet),,,
sensitive,敏感内容/Sensitive（轻微性暗示）,轻微性暗示/敏感内容（Sensitive）,轻微性暗示/敏感内容（Sensitive）,
point3 x,,,,点3_横
Generate Info,生成信息,生成信息,生成信息,生成rの情
Script,脚本,脚本,脚本,スクリプト
az,,,,az
Uses the image's filename as the image labels instead of the instance prompt,使用图像的文件名作为图像标签而非实例提示词,使用图像的文件名作为图像标签而非实例提示词,使用图像的文件名作为图像标签而非实例提示词,
Only Show Models have no Info file,仅显示当前未在本地创建 信息文件 的模型,,,
Interrogate Selected Image,用算法反推选中图像的注释,,,xkした画像を精摔工
Auto-Adjust (WIP),自动调整 (施工中),自动调整 (施工中),自动调整 (施工中),
Enable scribble mode if your image has white background.,使用白色背景图片时请启用涂鸦模式,使用白色背景图片时请启用涂鸦模式,使用白色背景图片时请启用涂鸦模式,
Inspiration,灵感,灵感,灵感,Inspiration
Inpaint batch mask directory (required for inpaint batch processing only),,,重绘批处理蒙版目录（当需要重绘批量处理时）,inpaintバッチマスクディレクトリ (inpaintバッチI理でのみ必)
fill left,,,,左に
loss,,,,p失
FPS,,,,フレ`ムレ`ト
Sanity Sample Seed,,,,正常性_J用サンプルのシ`ド
JSON Validator,,,,JSONバリデ`タ
Layer5 mask strength,,,,Layer5 マスクの不透明度
AddNet TEnc Weight 5,[附加网络] Text Encoder 权重 5,[可选附加网络] Text Encoder 权重 5,[可选附加网络] Text Encoder 权重 5,TEncの重み 5(AddNet)
OUT05,,输出层05,输出层05,
here,这里,这里,这里,ここへ
alternate,,,,代替
Move buttons copy instead of move,"将图库浏览器内所有""移动""按钮改为""复制""按钮","将图库浏览器内所有""移动""按钮改为""复制""按钮","将图库浏览器内所有""移动""按钮改为""复制""按钮",移鹰堀骏螭稀敢印工扦悉胜「コピ`」に
AddNet TEnc Weight 3,[附加网络] Text Encoder 权重 3,[可选附加网络] Text Encoder 权重 3,[可选附加网络] Text Encoder 权重 3,TEncの重み 3(AddNet)
"is also a good option, it makes compact math formulae for Deforum keyframes by selecting various waveforms.",,,,は、さまざまな波形をxkすることで、Deforum キ`フレ`ムの数式もコンパクトになります。
Cutoff strongly.,强效分离,,强化阻断！,く遮断する
article: Returns the content with prefixed with a definite or indefinite article.,,,,article: 定冠~または不定冠~を前置してコンテンツを返します。
Engine,,,,エンジン
Choose your favorite mask:,选择一个效果较好的蒙版结果：,,选择要使用的蒙版编号,
Arbitrary replacement arguments in old=new format ? verbatim,,,,old=new形式の任意の置Q引数 ? verbatim
Left click the image to add one positive point (black dot). Right click the image to add one negative point (red dot). Left click the point to remove it.,左键单击创建正面提示点（黑点，纳入蒙版区域），右键单击创建负面提示点（红点，排除出蒙版区域），左键单击可删除提示点,,在图片上左键点击标注要保留的部分（黑点）.右键点击标注要去掉的部分（红点）.再次点击已有的点可以去除标注。,
[ControlNet] Model,[ControlNet] 模型,[ControlNet] 模型,[ControlNet] 模型,[ControlNet] モデル
- Body,--人体模型--,--人体模型--,--人体模型--,
Removes backgrounds from pictures.,,,,画像から背景を削除します。
CLIP skip schedule,,,,CLIPスキップのスケジュ`ル
hires_upscaler,,,,高解像度に大
Comp mask auto contrast cutoff low schedule,,,,コンポジットマスクの自鹰偿螗去楗攻趣蜗孪蕙攻饱弗濠`ル
zh_TW Localization,正w中文Z言包,正w中文Z言包,正w中文Z言包,zh_TW Localization
Maximum number of images in upscaling cache,图像放大缓存中的最大图片数量,图像放大缓存中的最大图片数量,图像放大缓存中的最大图片数量,upscalingキャッシュの最大枚数
Show all pages,显示所有页面,显示所有页面,显示所有页面,すべてのペ`ジを表示
Get Model Info from Civitai by URL,通过 Civitai网址 获取模型信息,使用URL从Civitai获取模型信息,使用URL从Civitai获取模型信息,
Play/Pause,,,,再生/一r停止
dog-c,,,,犬-C
ControlNet v1.1.290,扩散控制网络(ControlNet),,,
Scheduler,调度器(Scheduler),调度器(Scheduler),调度器(Scheduler),
zh_CN Localization,简体中文语言包,简体中文语言包,简体中文语言包,zh_CN Localization
while,,,,～するg
ControlNet v1.1.117,扩散控制网络(ControlNet),,,
Traditional Chinese localization,正w中文本地化,正w中文本地化,正w中文本地化,中国Z繁体字翻U
Add model name to generation information,将模型名称添加到生成信息（建议开启）,将模型名称添加到生成信息（建议开启）,将模型名称添加到生成信息（建议开启）,モデルの名称を生成情螭俗芳
Cafe Aesthetic,,,,Cafeの美的
visualize and make template,可视化分区并生成分段模板（粘贴到上方提示词区使用）,,,可化とテンプレ`トの作成
Loop back to initial seed,再变迁回初始种子,再变迁回初始种子,再变迁回初始种子,初期シ`ドにル`プバック
Z type,Z轴类型,Z轴类型,Z轴类型,ZSのN
Get Civitai Model Info by Model ID,从 Civitai 获取单个模型的信息,,,
ControlNet v1.1.254,扩散控制网络(ControlNet),,,
dog-fareast,,,,犬-|方
Seed,随机种子(seed),随机种子(seed),随机种子(seed),シ`ド
Clear selection,清空,,,xkをクリア
ControlNet v1.1.119,扩散控制网络(ControlNet),,,
Highres. fix,,高清修复,高清修复,
Use regex,使用正则表达式,,,正表Fを使用する
house-fineart,,,,家-ファインア`ト
hardsigmoid,hardsigmoid,,,hardsigmoid
Save metadata image key as fullpath,将完整路径作为元数据图像键存储,,,メタデ`タイメ`ジキ`をフルパスで保存
Save Settings,,储存设置,储存设置,O定を保存
tp__argos,,,,tp__argos
is equivalent to,等同于,等同于,等同于,これは以下と同じ意味です。
Select ungrouped keypoints for rotation/scale/skew,,,选择非分组关键点进行旋转/缩放/扭曲。,
Generation Settings,,,,生成のO定
Return the CLIP token count (prompt complexity) ? clip_count,,,,CLIPト`クン数（プロンプトの}jさ）を返す ? clip_count
Use Lora Extended,,,,LoRA を使用
ar,,,,ar
Upload mask,上传蒙版,上传蒙版,上传蒙版,
Reset default (Reload UI needed to apply),恢复默认（需要重启 Webui）,,,
Refresh Civitai Helper,刷新C站助手图标,刷新C站助手,刷新C站助手,
"For advanced keyframing with Math functions, see",,,,Math v数を使った高度なキ`フレ`ム付けについては、次を参照してください。
Inter Denoise:,,,,Inter Denoise:
First Page,首页,首页,首页,最初のペ`ジ
"List of active tabs (separated by commas). Available options are txt2img, img2img, txt2img-grids, img2img-grids, Extras, Favorites, Others. Custom folders are also supported by specifying their path.",选项卡列表，以逗号分隔（可用选项有 txt2img、img2img、txt2img-grids、img2img-grids、Extras、Favorites、Others， 支持写入指定路径自定义文件夹）,选项卡列表，以逗号分隔（可用选项有 txt2img、img2img、txt2img-grids、img2img-grids、Extras、Favorites、Others， 支持写入指定路径自定义文件夹）,选项卡列表，以逗号分隔（可用选项有 txt2img、img2img、txt2img-grids、img2img-grids、Extras、Favorites、Others， 支持写入指定路径自定义文件夹）,"アクティブなタブの一E (カンマで区切られています). 利用可能なオプションは、txt2img, img2img-grid, img2img-grids, extras, Favorites, Othersです. パスを指定することで、カスタムフォルダもサポ`トされます。"
"You can mask images by their categories via semantic segmentation. Please enter category ids (integers), separated by",可通过语义分割，给特定类别的内容添加蒙版，使用,,通过语义分割形成蒙版，需要输入分类的id（整数）每个id之间使用,
Select,,选择,选择,xk
Allows to store pictures and their metadata in a database. (supports MongoDB),,,,画像とそのメタデ`タをデ`タベ`スに保存できます。(MongoDBをサポ`ト)
"Very cheap approximation. Very fast compared to VAE, but produces pictures with 8 times smaller horizontal/vertical resolution and extremely low quality.",,,,超易NNモデル：VAEと比べ非常に高速だが、水平/垂直解像度が8倍小さく、画像品|がOめて低い。
Artist Tags,,画师标签(Tags),画师标签(Tags),
ControlNet v1.1.115,扩散控制网络(ControlNet),,,
Shoulder Width,肩宽,,,
Enable subseed controls,,,,サブシ`ドコントロ`ルを有郡摔工
Arguments in variable=value format ? verbatim,,,,涫 = フォ`マットの引数 ? verbatim
(C9) Thertiary,,(C9) 第三,(C9) 第三,
get,,,,get
Enter words and color hexes to mark weights on the sliders for guidance. Hint: Use the txt2img prompt token counter or,输入文字和颜色十六进制代码以在滑块上标记权重作为引导。 提示：使用文生图提示词词元计数器或使用,输入文字和颜色十六进制代码以在滑块上标记权重作为引导。 提示：使用文生图提示词词元计数器或使用,输入文字和颜色十六进制代码以在滑块上标记权重作为引导。 提示：使用文生图提示词词元计数器或使用,ガイダンス用にスライダ`の重みを示すgZとカラ`ヘックスを入力してください。ヒント：txt2imgプロンプトト`クンカウンタ`を使用するか、
Prompt Generator,,,,Prompt Generator
ko,,,,ko
Network module 1,附加网络模块 1,附加网络类型 1,附加网络类型 1,Network module 1
Denoising strength curve,,,,ノイズ除去度曲
Input Mesh (.ply),,,,Input Mesh (.ply)
https://github.com/CurtisDS/sd-model-preview-xd.git,,,,https://github.com/CurtisDS/sd-model-preview-xd.git
Prompt S/R,提示词搜索/替换,提示词搜索/替换,提示词搜索/替换,プロンプトS/R
*Upscale uploaded video*,,,,*アップロ`ドされた踊をagする*
ControlNet v1.1.127,扩散控制网络(ControlNet),,,
will be supported,的结果也可以识别，,,的模型,
load_history,加载历史记录,,,
Posex,3D OpenPose 编辑器(Posex),3D OpenPose 编辑器(Posex),3D OpenPose 编辑器(Posex),Posex
Start,,,,_始
Refresh Embeddings,刷新 Embeddings,刷新 Embeddings,刷新 Embeddings,Embeddingsを更新
Ex: Low quality,例：低质量,,,
Settings,设置,设置,设置,O定
Show new live preview image every N sampling steps. Set to -1 to show after completion of batch.,每N个采样步骤更新一次实时预览图像，设置为-1以在每批次完成后显示，设置为0关闭实时预览 (建议设为0，开启会占用大量显存和显卡算力),每N个采样步骤更新一次实时预览图像，设置为-1以在每批次完成后显示，设置为0关闭实时预览 (建议设为0，开启会占用大量显存和显卡算力),每N个采样步骤更新一次实时预览图像，设置为-1以在每批次完成后显示，设置为0关闭实时预览 (建议设为0，开启会占用大量显存和显卡算力),Nサンプリングステップごとに新しいライブプレビュ`を表示します。バッチK了後に表示するには、-1にO定します。
LoRA Block Weight,LoRA 权重分层设置(LoRA Block Weight),,,LoRA Block Weight
Prior Loss Target,,,,正t化のp失の象
Number of columns on image gallery,图库显示图像列数,图库显示图像列数,图库显示图像列数,画像ギャラリ`の列数
4 units,,,启用了4个单元,
DPM2 a Karras,DPM2 a Karras,,,DPM2 a Karras
Rotation 3D Y,,,,3D回Y
is experimental functions and NO PROOF of effectiveness., 为实验性功能，不保证有效性, 为实验性功能，不保证有效性, 为实验性功能，不保证有效性,
https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg.git,,,,https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg.git
Reroll blank frames,,,,空白フレ`ムを再ロ`ルする
This script translates your prompt from another language to english before generating the image allowing you to write prompts in your native language.,此脚本将您的提示词(Prompt)自动翻译成英语，从而允许您用您的母语编写。,,,
Fontsizebase,Fontsizebase,,,
choose,,,,xk
SwinIR 4x,,,,SwinIR 4x
Disable,禁用,,,
Interrogator Settings,反推算法设置,,,インタ`ロゲ`タ`のO定
"Information, comment and share @",,,,情蟆コメント、シェア @
To Language,语言选择,,,翻U先の言Z
Regional Prompter,画面分区(Regional Prompter)（配合 BREAK 语法，用法详见GitHub页面）,,,Regional Prompter
vae,VAE,,,
Canvas Zoom,,,,Canvas Zoom
"Simplified Chinese localization, recommend using with Bilingual Localization.",,简体中文本地化，推荐与双语对照翻译插件共同使用。,简体中文本地化，推荐与双语对照翻译插件共同使用。,易版中国Zロ`カライゼ`ション。バイリンガルロ`カライゼ`ションと悚护剖褂盲工毪长趣蛲Xします。
Warmup step per cycle,,,,サイクルごとのウォ`ムアップステップ数
No interpolation will be used. Requires one model; A. Allows for format conversion and VAE baking.,不添加差值，仅填入模型A即可，主要用于压缩、格式转换及整合 VAE (生成自带 VAE 颜色校正的模型),不添加差值，仅填入模型A即可，主要用于压缩、格式转换及整合 VAE (生成自带 VAE 颜色校正的模型),不添加差值，仅填入模型A即可，主要用于压缩、格式转换及整合 VAE (生成自带 VAE 颜色校正的模型),
Remove duplicated tag,,,删除重复的标签,重}するタグを削除
Save Current Config,保存当前设置,,保存当前配置,
Comp alpha schedule,,,,コンポジットのアルファスケジュ`ル
(INCLUSIVE),（模糊检索）,,,(包括的)
Hires fix: show hires prompt and negative prompt,,,高清修复：显示高清修复提示词选项,
Generate lora weights for extra networks.,,,,エクストラネットワ`ク用に lora の重みを生成します。
LLuL Interpolation method,,,,LLuLag法
Add/Remove...,编辑预设,编辑预设,编辑预设,
Source URL where this model could be found,发布该模型的网址,发布该模型的网址,发布该模型的网址,このモデルのソ`スURLがつかりませんでした
Output per image:,每张图片输出的蒙版数量：,,每几张图片输出一次,
R,,,,R
Show/hide extra networks,,,展开/折叠额外网络（模型）窗口,追加ネットワ`クの表示/非表示
Detection confidence threshold % (B),检测置信阈值 % (B),检测置信阈值 % (B),检测置信阈值 % (B),
mbw beta,分层设置 β（每行为一组 β 值）,,,
LLuL Downscaler AA,,,,LLuLダウンスケ`ラ`AA
"Depth Maps, Stereo Image, 3D Mesh and Video generator extension.",,,,深さマップ、ステレオイメ`ジ、3Dメッシュおよびビデオジェネレ`タ。
Allows users to generate images based on prompts written in 50 different languages. It translates the prompts to english from a selected source language before generating the image.,,,,50 Nの言Zでかれたプロンプトをもとに、画像を生成できます。 画像を生成する前に、xkした元の言Zから英Zにプロンプトを翻Uします。
array: Manages a group or list of values.,,,,配列:グル`プやデ`タリストの管理
Half,一半,一半,一半,
be,,,,be
Creates animation sequence from denoised intermediate steps with video frame interpolation to achieve desired animation duration,,根据去噪的过程生成动画序列，通过视频帧插值方法使动画持续预定的时间,根据去噪的过程生成动画序列，通过视频帧插值方法使动画持续预定的时间,
BLIP: num_beams,,,BLIP: 保留最佳候选数量,
ControlNet v1.1.248,扩散控制网络(ControlNet),,,
(B5) Secondary,,(B5) 第二,(B5) 第二,
alphanumcase,,,,英数字ケ`ス
your select language,已选择的语言,,,あなたのxkした言Z
Video path,,,,Video path
Benchmark level,基准水平,,,
Maximum width or height default,,,,最大幅または高さのデフォルト
Always save all generated images,始终保存所有生成的图像,始终保存所有生成的图像,始终保存所有生成的图像,生成された画像をすべて保存する
"Invert DepthMap (black=near, white=far)",,,,DepthMapを反 (\=近く、白=hい)
Copy config from,从...复制配置文件,从...复制配置文件,从...复制配置文件,ここからコンフィグをコピ`します
Status:,,,状态:,状B:
"1st and last digit must be 1. ex:'1, 2, 1'","第一个和最后一个数字必须是 1。例：'1, 2, 1'","第一个和最后一个数字必须是 1。例：'1, 2, 1'","第一个和最后一个数字必须是 1。例：'1, 2, 1'","最初と最後の数字は1でなければなりません。 例:'1, 2, 1'"
Perspective flip phi,,,,透投影反φ
Inter Denoise Size,,,,Inter Denoise Size
soft_light,,,,ソフトライト
Gustavosta/MagicPrompt-Stable-Diffusion,,,,Gustavosta/MagicPrompt-Stable-Diffusion
init_image: Loads an image from the given path and sets it as the initial image for use with img2img.,,,,init_image: 与えられたパスから画像をiみzみ、img2imgで使用するための初期画像としてO定する。
Train EMA,训练 EMA,训练 EMA,训练 EMA,
unknown,未知,未知,未知,不明
"In this case, a random number of artists between 1 and 3 is chosen.",此例中，会从中随机选 1 至 3 个艺术家,此例中，会从中随机选 1 至 3 个艺术家,此例中，会从中随机选 1 至 3 个艺术家,この龊1～3のランダムの数のartistがxばれます。
Aesthetic text for imgs,该图集的美术风格描述,该图集的美术风格描述,该图集的美术风格描述,Aesthetic text for imgs
ControlNet v1.1.198,扩散控制网络(ControlNet),,,
txt2img_sampling,采样方法(Sampler),,,
Perform warmup,预热设备,,,
-25%,,,,-25%
Canvas Hotkeys,,,画布快捷键,
fi,,,,fi
Segment Anything Output,Segment Anything 结果输出,,蒙版分割结果,
"Prompt, will append to your i2i prompt",输入区域提示词(Prompt),,正向提示词，会附加到原始正向提示词中,
Use dropout. Might improve training when dataset is small / limited.,,,,ドロップアウトを使用します。デ`タセットが小さい/限られている龊稀トレ`ニングを改善する可能性があります。
normal,标准,,法线,通常
Block ID,层 ID,,,
Prompts positive,,,,ポジティブプロンプト
Train Text Encoder,训练文本编码器,训练文本编码器,训练文本编码器,
Noise mask schedule,,,,ノイズマスクのスケジュ`ル
Open TextEditor,打开记事本编辑,,,
Tile height,,,,タイル高さ
Control Model - 2,控制模型-2,,,
Noise,,,,ノイズ
Minimum number ? _min,,,,最小 ? _min
save,保存,,,保存
Swap X/Y axes,XY互换,XY互换,XY互换,X/YSを入れ替える
Apply,应用参数,应用,应用,m用
(C8) Thertiary,,(C8) 第三,(C8) 第三,
softmax,softmax,,,softmax
dropdown,有下拉菜单,下拉菜单,下拉菜单,ドロップダウン
ControlNet v1.1.159,扩散控制网络(ControlNet),,,
Requires the,,,,必要です
Scale by,等比缩放,等比缩放,等比缩放,倍率指定
save_samples,,储存样本,储存样本,サンプルの保存
Corridor Crawler Outpainting,,,,Corridor Crawler Outpainting
"Due to ControlNet base extension's inner works it needs its models to be located at 'extensions/deforum-for-automatic1111-webui/models'. So copy, symlink or move them there until a more elegant solution is found. And, as of now, it requires use_init checked for the first run. The ControlNet extension version used in the dev process is a24089a62e70a7fae44b7bf35b51fd584dd55e25, if even with all the other options above used it still breaks, upgrade/downgrade your CN version to this one.",,,,ControlNetベ`スC能の内部幼鳏摔瑜辍モデルは「extensions/deforum-for-automatic1111-webui/models」に配置する必要があります。よりエレガントな解Q策がつかるまで、そこにコピ`、シンボリックリンク、または移婴筏皮ださい。Fr点では、最初のg行にはuse_initをチェックする必要があります。_kプロセスで使用されたControlNetC能のバ`ジョンはa24089a62e70a7fae44b7bf35b51fd584dd55e25です。他のオプションをすべて使用してもまだ菠欷龊悉稀CNバ`ジョンをこのバ`ジョンにアップグレ`ド/ダウングレ`ドしてください。
Send interrupt,发送中断指令,发送中断指令,发送中断指令,
"Select Layer weights initialization. Recommended: Kaiming for relu-like, Xavier for sigmoid-like, Normal otherwise",选择初始化层权重的方案。建议：类relu 用 Kaiming； 类sigmoid 用 Xavier；其它就用 Normal,选择初始化层权重的方案。建议：类relu 用 Kaiming； 类sigmoid 用 Xavier；其它就用正态,选择初始化层权重的方案。建议：类relu 用 Kaiming； 类sigmoid 用 Xavier；其它就用正态,Layer weightsの初期化をxkします。(推X): Kaimingはrelu-like、Xavierはsigmoid-like、それ以外はNormalを推Xします。
Save a checkpoint every N steps. ,每 N 步保存一次模型权重进度(ckpt),每 N 步保存一次模型权重进度(ckpt),每 N 步保存一次模型权重进度(ckpt),
Leave empty to use input directory,,,留空的话将使用“输入目录”,
Max number of top tags to show,要显示的最大常见标签数,要显示的最大常见标签数,要显示的最大常见标签数,表示するタグの最大数
fp16,储存为fp16,,,fp16
ControlNet v1.1.6,扩散控制网络(ControlNet),,,
sigma noise,sigma 噪声,sigma 噪声,sigma 噪声,sigma noise
Precision of instance selection ? instance_precision,,,,インスタンスxkの精度 <unk> instance_precision
Copy to directory,将图片复制到目标路径,将图片复制到目标路径,将图片复制到目标路径,
ControlNet v1.1.196,扩散控制网络(ControlNet),,,
3D Model Loader,,,,3Dモデルiみzみ
Show generation progress in window title.,在窗口标题中显示生成进度（建议开启）,在窗口标题中显示生成进度,在窗口标题中显示生成进度,ウィンドウのタイトルで生成のM盲虮硎
ControlNet v1.1.242,扩散控制网络(ControlNet),,,
Memory usage,最大内存用量,,,
DPM++ SDE,,,,DPM++ SDE
Invert evaluation such that a false condition will end the loop ? _not,,,,False 条件がル`プをK了するようにuを反する ? _not
"WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.",,,,ControlNetのWebUIC能です。注：（作成途中）アップデ`トによって状rが浃铯肟赡苄预あるため、シ`ドによる再F性を期待しないでください。
gif2gif,,,,gif2gif
fa,,,,fa
artists to study extension by camenduru |,,,,ア`ティスト学のC能 by camenduru氏作成
"When using ""Save"" button, save images to a subdirectory",使用“保存”按钮时，将图像保存到子目录,使用“保存”按钮时，将图像保存到子目录,使用“保存”按钮时，将图像保存到子目录,保存ボタンを押したr、画像をサブディレクトリに保存する
Colorprimaryhover,Colorprimaryhover,,,
Save category (Windows only),,,,カテゴリを保存(Windowsのみ)
localization,本地化翻译,本地化翻译,本地化翻译,言Z
Send to txt2img:, >> 文生图（按钮与插件面板模型1-5对应）,将模型发送到文生图页面\n（数字按钮1-5对应模型1-5）,将模型发送到文生图页面\n（数字按钮1-5对应模型1-5）,Txt2imgに送:
aesthetic_score,美学评分,美学评分,美学评分,美的スコア
Image CFG Scale,,,,画像CFGスケ`ル
y,纵,,,
OUT07,,输出层07,输出层07,
Power Up,骤增(Power up),,,
pluralize: Converts the content into plural form.,,,,pluralize: コンテンツを}数形にQします。
hypernyms,,,,上位概念
ControlNet v1.1.245,扩散控制网络(ControlNet),,,
clip,clip,,,
Renoise strength,Renoise 强度,,,
Minimize error,,,最小误差,エラ`の最小化
Linear Up,线性递增(Linear Up),,,
IN03,,输入层03,输入层03,
Use upscaler name as filename suffix in the extras tab,在附加功能选项卡中使用放大算法作为文件名后缀,在附加功能选项卡中使用放大算法作为文件名后缀,在附加功能选项卡中使用放大算法作为文件名后缀,Extrasタブでアップスケ`ラ`名をファイル名の後ろに追加する
Randomize CFG Scale,随机化 提示词相关性(CFG Scale),随机化 提示词相关性(CFG Scale),随机化 提示词相关性(CFG Scale),
Reload settings,重新加载设置,,,O定を再iみzみ
Record accessable images directories,"在 ""其他"" 标签下记录访问过的目录","在 ""其他"" 标签下记录访问过的目录","在 ""其他"" 标签下记录访问过的目录",
Auto segmentation output,Auto SAM 结果输出,,分割结果,
Depth Maps,深度图样例,深度图,深度图,Depth Maps
Save current settings,保存当前设置,,,F在のO定を保存
portrait-ukioe,,,,肖像画-浮世}
house-digipa-low-impact,,,,家-digipaロ`インパクト
Classification Image Negative Prompt,分类(classification)图像负面提示词,分类(classification)图像反向提示词,分类(classification)图像反向提示词,分イメ`ジのネガティブプロンプト
Show batch images in gradio gallery output,在页面上显示批量处理的输出结果,,展示批处理的图片,
?,?,,,
Overwrite extracted frames,,,,抽出されたフレ`ムを上き
Attention texts for visualization. (comma separated),,,,化のためのテキスト(カンマ区切り)
Comp mask blend alpha schedule,,,,コンプマスクブレンドアルファスケジュ`ル
The prompt to use when generating preview images.,生成预览图像时使用的提示词,生成预览图像时使用的提示词,生成预览图像时使用的提示词,
optimizations,启动参数,,,
Layer1,,,,Layer1
Load models/files in hidden directories,,,加载隐藏文件夹的模型,
ControlNet v1.1.191,扩散控制网络(ControlNet),,,
Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.,一个在潜空间中对不同提示词之间进行插值渐变，并生成其渐变过程的扩展脚本,一个在潜空间中对不同提示词之间进行插值渐变，并生成其渐变过程的扩展脚本,一个在潜空间中对不同提示词之间进行插值渐变，并生成其渐变过程的扩展脚本,AUTOMATIC1111/stable-diffusion-webuiのスクリプトは、潜在I域のプロンプトgを移婴筏蓼埂
This will produce the following prompts:,会产生下列提示词,会产生下列提示词,会产生下列提示词,これにより、以下のプロンプトが表示されます:
lora,LoRA,lora,lora,
ControlNet v1.1.148,扩散控制网络(ControlNet),,,
OUT_B_01,,模型B 输出层01,模型B 输出层01,
Change checkpoint,,,,Checkpointの涓
show_sample_per_step,,每步都显示样本,每步都显示样本,
AddNet Weight 5,[附加网络] 权重 5,[可选附加网络] 权重 5,[可选附加网络] 权重 5,重み 5(AddNet)
IN11,,输入层11,输入层11,
NSFW checker,,成人内容检测器,成人内容检测器,NSFW checker
ABG_extension,,,,ABG_extension
3D,,,,3D
Far clip,,,,hいクリップ
Unit type ? unit,,,,ユニット タイプ → ユニット
Save hypernetwork setting to file,,,,HypernetworksのO定をファイルに保存
Separate values for X axis using commas.,使用逗号分隔 X 轴的值,使用逗号分隔 X 轴的值,使用逗号分隔 X 轴的值,"XSに用いるをカンマ(,)で区切って入力してください。"
Include images in sub directories,显示子目录中的图片（建议开启）,显示子目录中的图片（建议开启）,显示子目录中的图片（建议开启）,サブディレクトリ内の画像を含める
Forearm,小臂,,,
"masks from files: in [], like [mask1.png]",,,,ファイルからのマスク：[mask1.png]のように、[]で表します。
Dataset Directory,数据集目录,数据集目录,数据集目录,デ`タセットのディレクトリ
es_ES Localization,,,,es_ES Localization
Instance prompt,实例(Instance)提示词,实例(Instance)提示词,实例(Instance)提示词,
Process images in a directory on the same machine where the server is running.,处理服务器主机上某一目录里的图像,处理服务器主机上某一目录里的图像,处理服务器主机上某一目录里的图像,サ`バ`が稼Pしているのと同じマシンにあるディレクトリ内の画像をI理します。
AdamW beta1 parameter,,,,AdamW beta1 パラメ`タ
artists,,,,ア`ティスト
Aesthetic Image Scorer,美术风格评分,美术风格评分,美术风格评分,Aesthetic Image Scorer
vi,,,,vi
ControlNet v1.1.292,扩散控制网络(ControlNet),,,
I hate green roses,I hate green roses,,,I hate green roses
tr_TR Localization,,,,tr_TR Localization
Only Show Models have no Info,仅显示无 Civitai 信息的模型,只显示没有信息的模型,只显示没有信息的模型,
2. Click on any of the files that appear in the tree to edit them.,,,,2. ツリ`に表示されているファイルをクリックして集します。
__<folder>/mywildcards__,,,,__<folder>/mywildcards__
tp_volcEngine,,,,tp_volcEngine
Single process,单张图片,单张图片,单张图片,g一I理
Show all results,显示所有结果,显示所有结果,显示所有结果,全てのタグを表示
Disable openpose edit,,,关闭Openpose编辑功能,
Hat,,,帽子,
ControlNet v1.1.9,扩散控制网络(ControlNet),,,
Seed of a different picture to be mixed into the generation.,将要参与生成的另一张图的随机种子,将要参与生成的另一张图的随机种子,将要参与生成的另一张图的随机种子,生成rに、eの画像のシ`ドを混ぜzんで使用します。
Sample Prompt,,,,サンプルプロンプト:
"Implementation of text2video diffusion models, such as ModelScope or VideoCrafter, using only Auto1111 webui dependencies.",,,,ModelScopeやVideoCrafterなどのtext2video散モデルのg装では、Auto1111 webuiの依存vSのみを使用しています。
dimensions,,,尺寸,
LLuL,局部细化(Local Latent upscaLer),潜变量局部放大器,潜变量局部放大器,LLuL
ControlNet v1.1.179,扩散控制网络(ControlNet),,,
min: Returns the minimum value among the given arguments.,,,,min: 与えられた引数の中の最小を返します。
wd14-convnext,,,,wd14-convnext
Apply Presets,应用预设,,,プリセットをm用
Prompt Magic,,,,Prompt Magic
ControlNet v1.1.193,扩散控制网络(ControlNet),,,
LLuL Weight,,,,LLuLウェイト
M_A_00,,模型A 中间层,模型A 中间层,
add,,,,追加
Selected,已选择的,已选择的,已选择的,xk中
ControlNet v1.1.220,扩散控制网络(ControlNet),,,
(S3) Inter-Method,,(S3) 插值方法,(S3) 插值方法,
Number of times to choose ? int,,,,xkする回数 <unk> int
stable-diffusion-webui-aesthetic-image-scorer,美术风格评分,美术风格评分,美术风格评分,stable-diffusion-webui-aesthetic-image-scorer
prompting,提示词相关,提示词编写,提示词编写,プロンプト表示
ny,,,,ny
si,,,,si
constant,常量(constant),常量(constant),常量(constant),定数
(B6) Secondary,,(B6) 第二,(B6) 第二,
Sort tags,开始排序,,,タグをKべ替え
"An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts. Note: New maintainer, uninstall prev. ext if needed.",,,,内iのComposable Diffusionをしたもので、サブプロンプトを反映した潜像空gのI域をQ定することができます。 注: 新しいメンテナ`のリポジトリURLに移行したため、必要に辘袱乒扭C能をアンインスト`ルしてください。
so,,,,so
Model Revision:,,,,モデルリビジョン:
similar,相似,相似,相似,
ckp,Stable Diffusion 模型(ckpt),ckp,ckp,
Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator,,,,Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator
+75%,,,,+75%
ControlNet v1.1.144,扩散控制网络(ControlNet),,,
Invert selection,反选,,,xkを反
Installed,已安装,已安装,已安装,インスト`ルg
Perlin H,,,,Perlin H
generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.,,,,distilgpt2 を使用して小さなベ`スプロンプトからプロンプトを生成します。モデルの追加制御を行うタブを追加します。
Clear values,清空权重设置,清空数值,清空数值,
Upscaled,,,,アップスケ`ルg
Tutorial,,,,チュ`トリアル
"For inpainting, save a copy of the greyscale mask",局部重绘时，保存灰度蒙版图像,,局部重绘时，保存一份灰度蒙版,inpaintingで、グレ`スケ`ルマスクを保存する
AddNet TEnc Weight 1,[附加网络] Text Encoder 权重 1,[可选附加网络] Text Encoder 权重 1,[可选附加网络] Text Encoder 权重 1,AddNetNetの重み 1
Inpaint sketch,局部重绘(有色蒙版),局部重绘(手涂蒙版),局部重绘(手涂蒙版),Inpaintスケッチ
cluster num,基于颜色信息的簇数量,,,
Autocontrast low/high cutoff schedules 0-100. Low 0 High 100 is full range.,,,,オ`トコントラストの低/高カットオフスケジュ`ルは0-100です。低0、高100はフルレンジです。
CLIP pretrain ? clip_pretrain,,,,CLIP pretrain ? clip_pretrain
ebsynth_utility,,,,ebsynth_utility
denoising_strength,,,,ノイズ除去度
Start Cropping,,,,クロッピングを_始
Quality for saved jpeg images,保存的 JPEG 图像的质量,保存的 JPEG 图像的质量,保存的 JPEG 图像的质量,JPG画像保存rの画|
Output filename format,输出文件名格式,输出文件名格式,输出文件名格式,出力ファイルフォ`マット
Translation Y,,,,YS方向の移
Open for Clip Aesthetic!,打开以调整 Clip 的美术风格！,打开以调整 Clip 的美术风格！,打开以调整 Clip 的美术风格！,Open for Clip Aesthetic!
Dynamic Thresholding Advanced Options,动态阈值高级选项,,,
Don't use prompt magic on negative prompts.,,,,ネガティブプロンプトで prompt magic を使用しない。
search,搜索,,,
ControlNet v1.1.272,扩散控制网络(ControlNet),,,
Separator string when returning multiple variables ? _sep,,,,}数の涫を返すときの区切り文字列 ? _sep
Thigh,大腿,,,
Enter category IDs,需要添加蒙版的类别ID,,输入语义分割的id,
Duplicate Skeleton (X-axis),X轴方向添加骨架（左右方向）,,,
Ignores step count - uses a number of steps determined by the CFG and resolution,,,,ステップ数をoし、CFGと解像度によってQまるステップ数を使用します。
Leave this alone unless you know what you are doing,,,不要改动这个之除非你知道你在做什么,
Seg,,,语义分割,
Nothing,无,无,无,なし
Ranking Filter,分级信息过滤,,,
latent nothing,潜空间数值零,潜变量数值零,潜变量数值零,潜在空gにおけるo
Send dimensions to stable diffusion,,,将分辨率同步到图片生成设置,
Comp mask equalize,,,,コンポジットマスクの均等化
"Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.",,多通道合并支持（最多 10 个）。 保存或加载你的合并组合为配方，也就是一些简单的文本,多通道合并支持（最多 10 个）。 保存或加载你的合并组合为配方，也就是一些简单的文本,}数のレ`ンマ`ジをサポ`ト(最大10まで) マ`ジのMみ合わせはレシピとして保存とiみzみが可能です(テキストのみ)
Include artist tags in tag string,,在标签字串中包含画师标签,在标签字串中包含画师标签,
Perspective flip theta,,,,透投影反θ
Mask schedule,,,,マスク スケジュ`ル
An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.,,,,Stable Diffusion depth2img モデルへのカスタム深度入力を管理できるようにするC能です。
Transparent,透明,透明,透明,透^
t2ia_color_grid,色彩引导（t2iadapter_color 模型）,,t2ia自适应 - 色彩引导（color_grid）,
Use mid-control on highres pass (second pass),进行高分辨率修复时使用中间层控制(mid-control),进行高清修复时使用中间层控制(mid-control),进行高清修复时使用中间层控制(mid-control),高解像度パス（2番目のパス）に中g制御を使用する
LLuL Upscaler,,,,LLuLアップスケ`ラ`
DPM++ 2M,DPM++ 2M,,,DPM++ 2M
Include Sub Grids,预览子宫格图,预览次级宫格图,预览次级宫格图,サブグリッドを含める
Keep resolution,保持分辨率不变,保持分辨率不变,保持分辨率不变,解像度を保持
Extra file in alias only format,附加词库文件使用仅别称格式,附加词库文件使用仅别称格式,附加词库文件使用仅别称格式,
Video init path,,,,踊の初期パス
Changelog,,,,涓ログ
Switch to Inpaint Upload,切换到 局部重绘(上传蒙版),,切换到局部重绘（上传蒙版）,
"CFG scale (dynamic cfg: low,high:type e.g. 1.0-3.5:cos)",,,,"CFGスケ`ル (拥 cfg: low,high:type 例: 1.0-3.5:cos)"
Multiple Hypernetworks,加载多个超网络模型(Hypernetworks),加载多个超网络(Hypernetworks),加载多个超网络(Hypernetworks),Multiple Hypernetworks
pykrita,,,,pykrita
Input Theme,,,,テ`マを入力
(A1) Primary,,(A1) 主要,(A1) 主要,
model hash,Stable Diffusion 模型(ckpt) 哈希值,模型(ckpt)哈希值,模型(ckpt)哈希值,モデルのHash
"Positive ""filewords"" only",,"只限正向 ""filewords""","只限正向 ""filewords""",ポジティブ「ファイルワ`ド」のみ
Keep empty if dont use.,不使用请留空,不使用请留空,不使用请留空,
"Metadata to show in XY-Grid label for Model axes, comma-separated (example: ""ss_learning_rate, ss_num_epochs"")","显示在X/Y表标签下的元数据选项，逗号分隔（示例：""ss_learning_rate, ss_num_epochs""）","显示在X/Y表标签下的元数据选项，逗号分隔（示例：""ss_learning_rate, ss_num_epochs""）","显示在X/Y表标签下的元数据选项，逗号分隔（示例：""ss_learning_rate, ss_num_epochs""）","X/Y プロットのSで表示されるラベルに使うメタデ`タ。カンマで区切って}数指定できます。(例: ""ss_learning_rate"", ""ss_num_epochs"")"
init_image,,,,init_image
min,,,,最小
ControlNet v1.1.162,扩散控制网络(ControlNet),,,
Move VAE to GPU,将 VAE 移动到 GPU,将 VAE 移放到 GPU,将 VAE 移放到 GPU,VAEをGPUに移
Copy Metdata,开始复制元数据,开始复制元数据,开始复制元数据,
OUT01,,输出层01,输出层01,
instance2mask,,,,instance2mask
"This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.",,,,}数のポ`ズキャラクタ`を追加したり、画像からポ`ズを食訾PNGに保存したり、controlnetのC能に送信することができます。
Half tile offset pass,,,,Half tile offset pass
(setting entries that also appear in txt2img/img2img interfaces),,,（设置条目也出现在文生土/图生图界面中）,
2D and 3D settings,,2D 及 3D 设定,2D 及 3D 设定,
"docked window should appear on the left of the Krita window. If it does not, look on the menubar under",,,,固定ウィンドウは、Krita ウィンドウの左趣吮硎兢丹欷毪悉氦扦埂１硎兢丹欷胜龊悉稀メニュ`バ`の下にある目を_Jしてください。
Model list,模型列表,模型列表,模型列表,
scribble,涂鸦处理（scribble）,涂鸦（scribble）,涂鸦（scribble）,scribble
AddNet Weight 1,[附加网络] 权重 1,[可选附加网络] 权重 1,[可选附加网络] 权重 1,重み 1(AddNet)
Infotext,图像生成信息,,生成信息,
Adjusts the generated prompt. You will need to experiment with this setting.,调整生成的提示词，使用时要尝试调整此设置,调整生成的提示词，使用时要尝试调整此设置,调整生成的提示词，使用时要尝试调整此设置,生成されたプロンプトを{整します。このO定をす必要があります。
Perspective flip fv,,,,h近反fv
CLIP model ? clip_model,,,,CLIP model ? clip_model
"Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.",,,,"Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal."
Combined,都显示,兼有,兼有,Y合された
Preview annotator result,预览预处理结果,预览预处理结果,预览预处理结果,アノテ`ションY果をプレビュ`
(O1) Output ckpt Name,,(O1) ckpt 输出名,(O1) ckpt 输出名,
CosineAnnealing lr increase step,,,,荷を加させるステップ
WebUI State,WebUI 版本,,WebUI 状态,
"Enter hypernetwork Dropout structure (or empty). Recommended : 0~0.35 incrementing sequence: 0, 0.05, 0.15",,,"输入超网络的Dropout结构（或为空）。推荐：0~0.35的增量序列：0, 0.05, 0.15","Hypernetworkのドロップアウト造（または空）を入力してください。推X：0～0.35 インクリメントシ`ケンス: 0, 0.05, 0.15"
"Result = ""X, Y, A, B, C""?(add X and Y to the beginning (""Prepend additional tags"" checked))","　　结果：“X, Y, A, B, C”（X和Y被添加到开头，勾选“前置附加的 Tag”时生效）",,,"Y果= ""X、Y、A、B、C""（「追加タグを前置する」がチェックされている龊悉稀XとYを先^に追加します）"
scripts,,,脚本,
Set 'seed_behavior' to 'schedule' under the Seed Scheduling section below.,,,,以下のSeedスケジュ`リングセクションで「seed_behavior」を「schedule」にO定してください。
Memory Optimised SHA256,SHA256哈希值 计算时优化内存用量,SHA256哈希值 计算时优化内存用量,SHA256哈希值 计算时优化内存用量,
Image to be masked,需要添加蒙版的图像,,要分割的图片,
"Ignore whitespace in prompts: All newlines, tabs, and multiple spaces are replaced by a single space",,,,プロンプトの空白をo: 全ての改行、タブ、}数の空白は１つの空白に置きQえられる
beta2,beta2,,,ベ`タ2
New Canvas Height,,,画布高度,
Upscale model,,,,アップスケ`ルモデル
Zip,,,,Zip
https://github.com/p1atdev/stable-diffusion-webui-cafe-aesthetic,,,,https://github.com/p1atdev/stable-diffusion-webui-cafe-aesthetic
Train_Gamma,,,,トレイン_ガンマ
3. Use the wildcard in your script by typing the name of the file or copying the text from the Wildcards file text box,,,,3. ファイル名を入力するか、ワイルドカ`ドファイルのテキストボックスからテキストをコピ`して、スクリプト内のワイルドカ`ドを使用します
Cancel generate forever,停止无限生成,停止无限生成,停止无限生成,この画像で生成を停止
Save separate diffusers snapshots when saving during training.,,,,トレ`ニング中、ディフュ`ザの重みのスナップショットをeに保存する。
Opacity,不透明度,透明度,透明度,
slower,,,,よりWい
Model path,模型路径,模型路径,模型路径,モデルのパス
stable-diffusion-webui-state,,,,stable-diffusion-webui-state
PNDM,,,,PNDM
"2. When changes are applied, all tags in each displayed images are replaced.",2.当更改被应用后，每个前显示的图像中的所有 Tag 都会被替换,,,2. 涓がm用されると、表示されている各画像のすべてのタグが置きQえられます。
Layer3 opacity,,,,Layer3 不透明度
el,,,,el
Show batch images in gradio gallerie output,在页面上显示批量处理的输出结果,,,
Model Epoch:,,,,モデルのエポック数
Mask transparency,蒙版透明度,蒙版透明度,蒙版透明度,マスクの透明度
Mimic CFG Scale,模拟提示词相关性(Mimic CFG Scale),模拟提示词相关性(Mimic CFG Scale),模拟提示词相关性(Mimic CFG Scale),
(B10) Secondary,,(B10) 第二,(B10) 第二,
dog,,,,犬
Perspective flip gamma,,,,透投影反γ
AUTOMATIC/promptgen-majinai-safe,,,,AUTOMATIC/promptgen-majinai-safe
Train Inpainting Model,,,,inpaint用モデルの学
Threshold schedule,,,,スケジュ`ル
Nothing selected,,,,何もxkされていません
multi-subject-render,,多主体渲染器,多主体渲染器,multi-subject-render
batch process,批量处理,,批量处理多张图片,
synonyms,,,,xZ
da,,,,da
Existing Caption txt Action,对已有的 txt 描述文本的行为,对已有的 txt 描述文本的行为,对已有的 txt 描述文本的行为,既存のキャプションの取りQい
Detection confidence threshold % (A),检测置信阈值 % (A),检测置信阈值 % (A),检测置信阈值 % (A),
Remove all point prompts,移除所有提示点,,移除所有标注点,
Save as float16,以 float16 储存,以 float16 储存,以 float16 储存,float16で保存
Denoising strength for the entire image,,,全图重绘幅度（若重建的脸部和全图接缝过于明显，可以加大此值）,
Bump seed (If > 0 do a Compare Paths but only one image. No video will be generated.),,,,Bump シ`ド (> 0 の龊稀パスの比^を行いますが、画像は 1 つだけです。ビデオは生成されません。)
Image folder ? folder,,,,イメ`ジフォルダ` ? folder
cosineB,余弦B（仅“加权和”可用）,,,
Generate Ckpt,创建 Stable Diffusion 模型(ckpt),创建模型(ckpt),创建模型(ckpt),Ckptを生成
Enable AA for Upscaling.,放大时启用抗锯齿(AA),放大时启用抗锯齿(AA),放大时启用抗锯齿(AA),アップスケ`リングにAAを有炕します。
(0 = disable),,,(0表示关闭),
webui-tokenizer,词元分析器(tokenizer)扩展,词元分析器(tokenizer)扩展,词元分析器(tokenizer)扩展,webui-tokenizer
ControlNet Inpaint Index,接收蒙版图像的 ControlNet 控制单元,,目标ControlNet单元编号,
Negative Prompt Weight,,,,Negative Prompt Weight
Infinity Grid Generator,,,,Infinity Grid Generator
Save template to metadata: Write prompt template into the PNG metadata,,,,テンプレ`トをメタデ`タに保存: PNGメタデ`タにプロンプトテンプレ`トをきzむ
Variation seed,差异随机种子,差异随机种子,差异随机种子,バリエ`ションのシ`ド
Conditionals,条件,条件,条件,条件O定
Masked content,蒙版蒙住的内容,蒙版蒙住的内容,蒙版蒙住的内容,マスクされたコンテンツ
System Info,系统信息,系统信息,系统信息,System Info
background color,,,,背景色
Top-K,,,,Top-K
Use mask video,,,,マスクビデオを使用
Make GIF,,,,GIFを作成
Unload all models from memory,解除 SA模型 对内存的占用,,从显存中卸载SAM模型,
spaceship-special,,,,宇宙船 スペシャル
use MBW,启用分层设置权重(MBW),,,
Show Gradient Clipping Options(for both),,,,Gradient Clipping オプションを表示(for both)
hybrid_comp_mask_blend_alpha_schedule,,,,hybrid_comp_mask_blend_alpha_schedule
Enable full page image viewer,启用整页图像查看器（建议开启）,启用整页图像查看器（建议开启）,启用整页图像查看器（建议开启）,フルペ`ジの画像ビュ`ワ`を有炕
random,随机,随机,随机,ランダム
Number of Samples to Generate,要生成的样本数量,要生成的样本数量,要生成的样本数量,生成するサンプル数
relative overlap,,,,相的な重ね合わせ
Total number of classification images to use. Set to 0 to disable.,要使用的分类(classification)图像总数。设置为 0 以禁用,要使用的分类(classification)图像总数。设置为 0 以禁用,要使用的分类(classification)图像总数。设置为 0 以禁用,
Enter the path to a txt file containing sample prompts.,,,,サンプルプロンプトが含まれるtxtファイルへのパスを入力してください。
Enable CFG-Based guidance,"启用基于CFG的引导(CFG-Based guidance)（配合无引导模式使用时请删除所有prompt，并设置""采样次数：50，CFG：3~5""，ControlNet将会自动识别输入的模式图）","启用基于CFG的引导(CFG-Based guidance)（配合无提示词(prompt)模式使用时请删除所有提示词，推荐设置""采样次数：50，CFG：3~5""，ControlNet将会自动识别输入的模式图）","启用基于CFG的引导(CFG-Based guidance)（配合无提示词(prompt)模式使用时请删除所有提示词，推荐设置""采样次数：50，CFG：3~5""，ControlNet将会自动识别输入的模式图）",CFG 基胜违イダンスを有郡摔工
portrait-fareast,,,,肖像画-|方
LAB Tools,,,,LABツ`ル
This will produce one prompt for each colour in the wildcard.txt file.,会为 colours.txt 中的每个颜色产生一条提示词,会为 colours.txt 中的每个颜色产生一条提示词,会为 colours.txt 中的每个颜色产生一条提示词,これにより、wildcard.txtファイル内の各色にして1つのプロンプトが生成されます。
canvas-zoom-and-pan,,,画布缩放和平移,
kabachuha,,,,kabachuha氏
Randomness,随机度,随机度,随机度,ランダム性
Produce an image that can be tiled.,生成可用于平铺(tiled)的图像,生成可用于平铺(tiled)的图像,生成可用于平铺(tiled)的图像,タイル状にKべられる画像を生成します。
sd-webui-cutoff,色彩分离(Cutoff)插件,,,sd-webui-cutoff
Custom settings file,,自定义设置文件,自定义设置文件,カスタムO定ファイル
Colorprimarybg,Colorprimarybg,,,
Arbitrary conditional statement(s) to test against ? verbatim,,,,任意の条件文を用いて元の文にしてテストする
Enable guided images mode,,,,ガイド付き画像モ`ドを有郡摔工
Start training.,开始训练,开始训练,开始训练,
Save a copy of image before applying highres fix.,在做高分辨率修复之前保存初始图像副本,在做高清修复之前保存初始图像副本,在做高清修复之前保存初始图像副本,高解像度a助を行う前に元画像のコピ`を保存しておく
Masking mode,蒙版模式,蒙版模式,蒙版模式,
Leave empty for auto,留空时自动生成,留空时自动生成,留空时自动生成,空冥亲
Use Lora in uc diffusion model,在负面提示词的扩散模型(diffusion model)上使用 LoRA（不建议开启）,在扩散模型降噪过程中对反向提示词也开启 LoRA（不建议开启）,在扩散模型降噪过程中对反向提示词也开启 LoRA（不建议开启）,
Don't Cache Latents,不要缓存潜空间变量,不要缓存潜变量,不要缓存潜变量,
Enable Token Merging,启用词元合并加速(Token Merging),,,
Clear,清空,清除,清除,
Train Hypernetwork,训练超网络,训练超网络,训练超网络,Hypernetworkの学を_始
Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer,为生成出来的图像计算其美学分数。基于 Chad Scorer 使用 CLIP+MLP 美学分数预测器,为生成出来的图像计算其美学分数。基于 Chad Scorer 使用 CLIP+MLP 美学分数预测器,为生成出来的图像计算其美学分数。基于 Chad Scorer 使用 CLIP+MLP 美学分数预测器,Chad Scorerに基づくClip+MLP美的スコア予y器を使用して、生成された画像の美的スコアを算する。
stable-diffusion-webui-localization-zh_TW,正w中文Z言包,正w中文Z言包,正w中文Z言包,
ControlNet v1.1.138,扩散控制网络(ControlNet),,,
Extra Networks,附加网络,附加网络,附加网络,追加のネットワ`ク
Warmup Steps,预热步数,预热步数,预热步数,
1 unit,,,启用了1个单元,
Classifier path,分类器(Classifier)的路径,分类器(Classifier)的路径,分类器(Classifier)的路径,分モデルのパス
Offset Noise,,,,オフセットノイズ
Background gradiant color,背景渐变色,,,
point2 y,,,,点2_k
Built with Gradio,,基于 Gradio 构建,基于 Gradio 构建,Gradioでビルドされました
Load training option(s) from saved json file,,,,保存されたjsonファイルからトレ`ニングオプションをiみzむ
Notes,,,,淇
ControlNet v1.1.283,扩散控制网络(ControlNet),,,
Also upload to img2img inpainting upload.,同时发送到局部重绘(上传蒙版),,,
Do not make DPM++ SDE deterministic across different batch sizes.,保留 DPM++SDE采样器 在不同的批量之间的结果差异(可以保持旧种子的复现性但改变批量时结果会发生变化),保留 DPM++SDE采样器 在不同的批量之间的结果差异(可以保持旧种子的复现性但改变批量时结果会发生变化),保留 DPM++SDE采样器 在不同的批量之间的结果差异(可以保持旧种子的复现性但改变批量时结果会发生变化),なるバッチサイズでDPM++ SDEをdeterministicにしないようにする。
Linux command:,,,,Linuxコマンド:
Save PNG,保存为 PNG图片,保存为 PNG图片,保存为 PNG图片,PNGを保存
Rectangular,矩形分区,,,
Tagger,WD1.4 Tag反推,Tag反推(Tagger),Tag反推(Tagger),タグ付け
Frames folder,,,,Frames folder
Keep input image size,保持输入图片尺寸,保持输入图像尺寸,保持输入图像尺寸,入力画像のサイズをS持する
Area 1 Weight,蒙版 1 的权重(Weight),,,
english,英文文本,,,英Z
Preset,预设,预设,预设,プリセット
ControlNet v1.1.238,扩散控制网络(ControlNet),,,
Filter,,,,フィルタ`
Apply color correction to img2img results to match original colors.,对图生图结果应用颜色校正以匹配原始颜色,对图生图结果应用颜色校正以匹配原始颜色,对图生图结果应用颜色校正以匹配原始颜色,元画像に合わせてimg2imgのY果を色a正する
DreamArtist-sd-webui-extension,梦作家,梦作家,梦作家,DreamArtist-sd-webui-extension
Resize the image so that entirety of image is inside target resolution. Fill empty space with image's colors.,调整图像大小，使整个图像在目标分辨率内。用图像的颜色填充空白区域,调整图像大小，使整个图像在目标分辨率内。用图像的颜色填充空白区域,调整图像大小，使整个图像在目标分辨率内。用图像的颜色填充空白区域,画像をリサイズして、タ`ゲット解像度の中にГ蓼毪瑜Δ摔筏蓼埂？瞻撞糠证匣像の色で埋めます。
Import,导入,,,
Original Deforum Github repo  github.com/deforum/stable-diffusion,,原始 Deforum Github 仓库  github.com/deforum/stable-diffusion,原始 Deforum Github 仓库  github.com/deforum/stable-diffusion,
Automatic,自动（仅加载与模型同名的 VAE，未找到时不加载）,自动（仅加载与模型同名的 VAE，未找到时不加载）,自动,自
"Magic Prompt adds interesting modifiers to your prompt for a little bit of extra spice.\nThe first time you use it, the MagicPrompt model is downloaded so be patient.\nIf you're running low on VRAM, you might get a CUDA error.",魔法提示词在提示词中加入有趣的修饰，额外增添趣味\n首次使用时会下载 MagicPrompt 模型，请耐心等待\n在低显存情况下可能会导致 CUDA 报错,魔法提示词在提示词中加入有趣的修饰，额外增添趣味\n首次使用时会下载 MagicPrompt 模型，请耐心等待\n在低显存情况下可能会导致 CUDA 报错,魔法提示词在提示词中加入有趣的修饰，额外增添趣味\n首次使用时会下载 MagicPrompt 模型，请耐心等待\n在低显存情况下可能会导致 CUDA 报错,Magic Promptは、プロンプトに面白いモディファイを追加して、ちょっとしたスパイスを加えることができます。\n初回使用rはMagicPromptのモデルがダウンロ`ドされますので、しばらくお待ちください。\nVRAMが不足している龊稀CUDAエラ`がk生することがあります。
Padding mode,,,,パディングモ`ド
Gustavosta/MagicPrompt-Dalle,,,,Gustavosta/MagicPrompt-Dalle
DDIM Eta,,,,DDIM Eta
"Use a two step process to partially create an image at smaller resolution, upscale, and then improve details in it without changing composition",使用两步处理的时候，以较小的分辨率生成初步图像，接着放大图像，然后在不更改构图的情况下改进其中的细节,使用两步处理的时候，以较小的分辨率生成初步图像，接着放大图像，然后在不更改构图的情况下改进其中的细节,使用两步处理的时候，以较小的分辨率生成初步图像，接着放大图像，然后在不更改构图的情况下改进其中的细节,画像生成を二段Aのプロセスで行います。最初に低解像度で途中までの画像を作成し、次に大して、恧浃à氦思部を改善します。
https://github.com/hnmr293/posex.git,,,,https://github.com/hnmr293/posex.git
Comp mask type,,,,コンポジットマスクのタイプ
Additional Networks,附加网络(Lora),可选附加网络(LoRA插件),附加网络(LoRA),Additional Networks
strength,,强度,强度,さ
Load Scene,加载场景,,,
Add X/Y/Z script info to its picture in the grid,将X/Y/Z脚本信息添加到宫格图的生成信息中,,,
blend,,颜色混合,颜色混合,
hu,,,,hu
microsoft/Promptist,,,,microsoft/Promptist
Hires steps,高分辨率采样次数,高清修复采样次数,高清修复采样次数,高解像度でのステップ数
for more info/ a Guide.,,,,情螭浈イドについて。
Cycles every nth Step,,,,N番目のステップごとのサイクル数
"String to use as left bracket for parser variants, .e.g {variant1|variant2|variant3}",,,,文解析でバリエ`ションの左括弧として使用する文字列 例: {variant1|variant2|variant3}
Translation display order,翻译显示顺序,翻译的显示顺序,翻译的显示顺序,表示
shuffle,随机风格（shuffle 模型）,,风格转移（shuffle）,
fast,快速处理（牺牲处理质量）,,,速い
"For SD upscale, how much overlap in pixels should there be between tiles. Tiles overlap so that when they are merged back into one picture, there is no clearly visible seam.",使用 SD 放大(SD upscale)时，图块(Tiles)之间应该有多少像素重叠。图块(Tiles)之间需要重叠才可以让它们在合并回一张图像时，没有清晰可见的接缝,使用 SD 放大(SD upscale)时，图块(Tiles)之间应该有多少像素重叠。图块(Tiles)之间需要重叠才可以让它们在合并回一张图像时，没有清晰可见的接缝,使用 SD 放大(SD upscale)时，图块(Tiles)之间应该有多少像素重叠。图块(Tiles)之间需要重叠才可以让它们在合并回一张图像时，没有清晰可见的接缝,SDアップスケ`ルで、どれだけタイルgの重なりを_保するか(pxg位)。タイルの一部を重}させることで、1枚の画像にしたr明らかな@ぎ目がなくなります。
ControlNet v1.1.177,扩散控制网络(ControlNet),,,
ControlNet Unit 5,控制单元 5,,ControlNet单元5,
5 units,,,启用了5个单元,
Weight for cond match (grad/replace-grad mode),用于匹配文字调节(cond)的权重 (梯度/取代模式),用于匹配文字调节(cond)的权重 (梯度/取代模式),用于匹配文字调节(cond)的权重 (梯度/取代模式),
"(Experimental, keep cond caches across jobs, reduce overhead.)",,,（实验性功能，跨作业保留条件缓存，减少开销。）,
"Set seed to -1, which will cause a new random number to be used every time",将随机种子设置为 -1，则每次都会使用一个新的随机数,将随机种子设置为 -1，则每次都会使用一个新的随机数,将随机种子设置为 -1，则每次都会使用一个新的随机数,シ`ドを-1にO定し、盎匦陇筏ぢ沂を使用します。
sd-webui-gelbooru-prompt,Gelbooru标签自动摘录插件,Gelbooru标签自动摘录插件,Gelbooru标签自动摘录插件,
Zoom,,,,ズ`ム
realesr-animevideov3,,,,realesr-animevideov3
hi,,,,hi
Skip,跳过,跳过,跳过,スキップ
singularize,,,,singularize
"Allows you to easily, or even completely automatically start using HTTPS.",让你可以很简单地自动配置HTTPS,让你可以很简单地自动配置HTTPS,让你可以很简单地自动配置HTTPS,gに、あるいは完全に自婴HTTPSの使用を_始できるようにします。
ControlNet v1.1.267,扩散控制网络(ControlNet),,,
Set your total number of keyframes to be 21 more than the last inserted keyframe image.,,,,キ`フレ`ムの合数を、最後に啡毪丹欷骏`フレ`ム画像よりも21多くO定してください。
Write prompts to file: Create a new .txt file for every batch containing the prompt template as well as the generated prompts.,,,,プロンプトをファイルにきzむ: プロンプトテンプレ`トと生成されたプロンプトを含むバッチごとに、新しい .txt ファイルを作成します。
Weight 1,权重 1,权重 1,权重 1,重み 1
Waiting...,,,,待C中...
normal_bae,法线贴图（normalbae 模型，BAE 算法）,,法线贴图（Normal Map，BAE 算法）,
"Width/height limit for the above option, in pixels",上述选项的宽、高限制，单位：像素,上述选项的宽、高限制，单位：像素,上述选项的宽、高限制，单位：像素,上のオプションの幅/高さ制限 (ピクセル)
"{% for colour in wildcard(""__colours__"") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}","{% for colour in wildcard(""__colours__"") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",,,"{% for colour in wildcard(""__colours__"") %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}"
Aesthetic steps,美术风格迭代步数,美术风格迭代步数,美术风格迭代步数,Aesthetic ステップ数
Foot Size,脚尺寸,,,
Step,,,,ステップ数
CLIP Minimum length,,,,CLIPの最大L
Swap Sample Faces,,,,サンプル面を入れ替え
I'm feeling lucky,手气不错,手气不错,手气不错,I'm feeling lucky
Mouse wheel,,,鼠标滚轮,
The learning rate scheduler to use.,要使用的学习率调度器,要使用的学习率调度器,要使用的学习率调度器,
de,,,,de
Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.,,,,Stable Horde Client. 他のユ`ザ`のPCを使用して画像を生成します。GPUがない龊悉吮憷です。
The frames of AI generated video,,,,The frames of AI generated video
Leave blank to save images to the default path.,留空以将图像保存到默认路径,留空以将图像保存到默认路径,留空以将图像保存到默认路径,空冥钎钎榨━毳趣违靴工嘶像を保存
sigma churn,sigma churn,,,sigma churn
Load from:,加载自：,加载自：,加载自：,iz
Start from Axis,优先遍历的坐标轴,优先遍历的坐标轴,优先遍历的坐标轴,
Checkbox Group,,,,Checkbox Group
"How strong of a variation to produce. At 0, there will be no effect. At 1, you will get the complete picture with variation seed (except for ancestral samplers, where you will just get something).",想要产生多强烈的变化。设为 0 时，将没有效果。设为 1 时，你将获得完全产自差异随机种子的图像（此功能对带有 a 后缀的采样器无效）,想要产生多强烈的变化。设为 0 时，将没有效果。设为 1 时，你将获得完全产自差异随机种子的图像（此功能对带有 a 后缀的采样器无效）,想要产生多强烈的变化。设为 0 时，将没有效果。设为 1 时，你将获得完全产自差异随机种子的图像（此功能对带有 a 后缀的采样器无效）,生成される画像に加える浠の度をO定します。度が0の龊悉嫌绊なし、度が1の龊悉贤耆に浠用シ`ドに基づいた画像が生成されます。ただし、Ancestralサンプラ`を使用する龊悉仙成される画像が多少なる可能性があります。
Related to output file,与输出文件有关的命名参数,与输出文件有关的命名参数,与输出文件有关的命名参数,出力ファイルにvB
"A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.",,,,ノイズの多いソ`スは、スキャンの精度を妨げる可能性があります。この龊稀ノイズはp少しますが、ディテ`ルもp少します。しかし、これはオリジナルには影しませんし、DFIのS容欷蛳沥幛毪长趣钎啸楗螗工蛉・氡匾があるかもしれませんが、rには平坦な画像もプロセス上いことではありません。
Prepend additional tags,前置附加的 Tag,,,先^にタグを追加
Alias from file,元数据中记录的别名（不随文件名变化而变化）,,元数据中的别名（Alias）,
Split image overlap ratio,分割图像重叠的比率,分割图像重叠的比率,分割图像重叠的比率,画像の重}比を分割
Filter by Tags,按 Tag 筛选,,,タグでフィルタリングする
Active in third party textboxes [Dataset Tag Editor] [Image Browser] [Tagger] [Multidiffusion Upscaler] (Requires restart),,,在如下第三方插件中也启用[Dataset Tag Editor] [Image Browser] [Tagger] [Multidiffusion Upscaler] (需要重启),
Prefix,前缀匹配,,,接^辞
Alpha Blend,基础权重（Alpha Blend，总提示词将以此权重作用于整个画面，总提示词蒙版区域强制为1）,,,
Primary model (A),模型 A,模型 A,模型 A,1つ目のmodel (A)
X Values,X轴值,,,
Reuse original image,复用原图,复用原图,复用原图,オリジナルの画像を再利用する
Save separate diffusers snapshots when training completes.,,,,トレ`ニング完了rに、ディフュ`ザ`のスナップショットをe々に保存します。
Krita Plugin.,Krita 插件,Krita 插件,Krita 插件,Kritaプラグイン。
Image path,,,,画像のパス
Lora UNET Rank,,,,LoRA UNET Rank
version,版本信息,,,
M_B_00,,模型B 中间层,模型B 中间层,
Initialization text (negative),,,,初期化テキスト（ネガティブ）
Scoring type,,,分数类型,
Advanced Seed Blending,高阶种子混合,高阶种子混合,高阶种子混合,
Video mask path,,,,踊マスクのパス
https://github.com/d8ahazard/sd_dreambooth_extension.git,,,,https://github.com/d8ahazard/sd_dreambooth_extension.git
Edit Caption of Selected Image,编辑选中图像的注释,,,xkした画像のキャプションを集
tp__sogou,,,,tp__sogou
Full res mask,,,,フル解像度マスク
quad,二阶,二阶,二阶,quad
Reload List,重新加载列表,,,
Prompt for hires fix pass.\nLeave empty to use the same prompt as in first pass.,,,高清修复过程-提示词\n留空则使用和修复前同样的提示词,
Precision of selected area ? mask_precision,,,,xkしたI域の精度 <unk> mask_precision
Korean localization,,,,n国Z翻U
Click Here,,,,ここをクリック
Show DepthMap,,,,深度マップを表示
crumb/bloom-560m-RLHF-SD2-prompter-aesthetic,,,,crumb/bloom-560m-RLHF-SD2-prompter-aesthetic
Generate Video,,,,ビデオを生成
Interpolation method,插值方式,,插值方法,ag法
co,,,,co
extensive,扩大,,,
?,?,,,
Adjusts the size of the image by multiplying the original width and height by the selected value. Ignored if either Resize width to or Resize height to are non-zero.,按比例放大原分辨率，单独设定目标长宽时被忽略,按比例放大原分辨率，单独设定目标长宽时被忽略,按比例放大原分辨率，单独设定目标长宽时被忽略,元の幅と高さを指定したで欷彼悚筏苹像のサイズを{整します。幅のサイズ涓または高さのサイズ涓が0以外になっている龊稀このはoされます。
Layer1 opacity,,,,Layer1 不透明度
(C10) Thertiary,,(C10) 第三,(C10) 第三,
txt2img,文生图,文生图,文生图,txt2img
stable-diffusion-webui-artists-to-study,艺术家图库,艺术家图库,艺术家图库,stable-diffusion-webui-artists-to-study
switch: Use in conjunction with [case] to run different logic blocks depending on the value of a var.,,,,切り替え: varのに辘袱飘なるロジックブロックをg行するには、 [case] とMみ合わせて使用します。
wd14-convnext-v2-git,,,,wd14-convnext-v2-git
Set from ID(-1 for last),应用所选ID的历史信息,,,
movements,,,,ム`ブメント(式)
Reset vars,,重置变量(vars),重置变量(vars),
ControlNet v1.1.221,扩散控制网络(ControlNet),,,
Localization file (Please leave `User interface` - `Localization` as None),"本地化翻译文件（开启后请将""用户界面-本地化翻译""设置为""无""）",本地化翻译文件 (请保持 `用户界面` - `本地化` 的选项为 None/无),本地化翻译文件 (请保持 `用户界面` - `本地化` 的选项为 None/无),言Zファイル (`ユ`ザ`インタ`フェ`ス` - `言ZO定` を「なし」にしてください)
Apply and restart UI,应用并重启用户界面,应用并重启用户界面,应用并重启用户界面,m用してUIを再起
Enable Noise Inversion,启用噪声反转,,,
Enable Region 0,启用此区域,,,
An always visible script extension to configure seamless image tiling independently for the X and Y axes.,,,,シ`ムレスイメ`ジタイリングをXSとYSで独立してO定するための常r表示スクリプトC能です。
bf16,储存为bf16,,,
Steps for cycle,,,,サイクルに於けるステップ数
Colorprimarytext,Colorprimarytext,,,
InOutPaint,,,,InOutPaint
Read Caption from Selected Image,从选中图像读取注释,,,xkした画像からキャプションをiむ
Unload VAE and CLIP from VRAM when training,训练时从 显存(VRAM) 卸载 VAE 和 CLIP ,训练时从 显存(VRAM) 卸载 VAE 和 CLIP ,训练时从 显存(VRAM) 卸载 VAE 和 CLIP ,
Move Mode (X key),切换到平移（按住X键）,,,
Select Translater,翻译器选择,,,翻Uサ`ビスをxk
merge from ID,读取历史合并信息（输入ID，-1表示最后一个）,,,
For,,用于,用于,
Number of negative vectors per token,每个词元(token)的负面向量数,每个词元(token)的反向向量数,每个词元(token)的反向向量数,ト`クンごとのネガティブベクトルの数
"More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).",,,,SDアップスケ`ルのためのよりMiしたオプション。より高いデノイズ率 (0.3-0.5) を用いてオリジナルよりも少ない歪みをgFします。
Replacement ? replacement,,,,置Q → 置Q
ControlNet v1.1.175,扩散控制网络(ControlNet),,,
If the groups wont drop down click,如果无法下拉组，点击,如果无法下拉组，点击,如果无法下拉组，点击,
IN09,,输入层09,输入层09,
Do not save grids consisting of one picture,只有一张图像时不要保存宫格图（建议开启）,只有一张图像时不要保存宫格图（建议开启）,只有一张图像时不要保存宫格图（建议开启）,1画像からなるグリッド画像は保存しない
Get subdirectories,获取子目录列表,,,
Region 3,区域 3,区域 3,区域 3,
Start XY plot,开始XY队列,,,
/path/to/images or /path/to/images/**/*,,,,/path/to/images または /path/to/images/**/*
Audio (if provided) will *not* be transferred to the interpolated video if Slow-Mo is enabled.,,,,スロ`モ`ションが有郡摔胜盲皮い龊稀⒁羯（もし提供されている龊希─涎agされたビデオに送されません。
Network module 4,附加网络模块 4,附加网络类型 4,附加网络类型 4,Network module 4
: Original extension\nAvailable algorithms:,：原始文件哈希，<algorithms>应替换成以下算法之一：,：原始文件哈希，<algorithms>应替换成以下算法之一：,：原始文件哈希，<algorithms>应替换成以下算法之一：,: 元の子\n利用可能なアルゴリズム:
View the wiki for usage tips.,点击查看wiki，获取使用说明,点击查看wiki，获取使用说明,点击查看wiki，获取使用说明,
house-black-white,,,,家-白\
Custom delimiter string ? _delimiter,,,,カスタム区切り文字 ? _delimiter
behind,落后,落后,落后,更新あり
softedge_hed,边缘检测（softedge 模型，HED 算法）,,软边缘检测（softedge，HED 算法）,
conditioning-highres-fix,高分辨率修复原图调节,高清修复原图调节,高清修复原图调节,conditioning-highres-fix
Colorbgcontainer,Colorbgcontainer,,,
Alpha matting,Alpha matting 抠图算法,,Alpha matting抠图算法,アルファマット合成
(changes seeds drastically; use CPU to produce the same picture across different vidocard vendors),,,(GPU的话可能会因为显卡不同而导致图片不能复现，使用CPU的话可以较高的保证图片复现),
DFI Expand:,,,,DFI Expand:
"1st and last digit must be 0 and values should be between 0 and 1. ex:'0, 0.01, 0'",,,,"1番目と最後の数字は0でなければならず、は0と1のgでなければなりません。ex:'0, 0.01, 0'"
How many times to improve the generated image iteratively; higher values take longer; very low values can produce bad results,迭代改进生成的图像多少次；更高的值需要更长的时间；非常低的值会产生不好的结果,迭代改进生成的图像多少次；更高的值需要更长的时间；非常低的值会产生不好的结果,迭代改进生成的图像多少次；更高的值需要更长的时间；非常低的值会产生不好的结果,生成された画像を反偷膜烁纳皮工牖厥です。を高くするとI理にrgがかかり、を低くしすぎるといY果になる可能性があります。
newest first,最新,最新,最新,新しい
Submit,提交,,,
Override `Denoising strength` to 1?,覆写 `重绘幅度` 为 1?,覆写 `重绘幅度` 为 1?,覆写 `重绘幅度` 为 1?,ノイズ除去度を1に上きする
Deforum-webui (use tab extension instead!),Deforum-webui (请使用选项卡上的扩展版本),Deforum-webui (请使用选项卡上的扩展版本),Deforum-webui (请使用选项卡上的扩展版本),
Cover image,预览图像,封面图像,封面图像,カバ`画像
Don't generate images,不生成图像,不生成图像,不生成图像,画像を生成しない
Slow Mo,,,,スロ`モ`ション
single image,单张图像,,拆分一张图片,
Remove Stylesheet,移除 风格样式表,移除 风格样式表,移除 风格样式表,
tiling,,,,タイリング
stable-diffusion-webui-conditioning-highres-fix,高分辨率修复原图调节强度 ,高清修复原图调节强度,高清修复原图调节强度,stable-diffusion-webui-conditioning-highres-fix
"If $$ is not provided, then 1$$ is assumed.",若没提供 $$，默认为 1$$,若没提供 $$，默认为 1$$,若没提供 $$，默认为 1$$,$$ が入力されていない龊稀1$$ にO定されます。
temparature,,,,色温度
softedge_hedsafe,边缘检测（softedge 模型，保守 HED 算法）,,软边缘检测（softedge，保守 HED 算法）,
custom fold,自定义文件夹,自定义文件夹,自定义文件夹,
Settings > Configure Krita...,,,,O定 > KritaのO定...
Escape parentheses on insertion,对插入的括号进行转义,对插入的括号进行转义,对插入的括号进行转义,啡rに括弧をエスケ`プする
Layer4 opacity,,,,Layer4 不透明度
Pixelization,像素化,,,Pixelization
Return true if any one of multiple conditions are true ? _any,,,,いずれかの条件が true の龊悉 true を返す ? _any
Image path ? image_path,,,,画像パス →　画像 パス
Blend mode,,,,ブレンド モ`ド
ta,,,,ta
Wildcards file,,,,ワイルドカ`ドファイル
From (full path),,,从（完整路径）,From (full path)
Result = A * (1 - M) + B * M,结果 = A × (1 - M) + B × M,结果 = A * (1 - M) + B * M,结果 = A * (1 - M) + B * M,出力されるモデル = A * (1 - M) + B * M
Load caption from filename if no text file exists,如果不存在对应的文本文件，则从文件名加载图片注释,,,テキストファイルが存在しない龊稀ファイル名からキャプションをiみzむ
sdweb-merge-block-weighted-gui,分层加权模型合并插件(MBW),分块加权模型合并插件(MBW),分块加权模型合并插件(MBW),
Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.,,,,Stable Horde用のワ`カ`クライアント。あなたのPCで、他のユ`ザ`のために写真を生成します。その他のh明はreadmeをごEください。
Generate Class Images,,,,クラス画像の生成
Preset Name,预设名称,,,プリセット名
path/to/output,,,,path/to/output
set_index,设置索引,设置索引,设置索引,set_index
mi,,,,mi
substring: Slices up the content.,,,,部分文字列: コンテンツをスライスします。
tp_modernMt,,,,tp_modernMt
Learning rate ? learning_rate,,,,学率 → 学率
End Page,尾页,尾页,尾页,最後のペ`ジ
Rating,评分,评分,评分,u
"Alternatively, use",,,,代わりのものを使用
Invert evaluation such that a true statement will return false ? _not,,,,true の文が false を返すようにuを反させる ? _not
Use the negative_prompts field to automatically append all words as a negative prompt. *Don't* add --neg in the negative_prompts field!,,,,ネガティブプロンプトフィ`ルドを使用して、すべてのgZを自拥膜素のプロンプトとして追加してください。ネガティブプロンプトフィ`ルドに--negを追加しないでください！
seed_behavior,,随机种子行为,随机种子行为,
From img2img,从 图生图 获取参考图,,从图生图加载,
realesrgan-x4plus-anime,,,,realesrgan-x4plus-anime
[ControlNet] Pre Resolution,[ControlNet] 预处理器 分辨率,[ControlNet] 预处理器 分辨率,[ControlNet] 预处理器 分辨率,[ControlNet] 事前の解像度
Include copyright tags in tag string,,在标签字串中包含版权标签,在标签字串中包含版权标签,
: Ensure,,,,_Jしてください。
right,右侧,右,右,右
Reference,,,参考,
Sample Image Prompt,样本图像的提示词,样本图像的提示词,样本图像的提示词,サンプル イメ`ジ プロンプト
Network module 5,附加网络模块 5,附加网络类型 5,附加网络类型 5,Network module 5
Camera Near,近景阈值,,,
ControlNet v1.1.106,扩散控制网络(ControlNet),,,
Show cards for models in hidden directories,,,显示隐藏文件夹内的模型卡片,
Clear prompt,清空提示词(prompt),清空提示词(prompt),清空提示词(prompt),プロンプトをクリア
[ControlNet] Resize Mode,[ControlNet] 缩放模式,[ControlNet] 缩放模式,[ControlNet] 缩放模式,[ControlNet] リサイズのモ`ド
Top-k,,,,Top-k
Save masked image,保存带蒙版的图片,,保存蒙版后的图片,
State,运行状态,运行状态,运行状态,状B
Arbitrary variable names to free from memory ? verbatim,,,,任意の涫名をメモリから解放する →verbatim
Final Prompt,最终提示词预览,,,
Fixed Roll,滚转修复,滚转修复,滚转修复,
Write image to a directory (default - log/images) and generation parameters into csv file.,将图像写入目录（默认 - log/images）并将生成参数写入 csv 表格文件,将图像写入目录（默认 - log/images）并将生成参数写入 csv 表格文件,将图像写入目录（默认 - log/images）并将生成参数写入 csv 表格文件,画像はディレクトリ(デフォルト: log/images)に、生成パラメ`タはcsvファイルにき出します。
Please go to img2img to copy to inpaint upload.,请前往图生图页面，再选择将蒙版 >>局部重绘(上传蒙版),,请到图生图页面使用“复制蒙版到局部重绘（上传蒙版）”,
Use same random seed for all lines,每行输入都使用同一个随机种子,每行输入都使用同一个随机种子,每行输入都使用同一个随机种子,すべての行に同じランダムシ`ドを使用
Add weights to Sequence X,将权重添加到X轴队列中,,,
AUTOMATIC/promptgen-lexart,,,,AUTOMATIC/promptgen-lexart
Seed schedule,,,,シ`ドのスケジュ`ル
(B2) Secondary,,(B2) 第二,(B2) 第二,
Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.,根据提示词生成一系列关注逐渐转移的图像。此脚本使你能够在提示词中为词元(token)的权重指定一个范围，然后生成从一端到另一端的一系列图像,根据提示词生成一系列关注逐渐转移的图像。此脚本使你能够在提示词中为词元(token)的权重指定一个范围，然后生成从一端到另一端的一系列图像,根据提示词生成一系列关注逐渐转移的图像。此脚本使你能够在提示词中为词元(token)的权重指定一个范围，然后生成从一端到另一端的一系列图像,プロンプトの注意をずらす画像のシ`ケンスを生成する。このスクリプトは、プロンプト内のト`クンの重みに欷蛴毪ā⒆畛酩违醛`クンから2番目のト`クンへとステップする一Bの画像を生成することができます。
https://github.com/Mikubill/sd-webui-controlnet.git,,,,https://github.com/Mikubill/sd-webui-controlnet.git
Refresh page,刷新页面,刷新页面,刷新页面,
Casing method ? str,,,,ケ`シング方法 ? str
Add a second progress bar to the console that shows progress for an entire job.,向控制台添加第二个进度条，显示整个作业的进度,向控制台添加第二个进度条，显示整个作业的进度,向控制台添加第二个进度条，显示整个作业的进度,ジョブ全体のM盲颔偿螗僵`ルに表示する2つ目のプログレスバ`を追加する
bg,,,,bg
load_switch,载入开关,载入开关,载入开关,load_switch
None,无,无,无,なし
Face restoration,面部修复,面部修复,面部修复,の修
"An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts.",,内置 Composable Diffusion 的扩展，能让你划分潜空间并在对应区域反映出你指定的提示词段落。,内置 Composable Diffusion 的扩展，能让你划分潜空间并在对应区域反映出你指定的提示词段落。,
Prepend the content to the variable's current value ? _prepend,,,,涫のF在の先^にコンテンツを追加する ? _prepend
Close Preview,,,关闭预览,
Dynamic Prompts,动态提示词,动态提示词,动态提示词,Dynamic Prompts
CFG,,,,CFG
Use Noise training scheduler(test),,,,ノイズトレ`ニングスケジュ`ラを使用(テスト)
Generate ControlNet images,根据视角生成模式图,,,
You can use this as a guided image tool or as a looper depending on your settings in the keyframe images field. \n                               Set the keyframes and the images that you want to show up. \n                               Note: the number of frames between each keyframe should be greater than the tweening frames.,,,,キ`フレ`ム画像フィ`ルドのO定に辘袱啤これをガイド付き画像ツ`ルまたはル`パ`として使用できます。\n表示したいキ`フレ`ムと画像をO定してください。\n※：各キ`フレ`ムgのフレ`ム数は、中gフレ`ムよりも大きくする必要があります。
"With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.",,,,"With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video."
length: Returns the number of items in a delimited string.,,,,length: 区切られた文字列の目数を返す。
Reconstruction loss weight,重建 损失(loss) 权重,重建 损失(loss) 权重,重建 损失(loss) 权重,再B p失の重み
save precision,保存精度,,,
Firstpass height,首次高度,首次高度,首次高度,
Value Threshold ? value_threhsold,,,,しきい → しきい
Shuffle the array ? _shuffle,,,,配列をシャッフル? _shuffle
Canvas Height,画布高度（使用上传图片时请忽略此项）,画布高度（使用上传图片时请忽略此项）,画布高度（使用上传图片时请忽略此项）,キャンバスの高さ
Bump seed (If > 0 do a Compare Paths but only one image. No video),自动递增种子 (大于 0 的时候会对比变迁轨迹，但不会生成视频而是只是一张图),自动递增种子 (大于 0 的时候会对比变迁轨迹，但不会生成视频而是只是一张图),自动递增种子 (大于 0 的时候会对比变迁轨迹，但不会生成视频而是只是一张图),
Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.,,,,既存のCLiPモデルに、事前に学させた小さなモデルを追加して、画像の知的な美的スコアを算出します。
"default variables: in \{\}, like \{init_mask\}, \{video_mask\}, \{everywhere\}",,,,"デフォルト涫：\{init_mask\}, \{video_mask\}, \{everywhere\}のように、\{\}で表します。"
"Make your changes, press 'View changes' to review the changed default values,",,,修改好你要的页签状态后，在这个页面点击“预览修改”,
Divide Ratio,分割比例（同行/列逗号分隔，分号换行/列）,,,分割の比率
Face restore,,,,の修
Add program version to generation information,添加生成该图像所使用的的 WebUI 版本信息,,在生成信息中加入程序版本号,
Near clip,,,,近くのクリップ
New preset name ,新预设的名称,新预设的名称,新预设的名称,
Bake in VAE,整合入模型的 VAE,整合入模型的 VAE,整合入模型的 VAE,VAEをきzむ
Number of Hard Resets,,,,ハ`ドリセット数
oldest first,发布时间,发布时间,发布时间,古い
Train an embedding; must specify a directory with a set of 1:1 ratio images,训练 Embedding； 必须指定一组具有 1:1 比例图像的目录,训练 Embedding； 必须指定一组具有 1:1 比例图像的目录,训练 Embedding； 必须指定一组具有 1:1 比例图像的目录,
Load Video Settings,,载入视频设置,载入视频设置,踊O定をiみzむ
Instance Token + Class Token + Description,实例的词元 + 类的词元 + 描述,实例的词元 + 类的词元 + 描述,实例的词元 + 类的词元 + 描述,
Overlay mask,,,,マスクをオ`バ`レイ
tp_translateCom,,,,tp_translateCom
Use optimized images in the thumbnail interface (significantly reduces the amount of data transferred),自动优化缩略图质量，以减少数据传输,,在缩略图界面优化图片显示（远程使用时大大减少数据传输量）,
Mask for ControlNet Inpaint,,,用于ControlNet重绘的蒙版,
KDPM2AncestralDiscrete,,,,KDPM2AncestralDiscrete
Details,细节设置（详见插件GitHub页面）,,详情,
Styles,模板风格,模板风格,模板风格,スタイル
Concept 2,,,,コンセプト 2
DFI Expand,,,,DFI Expand
LMS Karras,LMS Karras,,,LMS Karras
Postprocessing,后处理,后处理,后处理,後I理
Combinations,组合,组合,组合,Mみ合わせ
segmentation prompt,提示词(Segmentation Prompt),,,
Order,排序方式,排序方式,排序方式,序
ControlNet v1.1.121,扩散控制网络(ControlNet),,,
clip_threshold,CLIP 阈值,,,
Epochs to Simulate,,,,シミュレ`トするエポック数
File Name,文件名,文件名,文件名,ファイル名
not,,,,ではない
animation_mode,,动画模式,动画模式,
ru_RU Localization,,,,ru_RU Localization
"Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8",推荐设置：采样迭代步数：80-100，采样器：Euler a，重绘幅度：0.8,推荐设置：采样迭代步数：80-100，采样器：Euler a，重绘幅度：0.8,推荐设置：采样迭代步数：80-100，采样器：Euler a，重绘幅度：0.8,"推XO定: サンプリング回数: 80-100, サンプリングアルゴリズム: Euler a, ノイズ除去度: 0.8"
interrupt,,,,中断
Enable AA for Downscaling.,缩小时启用抗锯齿(AA),缩小时启用抗锯齿(AA),缩小时启用抗锯齿(AA),ダウンスケ`リングにAAを有炕します。
Style,,,,スタイル
stable-diffusion-webui-model-toolkit,模型工具包插件,,,
ControlNet v1.1.277,扩散控制网络(ControlNet),,,
"Run: Sampler, Width, Height, tiling, resize seed.",,,,g行: サンプラ`、幅、高さ、タイリング、シ`ドのサイズ涓。
Train UNET,,,,UNETでトレ`ニングする
safetensors,使用.safetensors格式,,,safetensors
Animation mode,,,,アニメ`ションモ`ド
"Enter categody ids, separated by +. For example, if you want bed+person, your input should be 7+12 for ade20k and 59+0 for coco.",输入类别ID，用 + 分隔。例如，如果你想要床+人，那么对于 ADE20k协议，你的输入应该是 7+12，对于 COCO协议，输入应该是 59+0,,每个id之间使用+分割，例如床+人在ade20k协议下就应该输入7+12，在coco协议下应该输入59+0,
Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.,显示来自图像板块（image booru，如 Danbooru）的标签(tags)自动补完。使用本地标签(tag) CSV 文件，并包含可用于自定义配置的文件,显示来自图像板块（image booru，如 Danbooru）的标签(tags)自动补完。使用本地标签(tag) CSV 文件，并包含可用于自定义配置的文件,显示来自图像板块（image booru，如 Danbooru）的标签(tags)自动补完。使用本地标签(tag) CSV 文件，并包含可用于自定义配置的文件,Danbooruなどの画像ボ`ドからのタグの自友a完のヒントを表示します。ロ`カルタグCSVファイルを使用し、カスタマイズのためのO定を含みます。
exif keyword,搜索生成信息关键字（按回车开始检索）,搜索生成信息关键字（按回车开始检索）,搜索生成信息关键字（按回车开始检索）,exif キ`ワ`ド
(selected items appear first),,,(选择的选项将优先显示),
DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.,,,,DAAMはDiffusion Attentive Attentive Attentive Mapsの略です。注意テキスト(プロンプトに含まれている文字列である必要があります) を入力してg行します。 注目テキストごとに、ヒ`トマップを重ねた画像が元の画像とともに生成されます。
"Prompt blacklist, find and replace, for semi-private and public instances.",,,,セミプライベ`トやパブリックインスタンスのためのブラックリストプロンプトを仕鳌⒅QするC能
Get comma-separated list of models (for XY Grid),生成逗号分隔的模型列表(方便X/Y表使用),生成逗号分隔的模型列表(方便X/Y表使用),生成逗号分隔的模型列表(方便X/Y表使用),
Magic prompt blocklist regex,,,,Magic prompt のブロックリスト正表F
Image Count,,,,画像の数
Scribble Mode (Reverse color),涂鸦模式（反色，强制预处理器重新识别）,涂鸦模式（反色，强制预处理器重新识别）,涂鸦模式（反色，强制预处理器重新识别）,
DFI Render,,,,DFIレンダ` (Differential frame interpolation - 差分フレ`ムa完)
Original prompt,初始提示词,初始提示词,初始提示词,オリジナルのプロンプト
"to see which words are constructed using multiple sub-words, e.g. 'computer' doesn't exist in stable diffusion's CLIP dictionary and instead 'compu' and 'ter' are used (1 word but 2 Embedding vectors). Currently buggy and needs a moment to process before pressing the button. If it doesn't work after a moment, try adding a random space to refresh it.",查看哪些词是使用多个子词构成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（1 个单词但使用 2 个 Embedding 向量）。目前这个扩展还有点问题，在按下按钮之前需要一点时间来处理。如果过了一会还是不行，试试随便加个空格刷新一下,查看哪些词是使用多个子词构成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（1 个单词但使用 2 个 Embedding 向量）。目前这个扩展还有点问题，在按下按钮之前需要一点时间来处理。如果过了一会还是不行，试试随便加个空格刷新一下,查看哪些词是使用多个子词构成的，例如 Stable Diffusion 的 CLIP 字典中不存在 'computer'，而是使用 'compu' 以及 'ter'（1 个单词但使用 2 个 Embedding 向量）。目前这个扩展还有点问题，在按下按钮之前需要一点时间来处理。如果过了一会还是不行，试试随便加个空格刷新一下,
AND,与(AND),,,AND
{2$$artist1|artist2|artist3},{2$$艺术家1|艺术家2|艺术家3},{2$$艺术家1|艺术家2|艺术家3},{2$$艺术家1|艺术家2|艺术家3},{2$$artist1|artist2|artist3}
stable-diffusion-NPW,,,,stable-diffusion-NPW
Shuffle,,,风格转移,
"Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.",,,,"Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later."
The 1st and last keyframe images should match.,,,,最初と最後のキ`フレ`ム画像は一致する必要があります。
timestamp,时间戳,,,
Check Console log for Downloading Status,打开控制台以查看下载状态,下载状态显示在控制台中。,下载状态显示在控制台中。,
X values,X轴值,X轴值,X轴值,XSの
Catppuccin Flavor,Catppuccin 主题样式（背景颜色）,Catppuccin 主题样式（背景颜色）,Catppuccin 主题样式（背景颜色）,
EMA replace steps (nagative),EMA 替换步数 (负),EMA 替换步数 (负),EMA 替换步数 (负),EMAの置Qステップ（ネガティブ）
Prompt Gallery,,,,Prompt Gallery
"Keyframes: motion parameters for 2D and 3D (angle, zoom, translation, rotation, perspective flip).",,,,キ`フレ`ム: 2D と 3D のモ`ションパラメ`タ (角度、ズ`ム、位置、回、パ`スペクティブフリップ)。
[output_extension],,,,[output_extension]
Resize width to,将宽度调整到,将宽度调整到,将宽度调整到,サイズ涓後の幅
Max Batch Count,最大批次数量,最大批次数量,最大批次数量,最大バッチ数
and tick the checkbox.,,,,チェックボックスをオンにします。
Nose To Neck,鼻子-脖子,,,
Remove background,背景去除算法,,去背景,背景を削除
ControlNet v1.1.252,扩散控制网络(ControlNet),,,
Heatmap blend alpha,,,,ヒ`トマップブレンド α
Loading...,载入中...,载入中...,载入中...,iみzみ中...
tp_caiyun,,,,tp_caiyun
Highres. Denoising Strength,高清修复：重绘幅度,高清修复：重绘幅度,高清修复：重绘幅度,ハイレゾのノイズ除去の度
Magic Prompt batch size,,,,Magic Prompt のバッチサイズ
(in sampling steps - show new live preview image every N sampling steps; -1 = only show after completion of batch),,,单位：采样步数，-1表示只显示最后的结果,
Manual dataset seed,,,,手婴钎签`タセットシ`ドを使う
wiki,wiki文档,wiki文档,wiki文档,wiki
Colortext,Colortext,,,
Strict,,,,格
Number of random seed(s),随机种子数量,随机种子数量,随机种子数量,ランダムシ`ドの数
TEnc Weight 2,Text Encoder 权重 2,Text Encoder 权重 2,Text Encoder 权重 2,TEncの重み2
2 units,,,启用了2个单元,
Image Generation Scheduler,,,,画像生成スケジュ`ラ`
Mask minimum number of pixels ? min_area,,,,マスクの最小ピクセル数 ? min_area
Select function:,,,,C能xk
(improves performance when prompt and negative prompt have different lengths; changes seeds),,,这将提升性能，但是出图结果会改变,
Token merging ratio for img2img,,,图生图Token合并率,
Recommended to set tile sizes as large as possible before got CUDA error: out of memory.,在显存不溢出的情况下（未提示 CUDA error: out of memory），请尽可能使用更大的图块尺寸,,在显存不溢出的情况下推荐使用较大的值,
refresh,,,,プレビュ`更新（集_定）
Embedding Learning rate,Embedding 学习率,Embedding 学习率,Embedding 学习率,Embeddingの学率(Learning rate)
Set Init tab's strength slider greater than 0. Recommended value (.65 - .80).,,,,初期化タブの度スライダ`を0より大きくO定してください。推X (.65 - .80)。
Denoising strength,重绘幅度(Denoising),重绘幅度(Denoising),重绘幅度(Denoising),ノイズ除去度
Overwrite image size,重设画面尺寸（覆盖上方原有设置）,覆写图像尺寸设置,覆写图像尺寸设置,F在の画像サイズで上き
"If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.",,,,"If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding."
OUT,,,,アウト
Images directory,图像目录,图像目录,图像目录,画像ディレクトリ
Interpolation rate,,,,ag率
"This regular expression will be used extract words from filename, and they will be joined using the option below into label text used for training. Leave empty to keep filename text as it is.",此正则表达式将用于从文件名中提取单词，并将使用以下选项将它们接合到用于训练的标签文本中。留空以保持文件名文本不变,此正则表达式将用于从文件名中提取单词，并将使用以下选项将它们接合到用于训练的标签文本中。留空以保持文件名文本不变,此正则表达式将用于从文件名中提取单词，并将使用以下选项将它们接合到用于训练的标签文本中。留空以保持文件名文本不变,この正表Fを使ってファイル名からgZを抽出し、以下のオプションでY合して学用のラベルテキストにします。ファイル名のテキストをそのまま使用する龊悉峡凇
Decode steps,解码迭代步数,解码迭代步数,解码迭代步数,デコ`ドステップ数
ml,,,,ml
Automatically detects faces and replaces them.,,,,を自婴食訾贰⒅盲Qえることができます。
Generate Krita Plugin Symlink Command,,,,Kritaプラグインのシンボリックリンクコマンドを生成する
"Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.",,全新实现的双语对照翻译功能，不必再担心切换翻译后找不到原始功能。兼容原生语言包扩展，无需重新导入多语言语料。,全新实现的双语对照翻译功能，不必再担心切换翻译后找不到原始功能。兼容原生语言包扩展，无需重新导入多语言语料。,"バイリンガル翻U, 元のボタンをつける方法を心配する必要はありません. 言ZパックのC能と互Q性, 再インポ`トする必要はありません."
house-n,,,,家-n
Action on exiting caption,对退出符的响应方式,对退出符的响应方式,对退出符的响应方式,
threshold,阈值,阈值,阈值,しきい
Corruption Preserve:,,,,Corruption Preserve:
Create an aesthetic embedding out of any number of images,从任意数量的图像中创建美术风格 Embedding,从任意数量的图像中创建美术风格 Embedding,从任意数量的图像中创建美术风格 Embedding,任意の数の画像からAesthetic embeddingを作成します
Weight 5,权重 5,权重 5,权重 5,重み 5
Max Token Length,最大词元(Token)长度,最大词元(Token)长度,最大词元(Token)长度,最大ト`クンのLさ
Remove selected tags,移除已选择的的 Tag,,,xkしたタグを削除する
free_google,,,,free_google
tile division BG Remover,分块处理设置,,,
fy,,,,fy
PLMS,PLMS,,,PLMS
Discord Rich Presence,,,,Discord Rich Presence
th,,,,th
Var. strength,差异强度,差异强度,差异强度,浠の度
Provides an interface to browse created images in the web browser.,在网页浏览器里提供一个查看生成图像历史的界面,在网页浏览器里提供一个查看生成图像历史的界面,在网页浏览器里提供一个查看生成图像历史的界面,Webブラウザで作成された画像をEするためのインタ`フェ`スを提供します。
Minimum width,,,最小宽度,
sentencecase,,,,文ケ`ス
This parameter commands the new dynamic algorithm.,,,,このパラメ`タは、新しいダイナミックアルゴリズムを指令します。
spaceship-digipa-med-impact,,,,宇宙船演算子(digipa-med-impact)
dog-weird,,,,犬-奇妙
Input images directory,输入图像目录,输入图像目录,输入图像目录,入力画像のディレクトリ
cartoon,,,,カ`トゥ`ン
Length,按长度,,,Lさ
Use EMA,,,,EMAを使用
Next Image After Ranking (To be implemented),,,,次回画像ランキング(g装予定)
Moving the canvas,,,移动画布,
{2$$__artist__|__artist__},{2$$__艺术家__|__艺术家_},{2$$__艺术家__|__艺术家_},{2$$__艺术家__|__艺术家_},{2$$__artist__|__artist__}
"Hybrid motion may be used with hybrid composite off, to just use video motion.",,,,ハイブリッドモ`ションは、ビデオモ`ションを使用するために、ハイブリッド}合材と一wに使用することができます。
Aesthestic Score,美学评分,,,
x2,,,,x2
portrait-weird,,,,肖像画-奇妙
ControlNet v1.1.288,扩散控制网络(ControlNet),,,
Prompt template,,,提示词模版,プロンプトのテンプレ`ト
Aesthetic Gradients,美术风格梯度,美术风格梯度,美术风格梯度,Aesthetic Gradients
Decode CFG scale,解码提示词相关性(CFG scale),解码提示词相关性(CFG scale),解码提示词相关性(CFG scale),CFGスケ`ルをデコ`ド
Main,,,,メイン
give it a star on GitHub,,,,GitHubでスタ`をつけてください
Enter input path,键入输入路径,,输入拆分输入的路径,
Old unmaintained localizations that used to be a part of main repository,曾经在主分支上但现在不再维护的旧语言包,曾经在主分支上但现在不再维护的旧语言包,曾经在主分支上但现在不再维护的旧语言包,メインリポジトリの一部だった古いメンテナンスされていない翻U
Comp mask inverse,,,,コンポジットマスクの反
Show image creation progress every N sampling steps. Set 0 to disable.,每 N 个采样迭代步数显示图像生成进度。设置 0 禁用,每 N 个采样迭代步数显示图像生成进度。设置 0 禁用,每 N 个采样迭代步数显示图像生成进度。设置 0 禁用,
Position/Rotate Z,,,,位置/zS回
subseed_strength,,差异随机种子强度,差异随机种子强度,
Save Caption to .txt File,储存描述文本为 .txt 文件,储存描述文本为 .txt 文件,储存描述文本为 .txt 文件,
*READ ME before you use this mode!*,,,,*このモ`ドを使用する前にiんでください！*
Model 1,模型 1,模型 1,模型 1,モデル 1
FFmpeg settings,,,,FFmpegのO定
Enable MultiDiffusion,启用分块多重扩散(MultiDiffusion),启用 MultiDiffusion,启用 MultiDiffusion,MultiDiffusionを有郡摔工
loss type,,,,p失Ne
Norwegian localization,,,,ノルウェ`Z翻U
Logos,Logo,,,
Threshold,最低Tag置信阈值 (置信度大于此值的标签将被写入生成的Tags),阈值,阈值,しきい
Italian localization,,,,イタリアZ翻U
ControlNet v1.1.213,扩散控制网络(ControlNet),,,
"Mask color, enables Inpaint Sketch mode ? sketch_color",,,,マスクの色、inpaintスケッチモ`ドを有郡摔工 ? sketch_color
Additional tags (split by comma),附加标签(逗号分隔),附加标签(逗号分隔),附加标签(逗号分隔),追加タグ (カンマで区切る)
Comp mask auto contrast,,,,コンポジットマスクの自鹰偿螗去楗攻
Steps Animation,,,,Steps Animation
Leave empty to use the same name as onnx and put results into models/Unet-trt directory,,,留空则使用与ONNX相同的名称，并将结果放入models/Unet-trt目录中。,
Embeddings editor,Embeddings 编辑器,Embeddings 编辑器,Embeddings 编辑器,Embeddings editor
Sample guidance scale,样本的指导尺度(guidance scale) - 类似基准 CFG scale 的概念,样本的指导尺度(guidance scale) - 类似基准 CFG scale 的概念,样本的指导尺度(guidance scale) - 类似基准 CFG scale 的概念,
Encoder Color Fix,快速编码颜色修复,编码器颜色修复,编码器颜色修复,高速エンコ`ダの色修正を使用
Attention grabber,随机关键词吸引注意力,随机关键词吸引注意力,随机关键词吸引注意力,Attention grabber（プロンプトの後ろの: 1.5などのこと）
Complete documentation is available at https://github.com/adieyal/sd-dynamic-prompts. Please report any issues on GitHub.,,,,完全なドキュメントは https://github.com/adieyal/sd-dynamic-promptsで入手できます。GitHubで}を蟾妞筏皮ださい。
save model,保存模型,,,
yo,,,,yo
Apply and quit,,,应用并退出,
Add image number to grid,,,,Add image number to grid
silu,silu,,,silu
No Preview Found,,,,プレビュ`がつかりませんでした
A prompt for generating classification/regularization images. See the readme for more info.,生成分类/规范化图像用的提示词。详细信息请参阅 readme,生成分类/规范化图像用的提示词。详细信息请参阅 readme,生成分类/规范化图像用的提示词。详细信息请参阅 readme,
auto-sd-paint-ext Guide/Panel,,,,auto-sd-paint-ext ガイド/パネル
Base Ratio,全局提示词权重（每个区域可单独设置，逗号分隔）,,,ベ`スプロンプトの比率
deforum-for-automatic1111-webui,Deforum,Deforum,Deforum,deforum-for-automatic1111-webui
openai,,,,openai
eval,,,,u
for ade20k and,查看 ADE20k协议 类别与ID的映射关系，点击,,”来查看ADE20K协议，点击“,
ControlNet v1.1.234,扩散控制网络(ControlNet),,,
Instance Prompt,,,,インスタンスプロンプト
Description,描述,描述,描述,h明
Concepts List (Overrides instance/class settings below),概念列表（将取代下面实例/类这两项设置）,概念列表（将取代下面实例/类这两项设置）,概念列表（将取代下面实例/类这两项设置）,
antonyms: Replaces the content with one or more antonyms.,,,,反意Z：コンテンツを1つ以上の反意Zで置きQえます。
Filter Images,筛选出的图像,,,画像をフィルタ`
remake dimension,重置维度,,,
(B1) Secondary,,(B1) 第二,(B1) 第二,
Control Mode,控制干涉模式,,干涉模式,
LMSDiscrete,,,,LMSDiscrete
Depth Image I/O,,,,Depth Image I/O
Randomly decide to flip images horizontally.,随机决定要不要水平翻转图像,随机决定要不要水平翻转图像,随机决定要不要水平翻转图像,
ControlNet v1.1.235,扩散控制网络(ControlNet),,,
IN02,,输入层02,输入层02,
Seams fix,,,,Seams fix
Duplicate Skeleton (Z-axis),Z轴方向添加骨架（纵深方向）,,,
Train Imagic Only,,,,画像のみでトレ`ニング
Rotation 3D Z,,,,3D回Z
Depth Warping,,,,深度ワ`ピング
a1111-sd-webui-tagcomplete,Tag自动补全,Tag自动补全,Tag自动补全,a1111-sd-webui-tagcomplete
"Shuffleing tags by ',' when create texts.","创建文本时打乱以 ',' 分割的 tags","创建文本时打乱以 ',' 分割的 tags","创建文本时打乱以 ',' 分割的 tags",
dog-fineart,,,,犬-ファインア`ト
This is a mix from old style to new style. It is not in it's finished state,此插件尚处于新旧交接之际，并非最终版本,此插件尚处于新旧交接之际，并非最终版本,此插件尚处于新旧交接之际，并非最终版本,
Blur edges size ? blur_size,,,,エッジのぼかしサイズ ? blur_size
"How many times to process an image. Each output is used as the input of the next loop. If set to 1, behavior will be as if this script were not used.",,,,画像をI理する回数。各出力は、次のル`プの入力として使用されます。1にO定すると、このスクリプトが使用されていない龊悉韧の幼鳏摔胜辘蓼埂
query,队列相关,查询,查询,クエリ
Ascending,升序,,,N
Color variation,色彩变化,色彩变化,色彩变化,カラ`バリエ`ション
Number of sampling steps to use when generating preview images.,生成预览图像时要使用的采样迭代步数,生成预览图像时要使用的采样迭代步数,生成预览图像时要使用的采样迭代步数,
stability_score_threshold,稳定性评分 阈值(Stability Score Threshold),,,
zu,,,,zu
digipa-low-impact,,,,digipaロ`インパクト
Do not fix prompt schedule for second order samplers.,使用二阶采样器时，不要修正动态提示词调度（依旧保持占有相同采样比例，先写入的提示词会产生更大影响，即使用“[tag1:tag2:0.5]”时，tag1的影响力占绝对优势，使用“[tag1:tag2:0.3]”时，才能使两个tag影响力均衡,,不为二阶采样方法修复提示词作用时间,
Resize the image so that entirety of target resolution is filled with the image. Crop parts that stick out.,调整图像大小，使整个目标分辨率都被图像填充。裁剪多出来的部分,调整图像大小，使整个目标分辨率都被图像填充。裁剪多出来的部分,调整图像大小，使整个目标分辨率都被图像填充。裁剪多出来的部分,象の解像度に画像をフィットさせます。はみ出た部分は切り取られます。
Evaluation method ? _is,,,,u方法 ? _is
Effect,,,,抗
Sample Image Generation,,,,サンプル画像の生成
Optional information about Hypernetwork,,,,Hypernetwork にvするオプション情
tile_resample,二次采样（tile 模型）,,重采样（tile）,
Reload Tags,重新加载标签,,,
Reset recipe text area,,重置配方文本区域,重置配方文本区域,
Slerp interpolation,球面线性插值,球面线性插值,球面线性插值,スラ`プag（ag）
convert,转换,转换,转换,
Image,图像,图像,图像,画像
Train Model,训练模型,训练模型,训练模型,
EXIF keyword search,图片附加信息检索,,EXIF关键字搜索,EXIF キ`ワ`ド仕
R-ESRGAN 4x+,,,R-ESRGAN 4x+（新手写实向首选）,R-ESRGAN 4x+
(O7) Output ckpt Name,,(O7) ckpt 输出名,(O7) ckpt 输出名,
screen,,,,スクリ`ン
Upscaler for img2img,图生图的放大算法,图生图的放大算法,图生图的放大算法,img2imgで使うアップスケ`ラ`
Draw tiles as background (SLOW but save VRAM) ,分块绘制背景（较慢但节省显存）,,,
Batch settings,,批次设定,批次设定,
Calculate training parameters for a non-human subject. Disables prior preservation.,计算训练非人物主体需要的参数。并禁用先验存留(prior preservation),计算训练非人物主体需要的参数。并禁用先验存留(prior preservation),计算训练非人物主体需要的参数。并禁用先验存留(prior preservation),
https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git,,,,https://github.com/camenduru/stable-diffusion-webui-artists-to-study.git
must be positive float,,,,正の小数である必要があります
Face margin,,,边缘保留程度,
https://github.com/toriato/stable-diffusion-webui-daam.git,,,,https://github.com/toriato/stable-diffusion-webui-daam.git
Number of vectors per token,每个词元(token)的向量数,每个词元(token)的向量数,每个词元(token)的向量数,ト`クン挨违佶トル数
"Set the maximum number of words to be used in the [prompt_words] option; ATTENTION: If the words are too long, they may exceed the maximum length of the file path that the system can handle",设置在[prompt_words]选项中要使用的最大字数；注意：如果字数太长，可能会超过系统可处理的文件路径的最大长度,设置在[prompt_words]选项中要使用的最大字数；注意：如果字数太长，可能会超过系统可处理的文件路径的最大长度,设置在[prompt_words]选项中要使用的最大字数；注意：如果字数太长，可能会超过系统可处理的文件路径的最大长度,
Reservation,预约信息,,,
tp_iflytek,,,,tp_iflytek
Face detection confidence,,,检测置信度,
sd-web-ui-kitchen-theme,Kitchen 主题,Kitchen 主题,Kitchen 主题,
ControlNet v1.1.197,扩散控制网络(ControlNet),,,
vary_coeff,,,,vary_coeff
"Negative Prompt, will be appended to your i2i negative prompt",输入区域负面提示词(Negative Prompt),,,
Poor man's outpainting,效果稍差的向外绘制,效果稍差的向外绘制,效果稍差的向外绘制,易アウトペインティング
Configure colors. See https://github.com/DominikDoom/a1111-sd-webui-tagcomplete#colors for info. Must be valid JSON.,颜色设置，必须是有效的JSON格式，详情参见https://github.com/DominikDoom/a1111-sd-webui-tagcomplete#colors,,,
Random number generator source. Changes seeds drastically. Use CPU to produce the same picture across different vidocard vendors.,选择生成随机数的设备（使用CPU时可使同一个设备上的多张不同厂家的显卡生成结果保持一致，但会彻底改变现有随机种子生成的结果，且无法保证不同设备均能得到一致结果）,,随机数产生源，GPU的话可能会因为显卡不同而导致图片不能复现，使用CPU的话可以较高的保证图片复现,
Parseq does,,,,パ`セックは行います
"A value that determines the output of random number generator - if you create an image with same parameters and seed as another image, you'll get the same result",一个固定随机数生成器输出的值 - 以相同参数和随机种子生成的图像会得到相同的结果\n? 将随机种子设置为-1，则每次都会使用一个新的随机数\n?? 重用上一次使用的随机种子，如果想要固定输出结果就会很有用,一个固定随机数生成器输出的值 - 以相同参数和随机种子生成的图像会得到相同的结果\n? 将随机种子设置为-1，则每次都会使用一个新的随机数\n?? 重用上一次使用的随机种子，如果想要固定输出结果就会很有用,一个固定随机数生成器输出的值 - 以相同参数和随机种子生成的图像会得到相同的结果\n? 将随机种子设置为-1，则每次都会使用一个新的随机数\n?? 重用上一次使用的随机种子，如果想要固定输出结果就会很有用,乱数生成器の出力をQ定する。同じパラメ`タ`とシ`ドで画像を生成すると、同じY果が得られます。
Optimizer,,,,オプティマイザ`
Hypernet str.,超网络(Hypernetwork) 强度,超网络(Hypernetwork) 强度,超网络(Hypernetwork) 强度,
multiply,,,,\算
VRAM usage polls per second during generation. Set to 0 to disable.,生成图像时，每秒轮询显存(VRAM)使用情况的次数。设置为 0 以禁用,生成图像时，每秒轮询显存(VRAM)使用情况的次数。设置为 0 以禁用,生成图像时，每秒轮询显存(VRAM)使用情况的次数。设置为 0 以禁用,生成中のVRAM使用率の取得g隔。0にすると取得しない。
Local Latent Upscaler. Target an area to selectively enhance details.,,,,Local Latent Upscaler（ロ`カル?ラテント?アップスケ`ラ`）。I域を指定して、xk的にディテ`ルを{することができます。
openpose,姿态检测（openpose 模型，OpenPose 算法，仅姿态）,OpenPose 姿态检测（OpenPose pose detection）,姿态检测（OpenPose 算法，仅身体）,openpose
tp_google,,,,tp_google
(S9) Inter-Method,,(S9) 插值方法,(S9) 插值方法,
Filter by Selection,手工选择,,,xk欷钎榨％毳骏辚螗挨工
Custom Name (Optional),输出模型文件名（默认与A同名，同目录下会覆盖）,输出模型文件名（留空则与模型A相同，同目录下会覆盖模型A）,输出模型文件名（留空则与模型A相同，同目录下会覆盖模型A）,名前 (任意)
extras,附加功能,附加功能,附加功能,その他
Select a component class or specific component.,选择 组件类 或 特定组件,,,
Use Lora in uc text model encoder,在负面提示词的文本编码器(text encoder)上使用LoRA（不建议开启）,在文字模型编码过程中对反向提示词也开启 LoRA（不建议开启）,在文字模型编码过程中对反向提示词也开启 LoRA（不建议开启）,
Presets,预设,,预设,プリセット
Gradient accumulation steps,,梯度累加步数(Gradient Accumulation Steps),梯度累加步数(Gradient Accumulation Steps),Gradient蓄eステップ
Blend Average,平均混合,平均混合,平均混合,平均して混ぜる
stable-diffusion-webui-embedding-editor,Embedding 编辑器,Embedding 编辑器,Embedding 编辑器,stable-diffusion-webui-embedding-editor
ControlNet v1.1.7,扩散控制网络(ControlNet),,,
Choose Min-max to activate these controls,,,←从小到大的上下限,
Weight decay ? weight_decay,,,,Weight decay ? weight_decay
pix2pix_zero,,,,pix2pix_zero
Jinja2 templates,Jinja2 模板,Jinja2 模板,Jinja2 模板,Jinja2 templates
"On the menubar, go to",,,,メニュ`バ`上の
Alternate Steps,交替迭代,交替迭代,交替迭代,ステップごとに交互に行う
te,,,,te
IN_A_02,,模型A 输入层02,模型A 输入层02,
tp_qqTranSmart,,,,tp_qqTranSmart
Leave empty to use the same name as model and put results into models/Unet-onnx directory,,,留空则使用与原模型相同的名称，并将结果放入models/Unet-onnx目录中。,
Info & Help,,,,情&ヘルプ
"In the file explorer that appears, look for a folder called",,,,表示されるファイルエクスプロ`ラで、呼び出されるフォルダを探します。
Max Caption length (0=unlimited),最大描述长度 (0 为无限制),最大描述长度 (0 为无限制),最大描述长度 (0 为无限制),
Approx NN,,,,近似最近傍(ANN)
Idle,,,,待C中
jumbo,,,,jumbo
Stable Diffusion,Stable Diffusion,,,Stable Diffusion
Stable Diffusion checkpoint,Stable Diffusion 模型(ckpt),Stable Diffusion 模型(ckpt),Stable Diffusion 模型(ckpt),Stable Diffusionのcheckpoint
"Save a copy of embedding to log directory every N steps, 0 to disable",每 N 步将 Embedding 的副本保存到日志目录，0 表示禁用,每 N 步将 Embedding 的副本保存到日志目录，0 表示禁用,每 N 步将 Embedding 的副本保存到日志目录，0 表示禁用,指定したステップ数ごとにEmbeddingのコピ`をログに保存する。0でo炕。
Variable to get ? str,,,,取得する涫 ? str
Upscaler,放大算法,放大算法,放大算法,アップスケ`ラ`
questionable,可疑内容/Questionable（强烈性暗示）,强烈性暗示/可疑内容（Questionable）,强烈性暗示/可疑内容（Questionable）,
(setting entries that appear at the top of page rather than in settings tab),,,（将出现在页面顶部而不是设置选项卡中的设置项）,
Scale Factor,放大倍率,缩放系数,缩放系数,倍率
Choose mode:,选择模式,,选择模式,
Pad Tokens,词元(Tokens)垫齐,词元(Tokens)垫齐,词元(Tokens)垫齐,パッドト`クン
(A4) Primary,,(A4) 主要,(A4) 主要,
Center Crop,中心裁切,中心裁切,中心裁切,
ControlNet - 8,扩散控制网络(ControlNet) - 8,,,
Eta for ancestral samplers,,,先祖采样的Eta,
X Types,X轴类型,,,
Canny high threshold,硬边缘上限阈值（Canny high threshold）,强边缘判断阈值（Canny high threshold）,强边缘判断阈值（Canny high threshold）,
es,,,,es
Far schedule,,,,hいスケジュ`ル
IN08,,输入层08,输入层08,
tensor,张量替换（仅“加权和”可用）,,,
No,否,否,否,No
Merge,合并,合并,合并,マ`ジ
Maximum attention,,,,Attentionの最大
Style 1,模版风格 1,模版风格 1,模版风格 1,
Link to image page,,链接到图片页面,链接到图片页面,
Select a collection,,,,コレクションをxk
Fast Encoder may change colors; Can fix it with more RAM and lower speed.,快速编码可能导致色偏，启用修复将消耗更多内存和时间,快速编码可能会改变颜色，关闭后虽然计算更精确但是消耗巨量的显存和内存,快速编码可能会改变颜色，关闭后虽然计算更精确但是消耗巨量的显存和内存,高速エンコ`ダは色が浃铯肟赡苄预あります。これはメモリをやしたり低速にする事で改善できます。
reallybigname,,,,reallybigname
Options,,,,オプション
no-ema,舍弃ema信息,舍弃ema权重,舍弃ema权重,
Disabled when launched with --hide-ui-dir-config.,启动 --hide-ui-dir-config 时禁用,启动 --hide-ui-dir-config 时禁用,启动 --hide-ui-dir-config 时禁用,
Parseq Manifest (JSON or URL),,,,Parseq マニフェスト (JSON または URL)
Slow start,,,,Slow start
Reload UI,重启 WebUI,重启 WebUI,重启 WebUI,UIの再iみzみ
Prompt word wrap length limit,,,提示词分块长度,
duplicate,重复的,,,}u
Show maximum width or height button,,,,最大幅または高さボタンを表示します
(lets you override the noise schedule for k-diffusion samplers; choosing Automatic disables the three parameters below),,,（允许您覆盖k-diffusion采样器的噪声调度器；选择自动则会禁用下面的三个参数）,
ControlNet v1.1.125,扩散控制网络(ControlNet),,,
Excudes (split by comma),排除项(逗号分隔),排除项(逗号分隔),排除项(逗号分隔),除外 (カンマで分割)
Aesthetic scorer,美学评分器,美学评分器,美学评分器,
Output animation path,,输出动画路径,输出动画路径,
"Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.",,,,Txt2img、img2img、highres-fixを、次元とバッチサイズをやしてOOMまでg行し、デ`タをグラフに出力する。
override,,,,上き
3D Openpose Editor,3D Openpose 编辑器,,,3D Openpose Editor
portrait-c,,,,肖像画-c
schedule,,调度,调度,予s
Batch size,每批数量,每批数量,每批数量,バッチサイズ
Leave blank to save images to the same path.,留空则输出到输入目录下,留空则输出到输入目录下,留空则输出到输入目录下,空冥峭じパスへ画像を保存
Total num of layers (reload required),,,,レイヤ`の数(反映にはUIの再起婴必要)
"If PNG image is larger than 4MB or any dimension is larger than 4000, downscale and save copy as JPG",如果 PNG 图像大于 4MB 或宽高之一大于 4000，则缩小并保存副本为 JPG 图片,如果 PNG 图像大于 4MB 或宽高之一大于 4000，则缩小并保存副本为 JPG 图片,如果 PNG 图像大于 4MB 或宽高之一大于 4000，则缩小并保存副本为 JPG 图片,
Directories,目录,目录,目录,ディレクトリ
"This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.",,此扩展允许你将来自各种 booru 的图帖转换为提示词。它通过从对应的 API 中提取标签(tags)列表来实现。你可以自己复制粘贴你需要的图帖的链接，或者使用内置的搜索功能在不离开 webui 的情况下完成所有操作,此扩展允许你将来自各种 booru 的图帖转换为提示词。它通过从对应的 API 中提取标签(tags)列表来实现。你可以自己复制粘贴你需要的图帖的链接，或者使用内置的搜索功能在不离开 webui 的情况下完成所有操作,このSDC能により、さまざまな画像の投稿を安定した散プロンプトにQできます。 これは API からタグの一Eを引き出すことで行います。 自分で好きな投稿へのリンクをコピ`&ペ`ストすることも、内iの仕C能を使ってSDをxれることなくすべてを行うことも可能です。
Control Model - 6,控制模型-6,,,
invert_mask: Inverts the mask (great in combination with multiple txt2masks),,,,invert_mask: マスク反 (}数の txt2mask とMみ合わせると最m)
"Be sure to check the 'Write prompts to file' checkbox if you don't want to lose the generated prompts. Note, one image is still generated.",不想丢失生成的提示词的话，需确保勾选 “将提示词写入文件”\n注意依然会生成一张图像,不想丢失生成的提示词的话，需确保勾选 “将提示词写入文件”\n注意依然会生成一张图像,不想丢失生成的提示词的话，需确保勾选 “将提示词写入文件”\n注意依然会生成一张图像,生成されたプロンプトを失いたくない龊悉稀⒈丐骸弗抓恁螗抓趣颔榨ˉぅ毪きzむ」チェックボックスをチェックしてください。注意: 1つの画像が生成されたままです。
Body Parameters,身体骨架参数（尺寸调节）,,,
tp_qqFanyi,,,,tp_qqFanyi
"Use following tags to define how filenames for images are chosen: [steps], [cfg], [prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.",,,,"画像のファイル名として、以下のタグを使えます: [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; 空冥摔工毪去钎榨━毳仍O定が使われます。"
Replace underscore in tag with whitespace,,,,タグ中のアンダ`スコアを空白に置きQえる
Smart Preprocess,智能预处理,智能预处理,智能预处理,スマ`トプリプロセス
Colortextsecondary,Colortextsecondary,,,
Use TensorFloat 32,,,,TensorFloat 32を使用する
Image creation progress preview mode,图像生成过程预览的模式,图像生成过程预览的模式,图像生成过程预览的模式,画像の作成M行状rのプレビュ`モ`ド
Use transformers models to generate prompts.,,,,トランスフォ`マ`モデルを使用してプロンプトを生成します。
Move or Delete Files,移动或删除文件,,,ファイルの移婴蓼郡舷鞒
Y grid (Disabled if blank),Y轴内容（留空时自动禁用Y轴）,,,
ms,,,,ms
Upscale by,放大倍率,放大倍率,放大倍率,アップスケ`ル倍率
Append Flavor tags from CLIP,,,,CLIPからフレ`バ`タグを追加
"Also, please set the booru selection here before using select or search.",,另外，在选择或搜索之前，请在这里设置你要用哪个 booru,另外，在选择或搜索之前，请在这里设置你要用哪个 booru,
Lora UNET Learning Rate,,,,LoRA UNET 学率
How many batches of images to create,创建多少批次的图像,创建多少批次的图像,创建多少批次的图像,
Allow other script to control this extension,允许其他脚本对此扩展插件进行控制,允许其他脚本对此扩展插件进行控制,允许其他脚本对此扩展插件进行控制,他のスクリプトにこのC能の操作をS可する
ControlNet v1.1.143,扩散控制网络(ControlNet),,,
[name],,,,[name]
Send to inpaint,>> 局部重绘,>> 局部重绘,>>局部重绘,inpaintに送
model_A,模型A,,,
Enable Jinja2 templates,启用 Jinja2 模板,启用 Jinja2 模板,启用 Jinja2 模板,Jinja2 テンプレ`トを有郡摔工
Cutoff Weight,,,,Cutoff 重み
Author,作者,作者,作者,作成者
mask content ratio,内容蒙版比例（簇被视为前景的所含蒙版阈值）,,,
Add ALL Displayed,添加所有当前显示,,,表示されたすべてを追加
Subject Class,主体类别(Subject Class),主体类别(Subject Class),主体类别(Subject Class),サブジェクトクラス
Apply if any,,,如果适用的的话,
Subject B ? subject_b,,,,Subject B ? subject_b
tp__itranslate,,,,tp__itranslate
Apply changes (Reload UI),应用设置（重启 WebUI）,应用设置（重启 WebUI）,应用设置（重启 WebUI）,
Show Ground,,,,地面を表示
Append Trending tags from CLIP,,,,CLIPからトレンドタグを追加
uz,,,,uz
Result = A,获得与A完全相同的模型,获得与A完全相同的模型,获得与A完全相同的模型,Result = A
"Shuffle tags by ',' when creating prompts.",,"创建提示词时按 ',' 打乱标签(tags)","创建提示词时按 ',' 打乱标签(tags)","プロンプト作成rにタグを ',' 区切りでシャッフルする。"
(or open as text in a new page),,,(或者在新页面打开),
dog-anime,,,,犬のアニメ：
Abysz LAB 0.1.9 Temporal coherence tools,,,,Abysz LAB 0.1.9 rg的な一性ツ`ル
Apply Lora to outputs rather than inputs when possible (experimental),尽可能将 LoRA 模型应用于输出而非输入(实验性选项),尽可能将 LoRA 模型应用于输出而非输入(实验性选项),尽可能将 LoRA 模型应用于输出而非输入(实验性选项),
"If the saved image file size is above the limit, or its either width or height are above the limit, save a downscaled copy as JPG",如果保存的图像文件大小超过限制，或者其宽度或高度超过限制，将其缩小的副本另存为 JPG 格式,如果保存的图像文件大小超过限制，或者其宽度或高度超过限制，将其缩小的副本另存为 JPG 格式,如果保存的图像文件大小超过限制，或者其宽度或高度超过限制，将其缩小的副本另存为 JPG 格式,保存された画像のファイルサイズが上限を超える龊稀または幅と高さのいずれかが上限を超える龊悉稀⒖s小したものをJPGで保存します。
Control Model - 0,控制模型-0,,,
Translation First,翻译在前,翻译在上面,翻译在上面,xk言Zを先に表示
txt2img_hr_scale,高分辨率修复-放大倍率,,,
(O9) Output ckpt Name,,(O9) ckpt 输出名,(O9) ckpt 输出名,
Heatmap image scale,,,,ヒ`トマップ画像のスケ`ル
Fixed size to resize images to,调整图像大小到固定大小,调整图像大小到固定大小,调整图像大小到固定大小,比率を固定したままリサイズ
IN04,,输入层04,输入层04,
Remove Near %,近景排除（%）,近景排除（%）,近景排除（%）,
Send image to tag selection,,>> 标签(Tag)选择,>> 标签(Tag)选择,
pl,,,,pl
Highest possible roll ? _sides,,,,最高の出目 <unk> _sides
Sample Prompts,,,,サンプルプロンプト
Images Browser,图库浏览器,图库浏览器,图库浏览器,
stable-diffusion-webui-tokenizer,词元分析器(tokenizer),词元分析器(tokenizer),词元分析器(tokenizer),stable-diffusion-webui-tokenizer
LoRA model name filter,LoRA 模型名称过滤器,LoRA 模型名称过滤器,LoRA 模型名称过滤器,LoRA モデル名フィルタ
Variable name ? verbatim,,,,涫名 ? verbatim
Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui,,,,AUTOMATIC1111のStable Diffusion webui上で、gelbooru画像のタグを取得するC能
must be enabled,,,,有郡摔工氡匾があります
(in milliseconds),,,（单位：毫秒）,
ControlNet - 9,扩散控制网络(ControlNet) - 9,,,
How many batches of images to create (has no impact on generation performance or VRAM usage),,,,作成する画像のバッチ数 (生成パフォ`マンスやVRAMの使用に影を与えません)
description-based:,,,,h明に基づく：
ControlNet v1.1.113,扩散控制网络(ControlNet),,,
Leave blank to use same filename as original.,,留空以使用与原始文件相同的文件名,留空以使用与原始文件相同的文件名,空白のままの龊稀⒃のファイルと同じファイル名を使用
available,可用值,,,
Sampler,采样方法 (Sampler),采样方法 (Sampler),采样方法 (Sampler),サンプラ`
camelcase,,,,キャメルケ`ス
Your huggingface token to use for cloning files.,用于下载文件的 huggingface 令牌(token),用于下载文件的 huggingface 令牌(token),用于下载文件的 huggingface 令牌(token),
spaceship-weird,,,,宇宙船演算子(weird)
Horizontal,按行分区,,,水平方向
Mask brightness adjust,,,,マスクの明るさ{整
settings for,,,,O定:
Generate Preview,生成预览,生成预览,生成预览,プレビュ`を生成
depth_leres,深度估算（depth 模型，LeReS 算法）,LeReS 深度信息估算（LeReS depth estimation）,深度检测（depth，LeReS 算法）,深度（LeRes）
Subseed strength schedule,,,,サブシ`ド度スケジュ`ル
dog-ukioe,,,,犬の浮世}
Layer4 mask strength,,,,レイヤ`4のマスク不透明度
Select or create a model to begin.,,,,_始するモデルをxkまたは作成する。
Kitchen Theme,,Kitchen 主题,Kitchen 主题,Kitchen Theme
spaceship-cartoon,,,,宇宙船 カ`トゥ`ン
Click to Upload,点击上传,点击上传,点击上传,クリックしてアップロ`ド
Y offset (B),Y 偏移 (B),Y 偏移 (B),Y 偏移 (B),
Number of steps for the warmup in the lr scheduler.,学习率调度器中的预热步数,学习率调度器中的预热步数,学习率调度器中的预热步数,
inpaint sketch,局部重绘(有色蒙版),局部重绘(手涂蒙版),局部重绘(手涂蒙版),inpaintスケッチ
"To do this, open file, search for `prevent_thread_lock` add comma, paste in text, save.","具体操作请打开文件并搜索 ""prevent_thread_lock"" ，在结尾添加逗号，粘贴并保存","具体操作请打开文件并搜索 ""prevent_thread_lock"" ，在结尾添加逗号，粘贴并保存","具体操作请打开文件并搜索 ""prevent_thread_lock"" ，在结尾添加逗号，粘贴并保存",
ControlNet v1.1.214,扩散控制网络(ControlNet),,,
Dreambooth,Dreambooth,,,Dreambooth
Float value from 0 to 1,从 0 到 1 的浮点数数值,从 0 到 1 的浮点数数值,从 0 到 1 的浮点数数值,0 から 1 までの浮有∈点数の
Checkpoint Dropdown,Stable Diffusion 模型(ckpt) 列表,模型(ckpt)列表,模型(ckpt)列表,
Tile overlap for SCUNET upscalers.,,,SCUNET放大时潜变量分块（tile）重叠大小,
Flow method,,,,フロ`メソッド
Checkpoint format,模型格式,模型(ckpt)格式,模型(ckpt)格式,checkpointのファイル形式
Remove background image,移除背景参考图片,移除背景图片,移除背景图片,
OUT_B_06,,模型B 输出层06,模型B 输出层06,
Start steps,起始迭代步数,起始迭代步数,起始迭代步数,ステップを_始
https://github.com/dfaker/SD-latent-mirroring.git,,,,https://github.com/dfaker/SD-latent-mirroring.git
Get List,获取模型列表,获取列表,获取列表,
(Low values = visible seam),,,（这个值小的话图片可能会有接缝）,
Store frames in ram,,,,フレ`ムをRAMに保存
get: Returns the value of a variable.,,,,get: 涫のを返します。
"List of model names (with file extension) or their hashes to use as black/whitelist, separated by commas.",模型黑/白名单列表（用于区分自然语言模型，填入模型哈希值或其文件名（带后缀），逗号分隔）,模型黑/白名单列表（用于区分自然语言模型，填入模型哈希值或其文件名（带后缀），逗号分隔）,模型黑/白名单列表（用于区分自然语言模型，填入模型哈希值或其文件名（带后缀），逗号分隔）,ブラックリストもしくはホワイトリストとして使用するモデル名(子付き)もしくはハッシュのリスト(カンマ区切り)
Seed iter N,,,,Seed iter N
ControlNet v1.1.218,扩散控制网络(ControlNet),,,
"Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.",,,,任意のト`クン(gZ) またはTextual-Inversionの埋めzみを摔贰どの埋めzみが似しているかを{べることができます。Embeddingsの混合、修正、作成は数秒で可能です。
Unload all interrogate models,卸载显存中所有反推模型(使用完毕后请务必卸载，反推模型将占用大量宝贵显存),卸载显存中所有反推模型(使用完毕后请务必卸载，反推模型将占用大量宝贵显存),卸载显存中所有反推模型(使用完毕后请务必卸载，反推模型将占用大量宝贵显存),すべてのインタロゲ`トモデルをアンロ`ドする
Update Mask,,,刷新蒙版,
left-to-right,,,,左から右へ
Duration,持续时间,持续时间,持续时间,
DIS Medium,,,,DIS 中
special,,,,特e
Scan Models for Civitai,扫描模型在 Civitai 上的信息,扫描模型,扫描模型,
Mode to add the extra tags to the main tag list,将额外标记添加到主标记列表的模式,将额外标记添加到主标记列表的模式,将额外标记添加到主标记列表的模式,メインタグリストに追加するモ`ド
Allow the default Euler a Sampling method. (Does not produce good results),允许使用默认的 Eular a 采样方法. (通常不会出漂亮的结果),允许使用默认的 Eular a 采样方法. (通常不会出漂亮的结果),允许使用默认的 Eular a 采样方法. (通常不会出漂亮的结果),デフォルトの Euler a サンプルアルゴリズムをS可します。(良いY果にはなりません)
Path to directory with input images,带有输入图像的目录路径,带有输入图像的目录路径,带有输入图像的目录路径,入力画像のあるディレクトリへのパス
km,,,,km
https://discord.com/api/webhooks/XXX/XXXX,,,,https://discord.com/api/webhooks/XXX/XXXX
Japanese localization,,,,日本Z翻U
* check your CLI for outputs,,,,* CLIの出力を_Jしてください
Upscale V1,,,,上位スケ`ル V1
ky,,,,ky
Import Model from Huggingface Hub,自 Huggingface Hub 载入模型,自 Huggingface Hub 载入模型,自 Huggingface Hub 载入模型,
Directory for temporary images; leave empty for default,临时图像目录，默认为空,临时图像目录，默认为空,临时图像目录，默认为空,一r的なイメ`ジのためのディレクトリ、デフォルトでは空
Minimum score,,,最小分数,
Leave blank to use base model VAE.,留空以使用基底模型的 VAE,留空以使用基底模型的 VAE,留空以使用基底模型的 VAE,ベ`スモデルVAEを使用する龊悉峡瞻驻韦蓼蓼摔筏皮ださい。
mocha,mocha/摩卡（深色-暗）,mocha/摩卡（深色-暗）,mocha/摩卡（深色-暗）,
(select Disco output format).,,,,(Disco出力フォ`マットをxk)。
"Save an image to log directory every N steps, 0 to disable",每 N 步保存一张图像到日志目录，0 表示禁用,每 N 步保存一张图像到日志目录，0 表示禁用,每 N 步保存一张图像到日志目录，0 表示禁用,指定したステップ数ごとに画像を生成し、ログに保存する。0でo炕。
Load Params,载入参数,载入参数,载入参数,
Expand Mask,拓展蒙版,,外扩蒙版,
EMA (positive),EMA (正),EMA (正),EMA (正),EMA（ポジティブ）
Append comma on tag autocompletion,自动添加逗号,自动添加逗号,自动添加逗号,タグの自友a完rにカンマを追加
ControlNet Unit 3,控制单元 3,,ControlNet单元3,
hires_steps,,,,高解像度ステップ数
Upscale Ratio,放大比例,放大比例,放大比例,
Crop and Resize,剪裁引导图像,,裁剪缩放,
Make LoRA (alpah * A - beta * B),从ckpt差值提取LoRA（A×α - B×β）,,,
ControlNet v1.1.110,扩散控制网络(ControlNet),,,
Images to use for keyframe guidance,,,,キ`フレ`ムガイダンスに使用する画像
"Can be empty, indicating no translation",可以留空以表示不翻译,,,
Diffusion Defender,,,,Diffusion Defender
point1 y,,,,点1_k
Stable Horde Client,,,,Stable Horde Client
directory.,目录,目录,目录,
Layer1 mask blur,,,,Layer1 マスクのぼかし
Black outfill,填黑,填黑,填黑,\いTりつぶし
Merge Block Weighted,模型合并(分层加权),模型合并(分块加权),模型合并(分块加权),Merge Block Weighted
OUT00,,输出层00,输出层00,
"Prompt, will be appended to your i2i prompt",输入区域提示词(Prompt),,,
Functions,,,,C能
{{1-$$and$$__adjective__}},{{1-3$$and$$__adjective__}},{{1-3$$and$$__adjective__}},{{1-3$$and$$__adjective__}},{{1-$$and$$__adjective__}}
Save original image,,,保存原图,
"If you liked this extension, please",,,,このC能を荬巳毪盲皮い郡坤堡龊悉稀
Noise type,,,,ノイズのN
https://github.com/ThereforeGames/unprompted.git,,,,https://github.com/ThereforeGames/unprompted.git
ControlNet v1.1.298,扩散控制网络(ControlNet),,,
Don't use LoRA in uc if there're no subprompts,无 子提示词(sub prompt) 时不将 LoRA 应用于负面提示词,,,
Fuse Strength,,,,Fuse Strength
Entire Caption,整个图片注释,,,全体のキャプション
Use depth warping,,,,深度ワ`ピングを使用する
Example Function,,,,v数例
Hide extensions with tags,隐藏含有以下标签的扩展,隐藏含有以下标签的扩展,隐藏含有以下标签的扩展,タグでC能をLす
Apply inside mask only,,,只重建面部本身（否则会重建包含面部的正方形）,
Colorfillquaternary,Colorfillquaternary,,,
Interrogate: maximum description length,最大描述长度,最大描述长度,最大描述长度,インタロゲ`ト: h明の最大L
dog-digipa-med-impact,,,,犬-digipa中インパクト
Colorprimarybghover,Colorprimarybghover,,,
Reset Camera,重置镜头,重置镜头,重置镜头,
Onnx model filename,,,Onnx模型名称,
Show HeatMap,,,,ヒ`トマップを表示
ControlNet v1.1.251,扩散控制网络(ControlNet),,,
Sample Batch Size,,,,サンプルのバッチサイズ
Sample steps,样本迭代步数,样本迭代步数,样本迭代步数,
mk,,,,mk
ha,,,,ha
beta,β 值,,,
Checkpoint,,,,Checkpoint
Cutoff Enabled,,,,Cutoff 有炕
Batching,,,,バッチI理
Colortextquaternary,Colortextquaternary,,,
filter out those tags from deepbooru output (separated by comma),从deepdanbooru的标签库中过滤掉以下标签，用逗号分隔,从deepdanbooru的标签库中过滤掉以下标签，用逗号分隔,从deepdanbooru的标签库中过滤掉以下标签，用逗号分隔,deepbooruの出力からこれらのタグを除外する(カンマで区切る)
The number of prompts to generate per batch. Increasing this can speed up prompt generation at the expense of slightly increased VRAM usage.,,,,バッチごとに生成するプロンプトの数。これをやすと、VRAMの使用量がわずかに加する代わりに、プロンプトの生成が高速化されます。
Search Text,检索文本,,,テキストを仕
Mask contrast adjust,,,,マスクのコントラスト{整
Video to extract frames from:,要从中提取帧的视频：,要从中提取帧的视频：,要从中提取帧的视频：,フレ`ムを抽出するビデオを指定する：
Check Progress,,,,M行状rを_J
https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension.git,,,,https://github.com/aria1th/Hypernetwork-MonkeyPatch-Extension.git
Grid row count; use -1 for autodetect and 0 for it to be same as batch size,宫格图行数； 使用 -1 进行自动检测，使用 0 使其与每批数量相同,宫格图行数； 使用 -1 进行自动检测，使用 0 使其与每批数量相同,宫格图行数； 使用 -1 进行自动检测，使用 0 使其与每批数量相同,グリッドの列数; -1で自釉O定、0でバッチ生成回数と同じにする
Replaces NSFW images with black.,,将含有成人内容的图像以纯黑图替换,将含有成人内容的图像以纯黑图替换,NSFW画像を\に置きQえます。
"restricts decay value, but does not restrict gamma rate decay",,,,p衰を制限しますが、ガンマレ`トのp衰は制限しません
X offset (B),X 偏移 (B),X 偏移 (B),X 偏移 (B),
Path to JSON file with concepts to train.,用于训练概念的 JSON 文件路径,用于训练概念的 JSON 文件路径,用于训练概念的 JSON 文件路径,トレ`ニングする概念が含まれるJSONファイルへのパス。
img2img_cfg_scale,提示词相关性(CFG Scale),,,
Model Preview XD,,,,モデルプレビュ`
Ultimate SD upscale,,,,最高SDアップスケ`ル
"Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.",,,,UI内の要素の外Qと配置をカスタマイズするために、custom.cssファイルを迅速にxkしてm用するためのC能。
Search for Loras,检索 LoRA,搜索 LoRA 模型,搜索 LoRA 模型,LoRAを仕
ControlNet v1.1.134,扩散控制网络(ControlNet),,,
Deforum extension for auto1111 ― version 2.2b,,,,Auto1111用のDeforumC能 - バ`ジョン2.2b
Only show alias,仅显示别称,仅显示别称,仅显示别称,エイリアスのみ表示
The new dynamic algorithm will handle these parameters. Activate them only for manual control.,,,,The new dynamic algorithm will handle these parameters. Activate them only for manual control.
Video drop last frame,丢弃视频最后一帧,丢弃视频最后一帧,丢弃视频最后一帧,
Need help?,,,,ヘルプ
Memory optimization,显存优化选项,显存优化选项,显存优化选项,
Class Token + Description,类的词元(Token) + 描述,类的词元(Token) + 描述,类的词元(Token) + 描述,
Stretch image,拉伸图像,拉伸图像,拉伸图像,画像を湫韦筏大する
Tokens,词元(Tokens),词元(Tokens),词元(Tokens),ト`クン
discard,,,,破する
Jinja2 documentation.,Jinja2 文档,Jinja2 文档,Jinja2 文档,Jinja2 ドキュメント
txt2img history,文生图历史记录,文生图历史记录,文生图历史记录,
Save DepthMap,,,,深度マップを保存
Set this to 2 to increase speed?,将此设置为 2 以提高速度？,将此设置为 2 以提高速度？,将此设置为 2 以提高速度？,
(M10) Multiplier,,(M10) 倍率,(M10) 倍率,
Script Enabled,,启用脚本,启用脚本,
Interrogate: num_beams for BLIP,BLIP 的 num_beams,BLIP 的 num_beams,BLIP 的 num_beams,|：BLIPのnum_beamsについて
repeat: Returns the content an arbitrary number of times.,,,,repeat: コンテンツを任意の回数Rり返し返します。
Resources,,,,Y料
Apply selected styles to current prompt,将已选择的模板风格写入当前的提示词(prompt),将已选择的模板风格写入当前的提示词(prompt),将已选择的模板风格写入当前的提示词(prompt),F在のプロンプトにxkしたスタイルをm用
has metadata,有元数据,有元数据,有元数据,メタデ`タがある
split,分居两端,,,
Keyframes: coherence (color coherence & cadence),,,,キ`フレ`ム： コヒ`レンス(色のコヒ`レンスとケイデンス)
Outpainting direction,向外绘制的方向,向外绘制的方向,向外绘制的方向,アウトペインティングを行う方向
"Growth factor limiting, use value like 1.02 or leave it as -1",,,,"Growth factor limiting, 1.02のようなを使用するか、 -1のままにしてください。"
ControlNet v1.1.297,扩散控制网络(ControlNet),,,
Control Model - 8,控制模型-8,,,
ControlNet v1.1.103,扩散控制网络(ControlNet),,,
ControlNet v1.1.123,扩散控制网络(ControlNet),,,
MLDanbooru Tagger,MLDanbooru Tag反推,,,
(O5) Output ckpt Name,,(O5) ckpt 输出名,(O5) ckpt 输出名,
Height,高度,高度,高度,高さ
Show command for conversion,,,显示转换命令,
extension to be installed.,,,,C能のインスト`ル
Video Loopback,,,,Video Loopback
ControlNet v1.1.206,扩散控制网络(ControlNet),,,
official Deforum Discord,,,,公式Deforum Discord
UniPC variant,UniPC 采样器变体,UniPC 变体 (bh1适合在无提示词且步数小于10情况下使用；vary_coeff同样在10步内效果最好；其余情况全部使用bh2),UniPC 变体 (bh1适合在无提示词且步数小于10情况下使用；vary_coeff同样在10步内效果最好；其余情况全部使用bh2),UniPC ソルバ`のN
Beginners guide,,,,ビギナ`ズガイド
Model Version,模型版本,模型版本,模型版本,
(S1) Inter-Method,,(S1) 插值方法,(S1) 插值方法,
Cutoff Padding,,,,Cutoff め替えるト`クン
"Activation keywords, comma-separated",该模型的触发词，逗号分隔,该模型的触发词，逗号分隔,该模型的触发词，逗号分隔,カンマで区切られた呼び出しキ`ワ`ド
Preview segmentation image,预览分割结果,,预览分割结果,
Max Grad Norms,最大梯度范数(Max Grad Norms),最大梯度范数(Max Grad Norms),最大梯度范数(Max Grad Norms),
"The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).",,,,\は基本的にそれがI理しないものです(それは婴をS持するためにそれを介してさせます)。 白色はフレ`ムagの中で安定しようとしています ここでは、手婴违攻喋`ズな幼(高度なセクション) をテストすることもできます。
Area 3 Weight,蒙版 3 的权重(Weight),,,
dog-cartoon,,,,犬のカ`トゥ`ン
Sample CFG Scale,样本提示词相关性(CFG Scale),样本提示词相关性(CFG Scale),样本提示词相关性(CFG Scale),サンプルCFGスケ`ル
Get sub directories,获取子目录,,获取子目录,サブディレクトリを取得
Extract nth frame,,,,N番目のフレ`ムを抽出
dithering,,,,ディザリング
Depth Library,深度图编辑器,深度图编辑器,深度图编辑器,Depth ライブラリ
Auto Translate,自动翻译,,,Auto Translate
Connection errored out.,连接出错,连接出错,连接出错,
OUT02,,输出层02,输出层02,
to txt2img,,,,文章から画像に
https://github.com/hyd998877/stable-diffusion-webui-auto-translate-language,,,,https://github.com/hyd998877/stable-diffusion-webui-auto-translate-language
Match Frame 0 RGB,,匹配帧 0 RGB,匹配帧 0 RGB,フレ`ム0のRGBに一致する
"Save current prompts as a style. If you add the token {prompt} to the text, the style use that as placeholder for your prompt when you use the style in the future.",将当前的提示词保存为模版风格。如果你在文本中添加{prompt}标记，那么将来你使用该模版风格时，你现有的提示词会替换模版风格中的{prompt},将当前的提示词保存为模版风格。如果你在文本中添加{prompt}标记，那么将来你使用该模版风格时，你现有的提示词会替换模版风格中的{prompt},将当前的提示词保存为模版风格。如果你在文本中添加{prompt}标记，那么将来你使用该模版风格时，你现有的提示词会替换模版风格中的{prompt},
License: MIT,,许可: MIT,许可: MIT,
Aesthetic weight,美术风格权重,美术风格权重,美术风格权重,Aesthetic ウェイト
Gradient Accumulation Steps,梯度累加步数(Gradient Accumulation Steps),梯度累加步数(Gradient Accumulation Steps),梯度累加步数(Gradient Accumulation Steps),勾配蓄eステップ
"Show '?' next to tags, linking to its Danbooru or e621 wiki page (Warning: This is an external site and very likely contains NSFW examples!)",在tag一侧显示‘?’用于链接到其danbooru或e621 wiki页面（警告：页面含有色情内容，谨慎浏览，需要科学上网）,在tag一侧显示‘?’用于链接到其danbooru或e621 wiki页面（警告：页面含有成人内容，谨慎浏览，需要科学上网）,在tag一侧显示‘?’用于链接到其danbooru或e621 wiki页面（警告：页面含有成人内容，谨慎浏览，需要科学上网）,タグの横に「?」を表示し、Danbooruまたはe621のwikiペ`ジにリンクします (警告:これは外部サイトで、NSFWの例が含まれている可能性が非常に高いです)
Report a bug,,,,バグを蟾妞工
Half Model,半模型,半模型,半模型,ハ`フモデル
Allow NSFW,,允许成人内容,允许成人内容,
(A5) Primary,,(A5) 主要,(A5) 主要,
Prompt for tokenization,给词元化准备的提示词,给词元化准备的提示词,给词元化准备的提示词,プロンプトのト`クン化
json,,,,json
fill it with latent space zeroes,于潜空间填零,于潜空间填零,于潜空间填零,潜在空g(latent space)における0で埋める
path/to/classify,,,,path/to/classify
wd14-vit,,,,wd14-vit
Checkpoints,Stable Diffusion 模型(ckpt),模型(ckpt),模型(ckpt),Checkpoints
ControlNet-4,控制网络-4,,,
autocorrect: Attempts to correct the spelling of content.,,,,autocorrect: コンテンツのスペルを修正しようとします。
Limit Jinja prompts: Limit the number of prompts to batch_count * batch_size. The default is to generate batch_count * barch_size * number of prompts generated by Jinja,,,,Jinjaのプロンプト数を制限する: プロンプトの数を batch_count * batch_size に制限します。デフォルトは batch_count * barch_size * Jinjaによって生成されるプロンプトの数 です。
Auto-sized crop,,,自动裁剪,自鹰单ぅ氦乔肖耆・
fake_scribble,伪涂鸦处理（fake_scribble）,伪涂鸦（fake_scribble）,伪涂鸦（fake_scribble）,fake_scribble
ScuNET,,,,ScuNET
tt,,,,tt
Image for Segment Anything,需要使用 Segment Anything 处理的图像,,上传要分割的图,
ControlNet v1.1.299,扩散控制网络(ControlNet),,,
scribble_xdog,涂鸦处理（scribble 模型，xDoG 算法）,,涂鸦处理（scribble，xDoG 算法）,
ControlNet v1.1.157,扩散控制网络(ControlNet),,,
Average image color,平均图像颜色,平均图像颜色,平均图像颜色,画像の平均色
Add Background image,添加背景图片,添加背景图片,添加背景图片,背景画像を追加する
sd-webui-depth-lib,深度图编辑器插件,深度图编辑器插件,深度图编辑器插件,sd-webui-depth-lib
Maximum number ? _max,,,,最大 ? _max
Unfreeze Model,,,,モデルを鼋Y解除
https://github.com/jexom/sd-webui-depth-lib.git,,,,https://github.com/jexom/sd-webui-depth-lib.git
Max Res,,,,最大解像度
ControlNet Unit 0,控制单元 0,,ControlNet单元0,
Inner Fit (Scale to Fit),嵌入适配（填充画布空白区域）,,,
Composable LoRA,,可自组 LoRA,可自组 LoRA,Composable LoRA
DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M,,,,DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M
depth_midas,深度估算（depth 模型，MiDaS 算法）,,深度检测（depth，MiDaS 算法）,
Close the video,,关掉视频,关掉视频,踊を]じる
"Draw a mask over an image, and the script will regenerate the masked area with content according to prompt",在图像上画一个蒙版，脚本会根据提示重新生成蒙版区域的内容,在图像上画一个蒙版，脚本会根据提示重新生成蒙版区域的内容,在图像上画一个蒙版，脚本会根据提示重新生成蒙版区域的内容,
Area 9 Weight,蒙版 9 的权重(Weight),,,
Model,模型,模型,模型,モデル
Negative mask smoothing radius in pixels ? neg_smoothing,,,,ピクセルg位のネガティブマスク平滑化半径 ? neg_smoothing
Pixel size,像素块大小,像素块大小,像素块大小,ピクセルサイズ
Use this when scanning can not find a local model on civitai,使用扫描无法获取模型信息时，可手动通过网址将信息强制写入，适用于下载后自行压缩或经历了其他操作的模型,扫描不到本地模型时可以使用这个功能。,扫描不到本地模型时可以使用这个功能。,
Canny low threshold ? low_threshold,,,,Cannyの低 ? low_threshold
Civitai URL,Civitai网址,Civitai 网址,Civitai 网址,
laion2b_s32b_b79k,,,,laion2b_s32b_b79k
Drop Video Here,拖拽视频到此处,拖拽视频到此处,拖拽视频到此处,
frappe,frappe/冰沙（深色-亮）,frappe/冰沙（深色-亮）,frappe/冰沙（深色-亮）,
Reloading...,正在重新加载...,正在重新加载...,正在重新加载...,
Delete Selected Skeleton (D key),删除选中的骨架（按D键）,,,
(A8) Primary,,(A8) 主要,(A8) 主要,
RGB to BGR,RGB格式法线贴图转BGR,RGB格式法线贴图转BGR,RGB格式法线贴图转BGR,RGBからBGRにQ
Will upscale the image to twice the dimensions; use width and height sliders to set tile size,将图像放大到两倍尺寸； 使用宽度和高度滑块设置图块尺寸(tile size),将图像放大到两倍尺寸； 使用宽度和高度滑块设置图块尺寸(tile size),将图像放大到两倍尺寸； 使用宽度和高度滑块设置图块尺寸(tile size),
Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file.,将 Optimizer 状态保存为单独的 *.optim 文件，嵌入式(Embedding)或 超网络(Hypernetwork) 的训练可以使用匹配的 optim 文件来恢复,将优化器状态保存为单独的 *.optim 文件 (可以使用匹配的optim文件来恢复中断的embadding或HN模型的训练),将优化器状态保存为单独的 *.optim 文件 (可以使用匹配的optim文件来恢复中断的embadding或HN模型的训练),Optimizerの状Bをeの*.optimファイルとして保存します。 埋めzみまたはHNのトレ`ニングは、一致するoptimファイルで再_できます。
Civitai Helper,C站助手,C站助手,C站助手,
tp__niutrans,,,,tp__niutrans
Add soundtrack,,,,サウンドトラックを追加
username,用户名,,,
stable-diffusion-webui-dataset-tag-editor,数据集 Tag 编辑器,数据集标签编辑器,数据集标签编辑器,stable-diffusion-webui-dataset-tag-editor
Use Text Escape,转义特殊符号（如“()”、“<>”等具有特殊含义的符号）,,,
(separate by comma),,,（用逗号分隔）,
LDSR,LDSR,,,LDSR
Progressbar and preview update period,,,进度条和预览更新的周期,
New Canvas Width,,,画布宽度,
Deterministic,,,,Q定的
Extensions,扩展,扩展,扩展,C能
ControlNet v1.1.241,扩散控制网络(ControlNet),,,
SD-latent-mirroring,镜像潜空间图像,镜像潜变量,镜像潜变量,SD-latent-mirroring
Image height,图像高度,图像高度,图像高度,画像の高さ：
favorites,收藏夹(已保存),收藏夹(已保存),收藏夹(已保存),
Resolution of the detection map ? detect_resolution,,,,食謦蕙氓驻谓庀穸 →食鼋庀穸
Linear Down,线性递减(Linear Down),,,
Performance Wizard (WIP),,,,パフォ`マンスウィザ`ド (WIP)
"Separate a list of words with commas, and the script will make a variation of prompt with those words for their every possible order",以逗号分割的单词列表，脚本会排列出这些单词的所有排列方式，并加入提示词各生成一次,以逗号分割的单词列表，脚本会排列出这些单词的所有排列方式，并加入提示词各生成一次,以逗号分割的单词列表，脚本会排列出这些单词的所有排列方式，并加入提示词各生成一次,
Colorerrorbghover,Colorerrorbghover,,,
"If this option is enabled, watermark will not be added to created images. Warning: if you do not add watermark, you may be behaving in an unethical manner.",如果启用此选项，水印将不会添加到生成出来的图像中。警告：如果你不添加水印，你的行为可能是不符合专业操守的,如果启用此选项，水印将不会添加到生成出来的图像中。警告：如果你不添加水印，你的行为可能是不符合专业操守的,如果启用此选项，水印将不会添加到生成出来的图像中。警告：如果你不添加水印，你的行为可能是不符合专业操守的,このオプションを有郡摔工毪取⒆鞒嗓丹欷炕像にウォ`タ`マ`クが追加されなくなります。警告:ウォ`タ`マ`クを追加しない龊稀⒎理的な行婴趣撙胜丹欷龊悉あります。
Face restoration model,面部修复模型,面部修复模型,面部修复的算法（模型）,
Send to Effect,,,,エフェクトに送
file2mask: Modify or replace your img2img mask with arbitrary files.,,,,file2mask: img2imgマスクを任意のファイルで修正または置きQえます。
Dataset Load Settings,数据集加载设置,,,デ`タセットのiみzみO定
Latent (bicubic),Latent（双立方插值）,潜变量 (bicubic),潜变量 (bicubic),Latent (バイキュ`ビックag)
Blend:,,,,Blend:
UI tab order,,,UI页签的顺序,
spaceship-fineart,,,,宇宙船演算子(fineart)
dog-digipa-low-impact,,,,犬-digipaロ`インパクト
Width,宽度,宽度,宽度,幅
ControlNet v1.1.247,扩散控制网络(ControlNet),,,
Blur,,,,ぼかし
greatest area,,,,最大のエリア
Half Cosine Up,半区间余弦递增(Half Cosine Up),,,
Tiling,分块绘图(Tiling),平铺/分块 (Tiling),平铺/分块 (Tiling),タイリング用の画像を生成
----deprecated----,----以下内容在webUI新版本已移除----,----以下内容在webUI新版本已移除----,----以下内容在webUI新版本已移除----,
Note,笔记,,,
[ControlNet] Guidance End,,,,[ControlNet] ガイダンスK了
Uses the filename.txt file's content as the image labels instead of the instance prompt,使用 文件名.txt 文件的内容作为图像的提示词而非实例提示词,使用 文件名.txt 文件的内容作为图像的提示词而非实例提示词,使用 文件名.txt 文件的内容作为图像的提示词而非实例提示词,
tp_deepl,,,,tp_deepl
Resize to,,,调整大小为,
LLuL Multiply,,,,LLuL\算
Model 4,模型 4,模型 4,模型 4,モデル 4
Image border outfill method:,图像边缘的填充方法：,图像边缘的填充方法：,图像边缘的填充方法：,画像境界のアウトフィル法
Token Merging,词元合并加速(Token Merging),,,
- Canvas Size,--画布大小--,--画布大小--,--画布大小--,
Filter Logic,筛选逻辑,,,フィルタ`ル`ル
Caption of Selected Image,选中图像的注释,,,xkした画像のキャプション
Existing Caption Action,对已有的描述文本的行为,对已有的描述文本的行为,对已有的描述文本的行为,既存のキャプションのアクション
Layer3 mask blur,,,,Layer3 マスクのぼかし
ControlNet-9,控制网络-9,,,
Autocomplete options,Tag自动补全选项,Tag自动补全选项,Tag自动补全选项,
Text input,文本输入,文本输入,文本输入,文字列入力
Auto detect size from img2img,,,自动检测尺寸,
Output Size,,,,出力サイズ
String to include after the filename ? post,,,,ファイル名の後に含める文字列 ? post
img2img_sampling,采样方法(Sampler),,,
OUT_A_08,,模型A 输出层08,模型A 输出层08,
Load Preset,读取预设,,载入预设,
Extras,附加功能,附加功能,附加功能,その他
do,,,,do
You may configurate the following items and generate masked image for all images under a directory. This mode is designed for generating LoRA/LyCORIS training set.,您可以配置以下项目，并为目录下的所有图像生成蒙版图像。该模式是为生成 LoRA/LyCORIS 训练集而设计的。,,这里可以为一个目录下的所有图片生成蒙版，这个功能是为了输出用于LoRA/LyCORIS训练的素材,
Draw Legends,输出坐标轴内容,输出坐标轴名字,输出坐标轴名字,
ControlNet v1.1.183,扩散控制网络(ControlNet),,,
controlnet: A neural network structure to control diffusion models by adding extra conditions. Check manual for setup info.,,,,controlnet: 追加の条件を追加して散モデルを制御するニュ`ラルネットワ`ク造です。
Full,,,,フル
Resize height to,将高度调整到,将高度调整到,将高度调整到,サイズ涓後の高さ
(S4) Inter-Method,,(S4) 插值方法,(S4) 插值方法,
kn,,,,kn
Randomize Highres. Height,随机化 高分辨率修复的第一遍的高度,随机化 高清修复的第一遍的高度,随机化 高清修复的第一遍的高度,
Perspective,,,,h近a正
Generation mode,生成方式（需要为 LoRA 限定区域时请使用 Latent）,,,生成モ`ド
Sample Negative Prompt,,,,サンプルネガティブプロンプト
Ignore,,,忽略,
Cutoff,色彩分离(Cutoff),,,Cutoff
antonyms,,,,xZ
Training Prompts,,,,トレ`ニングに使用したプロンプト
The current workflow is [text prompt]->[object detection]->[segmentation]. Semantic segmentation support is coming soon!,当前的工作流程是[文本提示]->[对象检测]->[分割]，语义分割功能即将推出,,,
Prev Page,上一页,上一页,上一页,前のペ`ジ
Dataset Images,数据集图片,,,デ`タセット画像
Sort caption on save,保存时对注释信息进行排序,,,保存rにキャプションをKべ替え
Tile,,,分块,
Hybrid Video Compositing in 2D/3D Mode,,,,2D/3Dモ`ドでハイブリッドビデオを作成する
Mask fill,,,,マスクのTりつぶし
Dropout tags when create texts,创建文本时随机丢弃一些 tags,创建文本时随机丢弃一些 tags,创建文本时随机丢弃一些 tags,
Limit the maximum number of prompts generated. 0 (default) will generate all images. Useful to prevent an unexpected combinatorial explosion.,,,,生成されるプロンプトの最大数を制限します。0 (デフォルト) はすべての画像を生成します。予期しないMみ合わせによる爆kを防ぐのに便利です。
mbw alpha,分层设置 α（每行为一组 α 值）,,,
Enable sampler scheduling,,,,サンプラ`のスケジュ`リングを有郡摔工
Extract Frames,提取帧,提取帧,提取帧,フレ`ムの抽出
LLuL Layers,,,,LLuLレイヤ`
Del,删除,删除,删除,
Detect from Image,从图片识别,,从图像中删除,
Add Background Image,添加背景图片,,添加背景图片,
Eta noise seed delta,Eta 噪声种子偏移(ENSD - Eta noise seed delta，建议值31337),Eta 噪声种子偏移(ENSD - Eta noise seed delta，建议值31337),Eta 噪声种子偏移(ENSD - Eta noise seed delta，建议值31337),Eta noise seed delta
Keyframes,,关键帧,关键帧,キ`フレ`ム
Delete Bar,删除图片控件,,,
Pretrained VAE Name or Path,预训练的 VAE 名字或者路径,预训练的 VAE 名字或者路径,预训练的 VAE 名字或者路径,事前gみのVAE名またはパス
Create inspiration images,,,,インスピレ`ション画像の作成
batch_count,,,,バッチ数
Number of rows on the page,每页行数,每页行数,每页行数,ペ`ジ上の行数
Escape brackets,转义括号(防止误识别为权重信息，推荐勾选),转义括号(防止误识别为权重信息，推荐勾选),转义括号(防止误识别为权重信息，推荐勾选),括弧をエスケ`プする
DEISMultistep,,,,DEISMultistep
Create a text file next to every image with generation parameters.,保存图像时，在每个图像旁边创建一个文本文件储存生成参数（开启前一个选项后不建议开启）,保存图像时，在每个图像旁边创建一个文本文件储存生成参数（开启前一个选项后不建议开启）,保存图像时，在每个图像旁边创建一个文本文件储存生成参数（开启前一个选项后不建议开启）,保存する画像とともに生成パラメ`タをテキストファイルで保存する
Enter the,,,,入力
[name].[output_extension],,,,[name].[output_extension]
DPMSolverSinglestep,,,,DPMSolverSinglestep
not save grid,不保存宫格图,,,
save_settings,,储存设定,储存设定,O定を保存
Request browser notifications,请求浏览器通知（生成完成时在屏幕右下角显示通知）,请求浏览器通知（生成完成时在屏幕右下角显示通知）,请求浏览器通知（生成完成时在屏幕右下角显示通知）,ブラウザに通知のS可を要求
Place options in main UI into an accordion,,,将主界面的选项折叠,
has user metadata,,,,ユ`ザ`メタデ`タがある
Make K-diffusion samplers produce same images in a batch as when making a single image,使 K-diffusion 采样器 批量生成与生成单个图像时，产出相同的图像,使 K-diffusion 采样器 批量生成与生成单个图像时，产出相同的图像,使 K-diffusion 采样器 批量生成与生成单个图像时，产出相同的图像,K-diffusionサンプラ`によるバッチ生成rに、g一画像生成rと同じ画像を生成する
MLSD,,,线段,
Face Restore Model,面部修复模型,面部修复模型,面部修复模型,驮モデル
tp_alibaba,,,,tp_alibaba
anime,,,,アニメ
SD Plugin,,,,SDプラグイン
unzip the file to,,,,ファイルの解鱿
Show console debug,在控制台显示调试信息,在控制台显示调试信息,在控制台显示调试信息,
Enable Control,启用,,启用控制,
ControlNet v1.1.274,扩散控制网络(ControlNet),,,
IN_A_03,,模型A 输入层03,模型A 输入层03,
id,,,,id
3D Fov settings:,,3D 视野设置:,3D 视野设置:,
*Interpolate uploaded video*,,,,*アップロ`ドされた踊をagする*
[wiki],[wiki文档],[wiki文档],[wiki文档],[wiki]
wd14-vit-v2-git,,,,wd14-vit-v2-git
Send seed when sending prompt or image to other interface,将提示词或者图像发送到 >> 其他界面时，把随机种子也传送过去（建议开启）,将提示词或者图像发送到 >> 其他界面时，把随机种子也传送过去（建议开启）,将提示词或者图像发送到 >> 其他界面时，把随机种子也传送过去（建议开启）,他のインタ`フェ`スにプロンプトや画像を送するHにシ`ドも送信する
save metadata,保存元数据,,,
Maximum height,,,最大高度,
Video to Interpolate,,,,ビデオをagする
hed,软边缘检测（HED 算法）,"HED 边缘检测（soft HED edge detection, 保留细节）","HED 边缘检测（soft HED edge detection, 保留细节）",hed
ControlNet v1.1.294,扩散控制网络(ControlNet),,,
Extracted Frame Set,提取好的帧,提取好的帧,提取好的帧,抽出フレ`ムセット
Move VAE and CLIP to RAM when training if possible. Saves VRAM.,训练时将 VAE 和 CLIP 从显存(VRAM)移放到内存(RAM)如果可行的话，节省显存(VRAM),训练时将 VAE 和 CLIP 从显存(VRAM)移放到内存(RAM)如果可行的话，节省显存(VRAM),训练时将 VAE 和 CLIP 从显存(VRAM)移放到内存(RAM)如果可行的话，节省显存(VRAM),hypernetworkの学をするH、VAEとCLIPをRAMへ退避。VRAMがsできます。
Weight for cond match,用于匹配文字调节(cond)的权重,用于匹配文字调节(cond)的权重,用于匹配文字调节(cond)的权重,
CRF,,,,CRF
tp__youdao,,,,tp__youdao
8bit AdamW,,,,8bit AdamW
"5. Changes are not applied to the text files until the ""Save all changes"" button is pressed.",5.按下“保存所有更改”按钮之前，更改将不会应用于文本文件,,,5. 「すべて涓を保存」ボタンが押されるまで、涓はテキストファイルにm用されません。
Console logging,向控制台输出日志,,,
Custom height,,,,カスタム高さ
Sort by,排序方式,,排序,ソ`ト
Result = A + (B - C) * M,结果 = A + (B - C) × M,结果 = A + (B - C) * M,结果 = A + (B - C) * M,出力されるモデル = A + (B - C) * M
WD 1.4 Tagger,WD1.4 Tag反推,WD 1.4 标签器,WD 1.4 标签器,WD 1.4 Tagger
Unprompted,非文本（代码化）提示词,非文本（代码化）提示词,非文本（代码化）提示词,Unprompted
Init Video,,,,ビデオを初期化
outputs,输出,,,
Negative Guidance minimum sigma,,,负面引导最小sigma,
I hate blue roses,I hate blue roses,,,I hate blue roses
ControlNet v1.1.266,扩散控制网络(ControlNet),,,
Output folder,,,,出力先フォルダ
{2::artist1|artist2},,,,{2::artist1|artist2}
How many image to create in a single batch (increases generation performance at cost of higher VRAM usage),,,,一回のバッチで生成する画像の数 (VRAM使用量が加して生成性能が向上)
Show only the tags selected in the Positive Filter,仅显示正面筛选条件中的 Tag,,,ポジティブフィルタ`でxkされているタグのみを表示
pascalcase,,,,パスカルケ`ス
others,其他,其他,其他,
x,横,,,x
"Raw percentage (50%, 150%)",,,,"元の割合 (50%, 150%)"
Use recycle bin when deleting images,将删除的图片放入回收站而非直接彻底删除（建议开启）,将删除的图片放入回收站而非直接彻底删除（建议开启）,将删除的图片放入回收站而非直接彻底删除（建议开启）,画像を削除するときにごみ箱を使用
UniPCMultistep,,,,UniPCMultistep
Area 5 Weight,蒙版 5 的权重(Weight),,,
"On the left sidebar, go to",,,,左のサイドバ`上の
KaimingUniform,Kaiming 均匀,Kaiming 均匀,Kaiming 均匀,He一分布
sketch,图生图(手绘修正),绘图,绘图,スケッチ
"Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.",,,,プロンプトトラベルとshift-attention のようなag(extを参照) を追加します。 Always-on + は既存のプロンプト集文で幼鳏筏蓼埂￥丹蓼钉蓼恃agモ`ドです。は wiki をごEください。
Negative prompt,负面提示词,反向提示词,反向提示词,ネガティブプロンプト
api,api,,,
Import Logo's (png),导入 Logo（PNG格式）,导入 Logo（PNG格式）,导入 Logo（PNG格式）,
original,原图,原图,原图,元の画像
Extra networks separator,,,附加网格的分隔符,
What to put inside the masked area before processing it with Stable Diffusion.,在使用 Stable Diffusion 处理蒙版区域之前要在蒙版区域内放置什么,在使用 Stable Diffusion 处理蒙版区域之前要在蒙版区域内放置什么,在使用 Stable Diffusion 处理蒙版区域之前要在蒙版区域内放置什么,Stable DiffusionでI理する前に、マスクされた欷撕韦きzむか。
Latent Mirror mode,镜像潜空间模式,镜像潜变量模式,镜像潜变量模式,R映化モ`ド
IN_B_11,,模型B 输入层11,模型B 输入层11,
Normalize:,,,,Normalize:
Combine axis,,,,SをY合
text2prompt,,,,text2prompt
V2 Model:,,,,V2 モデル:
CodeFormer,面部修复(CodeFormer),,,
Show mask in output ? show,,,,出力マスクを表示 → 表示
Show advanced adamW parameter options),,,,高度なadamWパラメ`タオプションを表示します)
Get inspiration,,,,インスピレ`ションを得る
Class Generation Schedulers,,,,クラス生成スケジュ`ラ`
Method to convert similarity into probability,,,,似性を_率にQする方法
tp__bing,,,,tp__bing
"Discard: remove style text from prompt, keep styles dropdown as it is.",,,丢弃：从提示词中移除样式，也不应用检测到的样式,
ControlNet v1.1.102,扩散控制网络(ControlNet),,,
Horizontal+Vertical Mirroring,垂直+水平镜像,垂直+水平镜像,垂直+水平镜像,上下左右R映化
NAIConvert,"""{}"" 转 ""()""",NAI 转换,NAI 转换,プロンプトQ
blur,,,,ぼかし
tp__qqTranSmart,,,,tp__qqTranSmart
Rate strength,,,,度
Randomize Sampler,随机化 采样器,随机化 采样器,随机化 采样器,
switch,,,,切り替え
Allow detectmap auto saving,允许自动保存探测模式图(detected maps),允许自动保存探测模式图(detected maps),允许自动保存探测模式图(detected maps),食訾丹欷骏蕙氓驻巫颖４妞蛟S可
(C6) Thertiary,,(C6) 第三,(C6) 第三,
sampling_steps,,,,サンプリングステップ数
Update,更新,更新,更新,アップデ`ト
ControlNet v1.1.244,扩散控制网络(ControlNet),,,
Create animation,,创建视频动画 (调用ffmpeg，需提前安装),创建视频动画 (调用ffmpeg，需提前安装),
Loose,,,,容
built with gradio,基于 Gradio 构建,基于 Gradio 构建,基于 Gradio 构建,
Bitwise operation,按位(Bitwise)运算,按位(Bitwise)运算,按位(Bitwise)运算,
Mode to use for model list,将以上列表内的模型设为,将以上列表内的模型设为,将以上列表内的模型设为,モデルリストに使用するモ`ド
Hybrid Schedules,,,,ハイブリッドスケジュ`ル
color,色彩引导（Color Guidance）,色彩,色彩,color
Colorerrortextactive,Colorerrortextactive,,,
Training parameters,训练参数,训练参数,训练参数,トレ`ニングパラメ`タ
Discard weights with matching name,"放弃与下列名称匹配的权重，可以通过写入""^model_ema""以舍弃模型中的EMA信息","放弃与下列名称匹配的权重，可以通过写入""^model_ema""以舍弃模型中的EMA信息","放弃与下列名称匹配的权重，可以通过写入""^model_ema""以舍弃模型中的EMA信息",一致する名前の重みを破する
Save as safetensors,存为safetensors格式,存为safetensors格式,存为safetensors格式,
Copy to ControlNet Segmentation,>>ControlNet,,复制到ControlNet,
stable-diffusion-webui-pixelization,像素化插件,像素化插件,像素化插件,stable-diffusion-webui-pixelization
Use only-mid-control on high-res. fix (second pass),高分辨率修复第二次生成时仅使用中间层控制(only-mid-control),,,
Hips,胯宽,,,
ug,,,,ug
Enable CLIP skip scheduling,,,,CLIPスキップスケジュ`リングを有郡摔工
"Negative Prompt, will be appended to your t2i negative prompt",输入区域负面提示词(Negative Prompt),,,
anti-burn,,,,anti-burn
Print image deletion messages to the console,"将 ""删除图片"" 的动作作为信息输出到控制台","将 ""删除图片"" 的动作作为信息输出到控制台","将 ""删除图片"" 的动作作为信息输出到控制台",コンソ`ルに画像削除メッセ`ジを出力する
Latent Couple,画面分区(Latent Couple)（配合 AND 语法，为每段 子提示词(sub prompt) 圈定画面区域),潜变量成对,潜变量成对,Latent Couple
Latent (nearest-exact),Latent（精确最邻近插值）,潜变量 (最近邻-整数),潜变量 (最近邻-整数),Latent (二アレスト-エグザクトag)
Generate Sample Images,,,,サンプル画像を生成
Prompt Info Update,预览效果并整合各段提示词(Prompt)（会同步上传到顶部提示词区域）,,,
ControlNet v1.1.120,扩散控制网络(ControlNet),,,
StylePile,,风格加码,风格加码,StylePile
Guided Images,,,,ガイド付き画像
ti,嵌入式(Embedding / TI / Textual Inversion),ti,ti,
Model C,模型C,,,
Band pass,,,,Band pass
Lora: use old method that takes longer when you have multiple Loras active and produces same results as kohya-ss/sd-webui-additional-networks extension,使用旧的 LoRA 加载方式（花费更长时间，以得到和使用 AddNet 时相同的结果）,,Lora：使用老的方法加载lora（当同时使用多个lora时将花费更多时间），这个选项可以用来复刻 kohya-ss/sd-webui-additional-networks插件的结果,
Foreground,前景,前景,前景,
slow,,,,Wい
missing metadata,缺失元数据,缺失元数据,缺失元数据,メタデ`タがありません
ScuNET PSNR,ScuNET PSNR,,,ScuNET PSNR
Blocks,被测试层ID,,,
Colorerrorborderhover,Colorerrorborderhover,,,
Save intermediate images during the sampling process. You can also make videos from the intermediate images.,,,,サンプリングI理中に中g画像を保存し、中g画像から踊を作成することも可能です。
Easily scale dimensions while retaining the same aspect ratio.,,,,同じアスペクト比をS持しながらgに大できます。
Hough distance threshold (MLSD),霍夫距离阈值（Hough distance threshold）（MLSD）,霍夫距离阈值（Hough distance threshold）（MLSD）,霍夫距离阈值（Hough distance threshold）（MLSD）,
Change your brush width to make it thinner if you want to draw something.,绘制内容请先调整笔刷粗细,绘制内容请先调整笔刷粗细,绘制内容请先调整笔刷粗细,ブラシの幅をくすると描きやすくなります
Intervals,,,,g隔
sigmoid,sigmoid,,,sigmoid
Soundtrack path,,,,サウンドトラックのパス
Preload images at startup for first tab,,,为第一个标签页预载图片,
Model B,模型B,模型B,模型B,
ControlNet-0,控制网络-0,,,
update list,更新列表,,,
Composable Mask scheduling,,,,合成可能なマスクスケジュ`リング
https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor,,,,https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor
openOutpaint extension,,,,openOutpaint extension
Artists To Study,,,,学するア`ティスト
Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.,,,,マッチするキ`ワ`ドを自拥膜衰抓恁螗抓趣啡毪筏蓼埂￥长C能を更新して、最新の model+keyword マッピングを取得します。
ranking filter,按图片评级筛选,评级筛选,评级筛选,ランキングフィルタ`
case,,,,ケ`ス
filelist: Returns a list of files at a given location using glob.,,,,filelist: globを使って、指定された鏊にあるファイルのリストを返します。
Enable tooltip on the canvas,,,在画布上启用悬停提示,
lb,,,,lb
stable-diffusion-webui-wd14-tagger,WD1.4 Tag反推插件,Waifu Diffusion 1.4 标签器,Waifu Diffusion 1.4 标签器,stable-diffusion-webui-wd14-tagger
mask,蒙版,,,
softsign,softsign,,,softsign
Video Input,,视频输入,视频输入,ビデオ入力
"Merge models with separate rate for each 25 U-Net block (input, middle, output).",,,,25のU-Netブロック(入力、中g、出力) ごとにe々の重みを持つモデルをマ`ジします。
invert_mask,,,,マスク反
OUT_B_03,,模型B 输出层03,模型B 输出层03,
Re-run your combinatorial batch this many times with a different seed each time.\nThe maximum number of outputs = Combinatorial batches * Batch size * Batch count.\nTo specify the maximum number of prompt combinations use 'Batch count'/'Batch size' options.,重复做多批次组合生成，每次用不同的随机种子\n最大输出数为 组合批次 * 批量（Batch size） * 批次（Batch count）\n在 “批次” 和 “批量” 处指定提示词组合的最大数量,重复做多批次组合生成，每次用不同的随机种子\n最大输出数为 组合批次 * 批量（Batch size） * 批次（Batch count）\n在 “批次” 和 “批量” 处指定提示词组合的最大数量,重复做多批次组合生成，每次用不同的随机种子\n最大输出数为 组合批次 * 批量（Batch size） * 批次（Batch count）\n在 “批次” 和 “批量” 处指定提示词组合的最大数量,
Use Interrogator Caption,使用反推算法为生成图片注释,,,インタ`ロゲ`タ`のキャプションを使用
OR,或(OR),,,OR
Append commas,附加逗号,附加逗号,附加逗号,
value,,,,
Low VRAM,显存优化,"低显存优化（需配合启动参数""--lowvram""）","低显存优化（需配合启动参数""--lowvram""）",低 VRAM
"How much to blur the mask before processing, in pixels.",处理前要对蒙版进行多强的模糊，以像素为单位,处理前要对蒙版进行多强的模糊，以像素为单位,处理前要对蒙版进行多强的模糊，以像素为单位,I理前にどれだけマスクをぼかすか。pxg位。
Control Model - 5,控制模型-5,,,
Send to,发送到,发送到,发送到,送する
OUT_A_11,,模型A 输出层11,模型A 输出层11,
- Reset zoom,,,- 重置缩放,
Adds image aspect ratio selector buttons.,,,,画像のアスペクト比xkボタンを追加します。
Network module 3,附加网络模块 3,附加网络类型 3,附加网络类型 3,Network module 3
Sampling Steps,,采样迭代步数(Steps),采样迭代步数(Steps),サンプリングステップ数
"Fullscreen Mode, maximizes the picture so that it fits into the screen and stretches it to its full width",,,全屏模式，将图像最大化以适应屏幕并将其拉伸到完整宽度,
ControlNet Unit 7,控制单元 7,,ControlNet单元7,
The RAW frames you have used as base for IA generation.,,,,The RAW frames you have used as base for IA generation.
Layer5 mask blur,,,,Layer5マスクのぼかし
Write the prompt template into the image metadata,,,,プロンプトテンプレ`トを画像のメタデ`タにきzみます
Weighted sum,加权和,加权和,加权和,加重平均
selected,已选择的,,,xk中
Amount of time to pause between Epochs (s),,,,エポックgで一r停止するrg(秒)
Token merging ratio,,,全局Token合并率,
smoothAdd,柔和加权（仅“添加差分”可用）,,,
Selected One,已选中的,,,xkされたもの
Move to favorites,移动到收藏夹,移动到收藏夹,移动到收藏夹,お荬巳毪辘匾
Instance token to swap,要互换的实例的词元(Token),要互换的实例的词元(Token),要互换的实例的词元(Token),
Truncate tags by token count,开始删节,,,ト`クン数でタグを切りめ
*Important* notes on Prompts,,,,プロンプトにvする重要な注意事
Sketch,图生图(手绘修正),绘图,绘图,スケッチ
or create it.,,,,または作成
Overwrite Old Embedding,覆写旧的 Embedding,覆写旧的 Embedding,覆写旧的 Embedding,古いEmbeddingを上き
Each image is center-cropped with an automatically chosen width and height.,,,每张图片都是自动居中裁剪,各画像は、自拥膜诉xkされた幅と高さで中央部分を切り取り(center crop)されます。
controlnet,,,,controlnet
base_alpha,文本编码器比例,文本编码器比例,文本编码器比例,
seed travel,种子变迁,种子变迁,种子变迁,seed travel
Laters,层,层,层,
Model_B,模型B,模型B,模型B,
img,,,,img
Max frames,,,,最大フレ`ム
zoom_enhance,,,,zoom_enhance
ControlNet v1.1.257,扩散控制网络(ControlNet),,,
Model 5,模型 5,模型 5,模型 5,モデル 5
prepend,放前面,放前面,放前面,先^に加える
"`animation_mode: None` batches on list of *prompts*. (Batch mode disabled atm, only animation_prompts are working)",,`animation_mode: None` *提示词*列表中的批次。 （批处理模式暂时禁用，只有 animation_prompts 有效）,`animation_mode: None` *提示词*列表中的批次。 （批处理模式暂时禁用，只有 animation_prompts 有效）,
Normal Resolution,法线贴图分辨率（Normal Resolution）,法线贴图分辨率（Normal Resolution）,法线贴图分辨率（Normal Resolution）,
Cosine Down,余弦递减(Cosine Down),,,
Generation Info,生成信息,,生成信息,生成rの情
sd-extension-aesthetic-scorer,美学评分插件,美学评分插件,美学评分插件,
devilkkw,,,,devilkkw
changeable blocks : ,可变权重层：,,,
openOutpaint,,,外扩插件,openOutpaint
Negative,负面提示词,,,
color_coherence_video_every_N_frames,,,,color_coherence_video_every_N_frames
Detect from image,从图片识别,从图片识别,从图片识别,画像から食訾工
',,,,'
Clip and renormalize,,,,クリップおよび再法I理
Make an attempt to produce a picture similar to what would have been produced with same seed at specified resolution,尝试生成图像，与同一随机种子在指定分辨率下生成的图像相似,尝试生成图像，与同一随机种子在指定分辨率下生成的图像相似,尝试生成图像，与同一随机种子在指定分辨率下生成的图像相似,指定された解像度で同じシ`ドを使用した龊悉位像に近いものを生成します。
Hybrid composite,,,,ハイブリッドコンポジット
BOOST (multi-resolution merging),,,,ブ`スト (マルチ解像度マ`ジ)
Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.,,,,「Pharmapsychotic」による「Clip Interrogator」がC能に移植されました。さまざまなクリップモデルとい合わせO定を浃à皮い蓼埂
Enable quantization in K samplers for sharper and cleaner results. This may change existing seeds. Requires restart to apply.,在 K 采样器中启用量化以获得更清晰、干净的结果。这可能会改变现有的随机种子。需要保存设置并重启才能应用,在 K 采样器中启用量化以获得更清晰、干净的结果。这可能会改变现有的随机种子。需要保存设置并重启才能应用,在 K 采样器中启用量化以获得更清晰、干净的结果。这可能会改变现有的随机种子。需要保存设置并重启才能应用,より良いY果を得るために、Kサンプラ`で量子化を有郡摔筏蓼埂￥长欷摔瑜昙却妞违珐`ドが涓される可能性があります。m用するには再起婴必要です。
N/A,,,,N/A
Style to apply; styles have components for both positive and negative prompts and apply to both,要使用的模版风格； 模版风格包含正面和负面提示词，并应用于两者\n? 随机添加一个艺术家到提示词中\n L?  从提示词中读取生成参数，如果提示词为空，则读取上一次的生成参数到用户界面\n? 将当前的提示词保存为模版风格(保存在styles.csv)\n? 将所选模板风格，应用于当前提示词\n如果你在文本中添加{prompt}标记，并保存为模版风格\n那么将来你使用该模版风格时，你现有的提示词会替换模版风格中的{prompt},要使用的模版风格； 模版风格包含正向和反向提示词，并应用于两者\n? 随机添加一个艺术家到提示词中\n L?  从提示词中读取生成参数，如果提示词为空，则读取上一次的生成参数到用户界面\n? 将当前的提示词保存为模版风格(保存在styles.csv)\n? 将所选模板风格，应用于当前提示词\n如果你在文本中添加{prompt}标记，并保存为模版风格\n那么将来你使用该模版风格时，你现有的提示词会替换模版风格中的{prompt},要使用的模版风格； 模版风格包含正向和反向提示词，并应用于两者\n? 随机添加一个艺术家到提示词中\n L?  从提示词中读取生成参数，如果提示词为空，则读取上一次的生成参数到用户界面\n? 将当前的提示词保存为模版风格(保存在styles.csv)\n? 将所选模板风格，应用于当前提示词\n如果你在文本中添加{prompt}标记，并保存为模版风格\n那么将来你使用该模版风格时，你现有的提示词会替换模版风格中的{prompt},
A file on the same machine where the server is running.,,,,サ`バ`が稼Pしている同じマシン上のファイル。
checkboxes,,,复选框,
mish,mish,,,mish
to_dir_load_switch,,,,to_dir_load_switch
ControlNet - 4,扩散控制网络(ControlNet) - 4,,,
Limb Width,肢体粗细,肢体粗细,肢体粗细,
"If the chosen number of terms is greater than the available terms, then some terms will be duplicated, otherwise chosen terms will be unique. This is useful in the case of wildcards, e.g.",选的项数多于提供的项数时，有些项会重复，其余情况各选项会保持唯一；\n重复对于通配符很有用，例如：,选的项数多于提供的项数时，有些项会重复，其余情况各选项会保持唯一；\n重复对于通配符很有用，例如：,选的项数多于提供的项数时，有些项会重复，其余情况各选项会保持唯一；\n重复对于通配符很有用，例如：,xkした用Zの数がプロンプトより大きい龊稀プロンプトが}uされます。 これはワイルドカ`ドを使うHに便利です。例えば、
hires_resize_x,,,,高解像度 サイズ涓X
Original First,原文在前,原文在上面,原文在上面,原文を先に表示
[ControlNet] Weight,[ControlNet] 权重,[ControlNet] 权重,[ControlNet] 权重,[ControlNet] 重み
Corruption Preserve,,,,Corruption Preserve
different,差异,差异,差异,
https://github.com/Bing-su/sd-webui-tunnels.git,,,,https://github.com/Bing-su/sd-webui-tunnels.git
"Output directory for images; if empty, defaults to three directories below",图像的输出目录； 如果为空，则默认为以下三个目录,图像的输出目录； 如果为空，则默认为以下三个目录,图像的输出目录； 如果为空，则默认为以下三个目录,画像の出力ディレクトリ(空冥龊稀⒁韵陇3つのディレクトリが定の保存先になります)
Edit pose of 3D model,编辑3D模型,,,
ControlNet v1.1.161,扩散控制网络(ControlNet),,,
Latent Mirror style,潜空间镜像方式,潜变量镜像方式,潜变量镜像方式,潜在R映化スタイル
IN_B_07,,模型B 输入层07,模型B 输入层07,
bh2,,,,bh2
Only copy to models with same session ID,仅复制到具有相同会话 ID 的模型,仅复制到具有相同 session ID 的模型,仅复制到具有相同 session ID 的模型,同じセッションIDのモデルにのみコピ`する
Scale,,,缩放比例,スケ`ル
Layer2,,,,Layer2
"To see effects, you must use dropdown, select as sheet, click apply, click restart. More options will be available on restart","想要查看效果，必须使用""模板风格""下拉菜单，选择并单击""应用风格""与""应用设置""， 重启后生效","想要查看效果，必须使用""模板风格""下拉菜单，选择并单击""应用风格""与""应用设置""， 重启后生效","想要查看效果，必须使用""模板风格""下拉菜单，选择并单击""应用风格""与""应用设置""， 重启后生效",
sq,,,,sq
(O3) Output ckpt Name,,(O3) ckpt 输出名,(O3) ckpt 输出名,
Has EMA:,,,,EMAがあります:
Cropping,剪裁,剪裁,剪裁,クロッピング
Apply to,应用于,应用于,应用于,次にm用
img2img-grids,宫格图(i2i),宫格图(i2i),宫格图(i2i),img2img-grids
Token Length,按词元(Token)长度,,,ト`クンのLさ
Fast Encoder,快速编码,快速编码,快速编码,高速エンコ`ダ
You can enhance semantic segmentation for control_v11p_sd15_seg from lllyasviel. You can also utilize,,,前三个选项可以用来增强ControlNet的语义分割效果。你也可以使用“随机”来产生不包含语义的蒙版，这目前是配合,
Create From Hub,,,,ハブから作成
Area 8 Weight,蒙版 8 的权重(Weight),,,
A weighted sum will be used for interpolation. Requires two models; A and B. The result is calculated as A * (1 - M) + B * M,将两个模型权重的加权和作为新模型的权重，仅需要填入模型A和B，公式：A×(1-M) + B×M，倍率(M)为模型B所占比例,将两个模型权重的加权和作为新模型的权重，仅需要填入模型A和B，公式：A*(1-M) + B*M，倍率(M)为模型B所占比例,将两个模型权重的加权和作为新模型的权重，仅需要填入模型A和B，公式：A*(1-M) + B*M，倍率(M)为模型B所占比例,重み付き平均法（加重平均）がag（内罚─耸褂盲丹欷蓼埂AとBの二つのモデルが必要です。Y果は、A * (1 - M) + B * M で算されます。
Platform,运行平台,运行平台,运行平台,
Overlay:,,,,Overlay:
The beta2 parameter for the Adam optimizer.,Adam 优化器的 beta2 参数,Adam 优化器的 beta2 参数,Adam 优化器的 beta2 参数,
Total num of point for curve (reload required),,,,ト`ンカ`ブのポイント数(反映には再起婴必要)
Saved directories,已保存的路径,已保存的路径,已保存的路径,保存先
Extra args:,,,额外参数（Extra args）,
+25%,,,,+25%
"video_init_path, extract_nth_frame, overwrite_extracted_frames",,,,"video_init_path, extract_nth_frame, overwrite_extracted_frames"
Dismiss,屏蔽,屏蔽,屏蔽,
DFI Tolerance,,,,S容
"Resize image to target resolution. Unless height and width match, you will get incorrect aspect ratio.",将图像大小调整为目标分辨率。除非高度和宽度匹配，否则你将获得不正确的纵横比,将图像大小调整为目标分辨率。除非高度和宽度匹配，否则你将获得不正确的纵横比,将图像大小调整为目标分辨率。除非高度和宽度匹配，否则你将获得不正确的纵横比,画像をタ`ゲット解像度にリサイズします。高さと幅が一致しない龊稀アスペクト比が正しくなくなります。
view,查看,查看,查看,
twitter,,,,twitter
Save grids to a subdirectory,将宫格图保存到子目录,将宫格图保存到子目录,将宫格图保存到子目录,グリッド画像をサブディレクトリに保存する
How many samples to generate per subject.,每个主体生成多少样本,每个主体生成多少样本,每个主体生成多少样本,
Print extra hypernetwork information to console.,将额外的超网络信息输出到控制台,将额外的超网络(hypernetwork)信息输出到控制台,将额外的超网络(hypernetwork)信息输出到控制台,追加のHypernetworksの情螭颔偿螗僵`ルに出力
ControlNet v1.1.131,扩散控制网络(ControlNet),,,
constant_with_warmup,含预热的常量(constant),含预热的常量(constant),含预热的常量(constant),constant_with_warmup
ru,,,,ru
A merger of the two checkpoints will be generated in your,合并后的 Stable Diffusion 模型(ckpt) 会生成在你的,合并后的模型(ckpt)会生成在你的,合并后的模型(ckpt)会生成在你的,
"When adding to prompt, refer to lora by",将附加网络添加到提示词的时候，使用：,,当在提示词中添加时，参考lora通过,
lt,,,,lt
replace: Updates a string using the arguments for replacement logic.,,,,replace: 置Qロジックの引数を使用して文字列を更新します。
perlin,,,,パ`リンノイズ
ControlNet - 0,扩散控制网络(ControlNet) - 0,,,
kmewhort/stable-diffusion-prompt-bolster,,,,kmewhort/stable-diffusion-prompt-bolster
Translated Status,翻译状态,,,翻Uのステ`タス
DPM++ 2M Karras,DPM++ 2M Karras,,,DPM++ 2M Karras
integrations,集成功能,集成功能,集成功能,
Load Model,,,,モデルiみzみ
Value should be in (0-1],,,,は(0-1] の炷冥扦る必要があります
Suffix,后缀匹配,,,接尾Z
save settings,保存选项,,,
Color correction factor,,,,色a正S数
Will upscale the image by the selected scale factor; use width and height sliders to set tile size,将按选定的比例因子对图像进行放大；使用宽度和高度滑块设置平铺大小,,,xkした倍率で画像を大します; 幅と高さのスライダを使ってタイルの大きさをO定します
?Open config file...,?打开配置文件,,,
Interrogate\nDeepBooru,DeepBooru Tag反推,DeepBooru\n反推提示词,DeepBooru\n反推提示词,DeepBooruによる解析
"Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps higher than 30-40 does not help",,,,Euler Ancectral - 非常に造的で、ステップ数によって全くなる画像が得られるが、ステップ数を30~40より高くO定しても抗はない
Save text information about generation parameters as chunks to png files,将有关生成参数的文本信息，作为块保存到 PNG 图片文件中（强烈建议开启）,将有关生成参数的文本信息，作为块保存到 PNG 图片文件中（强烈建议开启）,将有关生成参数的文本信息，作为块保存到 PNG 图片文件中（强烈建议开启）,生成にvするパラメ`タ`をPNG画像に含める
This mode works ONLY with 2D/3D animation modes. Interpolation and Video Input modes aren't supported.,,,,このモ`ドは、2D/3Dアニメ`ションモ`ドのみで幼鳏筏蓼埂Ｑagモ`ドやビデオ入力モ`ドには辘筏皮い蓼护蟆
sd-extension-steps-animation,,生成去噪过程动画插件,生成去噪过程动画插件,
Apply (Reload UI),应用（重启 WebUI）,应用（重启 WebUI）,应用（重启 WebUI）,
Deflickers Playground,,,,Deflickers Playground
Return the character count ? character_count,,,,文字数を返す ? character_count
a-z,首字母升序,,,a-z（N）
Apply transfer control when loading models,加载模型时应用传输控制,加载模型时应用传输控制,加载模型时应用传输控制,モデルをiみzむH、Control の送をm用する
3. Download Model,3.下载模型,3. 下载模型,3. 下载模型,
Create aesthetic images embedding,创建美术风格图集 Embedding,创建美术风格图集 Embedding,创建美术风格图集 Embedding,
Create an embedding from one or few pictures and use it to apply their style to generated images.,用一张或多张图像创建一个 Embedding，并用它将图集的风格转移到要生成的图像上,用一张或多张图像创建一个 Embedding，并用它将图集的风格转移到要生成的图像上,用一张或多张图像创建一个 Embedding，并用它将图集的风格转移到要生成的图像上,
Card width for Extra Networks (px),缩略预览图宽度（像素，推荐设为71，每行可显示20个预览）,,自定义卡片宽度，像素,追加ネットワ`クのカ`ドの幅 (px)
medium,,,,普通
Name of array variable ? str,,,,配列涫の名前 → str
Standard deviation for sampling,,,,サンプリングの势差
Select Image,,选择图像,选择图像,
"WARNING : Settings are immediately applied but will not be saved until you click ""Save""",警告：所有设置都会立即生效，但不会保存，需要手动点击保存按钮,,,
Debug info,,在控制台打印详细信息,在控制台打印详细信息,
Canvas Ground Color,,,,キャンバスの地面の色
"Apply if any: remove style text from prompt; if any styles are found in prompt, put them into styles dropdown, otherwise keep it as it is.",,,如果使用的话应用：从提示词中移除样式，并将检测到的可以使用的样式应用,
How many images to process at once per training step?,每步训练要处理多少张图像？,每步训练要处理多少张图像？,每步训练要处理多少张图像？,
Glow,,,,グロ`
Fields to save,预设包含的内容,,,
wd14-convnext-v2,,,,wd14-convnext-v2
(A6) Primary,,(A6) 主要,(A6) 主要,
Hough value threshold (MLSD),霍夫值阈值（Hough value threshold）（MLSD）,霍夫值阈值（Hough value threshold）（MLSD）,霍夫值阈值（Hough value threshold）（MLSD）,
Outer Fit (Shrink to Fit),截取适配（舍弃溢出画布的内容）,,,
tr,,,,tr
Use noise mask,,,,ノイズマスクを使用する
Pad prompt/negative prompt to be same length,,,将正向/反向提示词填充到同样的长度,
unset: Removes one or more variables from memory. Generally not needed.,,,,解除: メモリから1つ以上の涫を削除します。一般的には不要です。
Codec,,编码器,编码器,
"Example: seed_schedule could use 0:(5), 1:(-1), 219:(-1), 220:(5)",,,,"例: seed_schedule は 0:(5), 1:(-1), 219:(-1), 220:(5) を使用できます。"
Embedding Editor,Embedding 编辑器,Embedding 编辑器,Embedding 编辑器,Embedding Editor
"for coco to get category->id map. Note that coco jumps some numbers, so the actual ID is line_number - 21.",查看 COCO协议 类别与ID的映射关系。注意，COCO协议会跳过一些数字，所以实际的ID是 <行号>-21,,”来查看COCO协议的id对应表，注意COCO协议有些数字并没有定义。,
Constant/Linear Starting Factor,,,,定数/形_始S数
Force denoising strength to this value ? denoising_strength,,,,ノイズ除去度をこのに制する ? denoising_strength
SoftEdge,,,软边,
Extension index URL,扩展列表网址,扩展列表网址,扩展列表网址,C能リストのURL
- Background,--背景参考图--,--背景参考图--,--背景参考图--,
"Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.",,,,"Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you."
(0 = no tiling),,,（0表示不分块）,
stable-diffusion-webui-cafe-aesthetic,,,,stable-diffusion-webui-cafe-aesthetic
DPM adaptive,DPM adaptive,,,DPM adaptive
DH Patch,,,,DH Patch
Enter output path,键入输出路径,,输入拆分输出的路径,
tp_bing,,,,tp_bing
Enable Autocomplete,启用Tag自动补全,启用Tag自动补全,启用Tag自动补全,
Pixels to expand,拓展的像素数,拓展的像素数,拓展的像素数,大するピクセル数
Lora Text Weight,,,,LoRA Text Weight
Input path,输入路径,,拆分输入的路径,
kernel size,,,,カ`ネルサイズ
Whitelist,白名单（启用tag自动填充）,白名单（启用tag自动填充）,白名单（启用tag自动填充）,ホワイトリスト
Restart Krita again for changes to take effect.,,,,Krita をもう一度再起婴筏涓をm用します。
180 Degree Rotation,180度旋转,180度旋转,180度旋转,180度回
Power Down,骤减(Power down),,,
hybrid_comp_mask_auto_contrast,,,,ハイブリッドコンポジットマスクオ`トコントラスト
explicit,露骨内容/Explicit（色情）,色情/露骨内容（Explicit）,色情/露骨内容（Explicit）,
Increment seed after each controlnet batch iteration,每次扩散控制网络批量迭代后增加随机种子值,,批处理的每次迭代后改变ControlNet的随机种子（不是WebUI的随机种子）,
"Keyframes: generation settings (noise, strength, contrast, scale).",,,,キ`フレ`ム：生成O定 (ノイズ、度、コントラスト、スケ`ル)。
Network module 2,附加网络模块 2,附加网络类型 2,附加网络类型 2,Network module 2
Bicubic,,,,バイキュ`ビック
titlecase,,,,タイトルケ`ス
elif: Shorthand 'else-if.',,,,elif: 「else-if」の省略形です。
File Time,文件时间信息,,,
ML-Danbooru-webui,MLDanbooru Tag反推插件,,,
Fast Mode,,快速模式,快速模式,
Generate random prompts from lexica.art (your prompt is used as a search query).,从 lexica.art 生成随机提示词（你的提示词会被用作搜索查询）,从 lexica.art 生成随机提示词（你的提示词会被用作搜索查询）,从 lexica.art 生成随机提示词（你的提示词会被用作搜索查询）,lexica.artからランダムなプロンプトを生成します (仕鳐エリとしてプロンプトが使用されます)。
ex C.,例子C：,,,例えば、C.
sd-webui-aspect-ratio-helper,,,,sd-webui-aspect-ratio-helper
multidiffusion-upscaler-for-automatic1111,分块多重扩散(MultiDiffusion)插件,MultiDiffusion 放大器,MultiDiffusion 放大器,multidiffusion-upscaler-for-automatic1111
st,,,,st
Negative mask padding radius in pixels ? neg_padding,,,,ピクセルg位のネガティブマスクパディング半径 ? neg_padding
Username,用户名,用户名,用户名,
chance,,,,チャンス
Add to / replace in saved directories,添加或覆盖 已保存的目录,,增加/替换进已保存的目录,保存gディレクトリに追加/置Q
Send to txt2img ControlNet,>> 文生图(ControlNet),,>>文生图ControlNet,txt2img ControlNet に送
Enter a model name for saving checkpoints and lora models.,,,,CheckpointとLoRAモデルを保存するためのモデル名を入力
Return the word count ? word_count,,,,gZ数を返す ? word_count
Only show .safetensors format models,只显示 .safetensors 格式的模型,只显示 .safetensors 格式的模型,只显示 .safetensors 格式的模型,.safetensors 形式のモデルのみを表示する
txt2img_height,高度,,,
Dry Run,试运行,试运行,试运行,\
Font for image grids that have text,"有文字的宫格图使用的字体（避免出现X/Y表中文无法显示，可设置为 ""simhei.ttf""）","有文字的宫格图使用的字体（避免出现X/Y表中文无法显示，可设置为 ""simhei.ttf""）","有文字的宫格图使用的字体（避免出现X/Y表中文无法显示，可设置为 ""simhei.ttf""）",画像グリッド内のテキストフォント
Resize and Fill,填充画布无引导区域,,填充缩放,
Use minimal area (for close faces),,,多张人脸靠近时，使用较小的识别区域,
u2net,,,,u2net
Specific branch name,分支名称,,指定分支名（如果有）,
Instance selection mode ? select_mode,,,,インスタンスxkモ`ド → xkモ`ド
linear_light,,,,linear_light
- Camera,--镜头--,--镜头--,--镜头--,
model,Stable Diffusion 模型(ckpt) 名称,模型,模型,モデル
"You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.",,,,"You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed."
portrait,,,,ポ`トレ`ト
hr,,,,hr
Open Folder,打开文件夹按钮,,,
top_centered,顶部，居中,,,
https://github.com/muerrilla/stable-diffusion-NPW,,,,https://github.com/muerrilla/stable-diffusion-NPW
Return mask,返回蒙版图像,,输出蒙版,マスク画像のみ
Hybrid motion,,,,ハイブリッドモ`ション
"choose: Returns one of multiple options, delimited by newline or vertical pipe",,,,choose: 改行またはk棒で区切られた}数のオプションのうち1つを返します。
"Check this if you want to generate random prompts, even if your seed is fixed",勾选此选项以在固定随机种子的情况下依然生成随机提示词,勾选此选项以在固定随机种子的情况下依然生成随机提示词,勾选此选项以在固定随机种子的情况下依然生成随机提示词,シ`ドが固定されていても、ランダムなプロンプトを生成したい龊悉悉长欷颔隶Д氓してください
Batch from Directory,从目录进行批量处理,从目录进行批量处理,从目录进行批量处理,ディレクトリからバッチI理
Download localization template,下载本地化模板,下载本地化模板,下载本地化模板,翻U用テンプレ`トをダウンロ`ド
Please use smaller tile size when see CUDA error: out of memory.,当显存溢出(CUDA error: out of memory)时，请调小图块尺寸(Tile Size),当显存溢出(CUDA error: out of memory)时，请调小图块尺寸(Tile Size),当显存溢出(CUDA error: out of memory)时，请调小图块尺寸(Tile Size),CUDA error: out of memoryがk生した龊悉稀タイルサイズを小さくしてください。
Smart Process,智能预处理,智能预处理,智能预处理,Smart Process
Generate 3D inpainted mesh. (Sloooow),,,,3D inpaintされたメッシュを生成(とてもWい)
Upscaling,放大,放大,放大,アップスケ`ル
VRAM Estimator,显存评估,显存(VRAM)评估,显存(VRAM)评估,VRAM Estimator
Don't cache latents,不要缓存潜空间变量,不要缓存潜变量,不要缓存潜变量,
or to CTRL+SHIFT,将 CTRL 绑定更改为 CTRL+SHIFT,将 CTRL 绑定更改为 CTRL+SHIFT,将 CTRL 绑定更改为 CTRL+SHIFT,または Ctrl + Shift
Lora Text Encoder Rank,,,,LoRA Text Encorder Rank
Canny,,,边缘,
Optionally use [filewords] to read image captions from files.,可选择使用 [filewords] 去从文件中读取图像的描述,可选择使用 [filewords] 去从文件中读取图像的描述,可选择使用 [filewords] 去从文件中读取图像的描述,必要に辘袱啤[filewords] を使用してファイルから画像のキャプションをiみ取ることができます。
override: Force variable(s) to hold a pre-determined value the rest of the run.,,,,override: 涫にあらかじめQめられたを制的にO定して、g行をAけます。
A negative prompt to use when generating class images. Can be empty.,生成类图像时使用的否定提示。 可以为空。,生成类图像时使用的否定提示。 可以为空。,生成类图像时使用的否定提示。 可以为空。,
openpose_full,姿态检测（openpose 模型，OpenPose 算法，姿态+脸部+手部）,,姿态检测（OpenPose 算法，身体+脸部+手部）,
Caption Text File,注释文本文件,,,キャプションテキストファイル
Nearest,最邻近(整数缩放),最邻近(整数缩放),最邻近(整数缩放),Nearest
Training Picker,训练图挑选器,训练图挑选器,训练图挑选器,Training Picker
Canny high threshold ? high_threshold,,,,Cannyの高いしきい? high_threshold
Adam Beta 1,Adam Beta 1,,,
Generation settings:,,一般设置:,一般设置:,
Move face restoration model from VRAM into RAM after processing,面部修复处理完成后，将其模型从显存(VRAM)移至内存(RAM),面部修复处理完成后，将其模型从显存(VRAM)移至内存(RAM),面部修复处理完成后，将其模型从显存(VRAM)移至内存(RAM),I理K了後、の修庭猊钎毪VRAMからRAMへと移婴工
Use skip-connection. Won't work without extension!,,,,スキップ接Aを使用してください。C能なしでは幼鳏筏蓼护螅
Scale from image size,,,,画像サイズから大
Latent Mirroring,镜像潜空间图像,镜像潜变量,镜像潜变量,Latent Mirroring
Model Toolkit,模型工具包,,,
ControlNet v1.1.202,扩散控制网络(ControlNet),,,
ControlNet v1.1.135,扩散控制网络(ControlNet),,,
RIFE v4.6,,,,RIFE v4.6
Weight for latent match (grad/replace-grad mode),用于匹配潜空间(latent)的权重 (梯度/取代模式),用于匹配潜变量(latent)的权重 (梯度/取代模式),用于匹配潜变量(latent)的权重 (梯度/取代模式),
Multi Proc Cmd,多进程命令,多进程命令,多进程命令,
Get javascript logs,,,获取javascript日志,
ControlNet Unit 6,控制单元 6,,ControlNet单元6,
Enable pixelization,启用像素化,启用像素化,启用像素化,Enable pixelization
User guide for v0.5 docs.google.com/document/d/1pEobUknMFMkn8F5TMsv8qRzamXX_75BShMMXV8IFslI/edit,,v0.5 用户指南 docs.google.com/document/d/1pEobUknMFMkn8F5TMsv8qRzamXX_75BShMMXV8IFslI/edit,v0.5 用户指南 docs.google.com/document/d/1pEobUknMFMkn8F5TMsv8qRzamXX_75BShMMXV8IFslI/edit,
tp_yandex,,,,tp_yandex
reset,,,,リセット
Sample Image Negative Prompt,样本图像的负面提示词,样本图像的反向提示词,样本图像的反向提示词,
tl,,,,tl
black-white,,,,白\
sdweb-xyplus,X/Y图表 Plus 插件,X/Y图表 Plus 插件,X/Y图表 Plus 插件,
Class,类,,,
SAM Model,SA模型(Segment Anything Model) 选择,,SAM模型（大显存用h，中显存用l，小显存用b）,
OUT_B_07,,模型B 输出层07,模型B 输出层07,
CodeFormer weight,,,CodeFormer权重,
Before,,,,前
Hires. fix,高分辨率修复,高清修复,高清修复,高解像度a助
Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.,,,,Textual Inversion を文字列リテラルからg行rにマ`ジします。フレ`ズと重みのもサポ`トされています。
ControlNet v1.1.284,扩散控制网络(ControlNet),,,
Video Init,,,,ビデオの初期
IN_B_06,,模型B 输入层06,模型B 输入层06,
Init image,,,,初期画像
Models...,模型列表,模型列表,模型列表,
ControlNet v1.1.150,扩散控制网络(ControlNet),,,
"With img2img, do exactly the amount of steps the slider specifies (normally you'd do less with less denoising).",在进行图生图的时候，确切地执行滑块指定的迭代步数（正常情况下更弱的重绘幅度需要更少的迭代步数）,在进行图生图的时候，确切地执行滑块指定的迭代步数（正常情况下更弱的重绘幅度需要更少的迭代步数）,在进行图生图的时候，确切地执行滑块指定的迭代步数（正常情况下更弱的重绘幅度需要更少的迭代步数）,img2imgでスライダ`で指定されたステップ数を正_にg行する（通常は、ノイズ除去を少なくするためにより少ないステップ数でg行します）。
unload model,从 VRAM 卸载模型,,,
Base Depth,,,基础深度,
"ln -s ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff"" ""<path_to_pykrita>/krita_diff""\nln -s ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff.desktop"" ""<path_to_pykrita>/krita_diff.desktop""",,,,"ln -s ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff"" ""<path_to_pykrita>/krita_diff""\nln -s ""D:\StableDiffusion\clean install\webui\extensions\auto-sd-paint-ext\frontends\krita\krita_diff.desktop"" ""<path_to_pykrita>/krita_diff.desktop"""
Get Tags,从Gelbooru获取标签 (图像必须是原图且以Gelbooru原始的MD5哈希值命名),从Gelbooru获取标签 (图像必须是原图且以Gelbooru原始的MD5哈希值命名),从Gelbooru获取标签 (图像必须是原图且以Gelbooru原始的MD5哈希值命名),
SD Unet,,,SD Unet,
Inpaint area,重绘区域,重绘区域,重绘区域,inpaintを行うI域
escape (\) brackets in deepbooru (so they are used as literal brackets and not for emphasis),在 deepbooru 中使用转义括号（防止被误读为强调符）,在 deepbooru 中使用转义括号（防止被误读为强调符）,在 deepbooru 中使用转义括号（防止被误读为强调符）,deepbooruで括弧をエスケ`プする(\) ({を示す()ではなく、文字通りの()であることをモデルに示すため)
CFG Scale,提示词相关性(CFG Scale),提示词相关性(CFG Scale),提示词相关性(CFG Scale),CFGスケ`ル
lineart_realistic,线稿提取（lineart 模型，针对照片）,,线稿提取-写实（lineart_realistic）,
filename,,文件名,文件名,
Run inpaint per instance found ? per_instance,,,,kされたインスタンスごとに inpaint をg行する → インスタンス
Background Multiplier,背景权重(Background Multiplier),,,
Select visible tags,选择可见的 Tag,,,表示中のタグをxk
Save all changes,保存所有变更,,,すべての涓を保存
horizontal split num,水平分区数量,,,
refine,,,,美肌モ`ド
Match Frame 0 HSV,,匹配帧 0 HSV,匹配帧 0 HSV,フレ`ム0のHSVに一致する
Hair,,,头发,
Index,,,,インデックス
File,文件,文件,文件,ファイル
"Result = ""A, B, C, X, Y""?(add X and Y to the end (default))","　　结果：“A, B, C, X, Y”（X和Y被添加到结尾，此为默认设置）",,,"Y果= ""A、B、C、X、Y"" (XとYを末尾に追加（デフォルト）)"
Generate Shortcode,,,,ショ`トコ`ドを作成
ControlNet v1.1.216,扩散控制网络(ControlNet),,,
ControlNet - 1,扩散控制网络(ControlNet) - 1,,,
Copy to ControlNet Inpainting,复制到 ControlNet 进行局部重绘,,复制（默认是蒙版）到ControlNet重绘,
ControlNet v1.1.237,扩散控制网络(ControlNet),,,
separatorcase,,,,セパレ`タケ`ス
FFMPEG mp4,,,,FFMPEG mp4
working,运行中,运行中,运行中,
Path to store extracted frame sets in,储存截取帧的路径,储存截取帧的路径,储存截取帧的路径,抽出したフレ`ムセットを保存するパス
"After enabling translation, please Wait until I am ready",启用翻译后，请等待此处显示 “ready” 再进行下一步操作,,,
Create Model,创建模型,创建模型,创建模型,モデル作成
logsoftmax,logsoftmax,,,logsoftmax
"In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.",,,,"In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render."
Area upper bound,,,面积最大值,面e(幅×高さ)の上限
lv,,,,lv
ControlNet v1.1.262,扩散控制网络(ControlNet),,,
Set a variable ? my_var,,,,涫のO定 ? my_var
Mask Setting,蒙版设置,,,
Leg Length,整体腿长,,,
Use layers as row instead of Batch Length,,,,バッチLの代わりにレイヤ`を行に使用
Model hash,模型哈希值,模型哈希值,模型哈希值,モデルのHash
Disable control type selection,,,关闭“控制类型”选项,
txt2img_batch_count,生成批次,,,
Append DeepDanbooru to Caption,把 DeepDanbooru 的结果接在已有的描述文本后面,把 DeepDanbooru 的结果接在已有的描述文本后面,把 DeepDanbooru 的结果接在已有的描述文本后面,
grad,梯度,梯度,梯度,
https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git,,,,https://github.com/thomasasfk/sd-webui-aspect-ratio-helper.git
mine-diffusion,,,,mine-diffusion
to img2img,,,,画像から画像に
Send to Layer1,,,,レイヤ`1に送
Extract,,,,Extract
Upscale V2,,,,上位スケ`ル V2
OUT_B_02,,模型B 输出层02,模型B 输出层02,
sd-dynamic-prompting,动态提示词,动态提示词,动态提示词,
txt2img_batch_size,每批数量,,,
Ranking filter,,,评级（Ranking）过滤,ランキングフィルタ`
Skip video for run all,,,,すべてg行するためにビデオをスキップ
Resize by,,,调整大小百分比,
Blend,,,,Layerで合成
Unload SD checkpoint to free VRAM,从 显存 中卸载 Stable Diffusion 模型(ckpt),,从显存中卸载模型（checkpoint，无需重启）,SD checkpointをアンロ`ドしてVRAMを解放
sd_grid_add_image_number,图片序号标注插件,,,
ControlNet v1.1.173,扩散控制网络(ControlNet),,,
Extra arguments for trtexec command in plain text form,,,以纯文本形式提供trtexec命令的额外参数,
"{% for colour in [""red"", ""blue"", ""green""] %}\n        {% if colour == ""red""}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}","{% for colour in [""red"", ""blue"", ""green""] %}\n        {% if colour == ""red""}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}",,,"% for colour in [""red"", ""blue"", ""green""] %}\n        {% if colour == ""red""}\n            {% prompt %}I love {{ colour }} roses{% endprompt %}\n        {% else %}\n            {% prompt %}I hate {{ colour }} roses{% endprompt %}\n        {% endif %}\n    {% endfor %}"
Divide mode,分区方式,,,分割モ`ド
"Generate a preview image every N steps, 0 to disable",每隔 N 步生成一次预览图，设置为 0 以禁用,每隔 N 步生成一次预览图，设置为 0 以禁用,每隔 N 步生成一次预览图，设置为 0 以禁用,
What DFI does?,,,,What DFI does?
max: Returns the maximum value among the given arguments.,,,,max: 与えられた引数の中の最大を返します。
A directory on the same machine where the server is running.,服务器主机上某一目录,服务器主机上某一目录,服务器主机上某一目录,サ`バ`が稼Pしているのと同じマシンにあるディレクトリ
spaceship-n,,,,宇宙船演算子(n)
Copy to clipboard,复制到剪贴板,复制到剪贴板,复制到剪贴板,
Save generated images within tensorboard.,将生成的图像保存在 tensorboard 中,将生成的图像保存在 tensorboard中,将生成的图像保存在 tensorboard中,生成した画像をテンソルボ`ド内に保存します。
ControlNet-3,控制网络-3,,,
portrait-digipa-med-impact,,,,肖像画-digipa中インパクト
default = 1e-8,,,,既定 =1e-8
Accent color,高亮区域颜色,,,
hyponyms: Replaces the content with one or more synonyms.,,,,下位概念：コンテンツを1つ以上のxZに置きQえる
Pad Images,,,,Pad画像
house-fareast,,,,家-|方
Sort models by,排序方式,排序方式,排序方式,
Sampling steps,采样迭代步数(Steps),采样迭代步数(Steps),采样迭代步数(Steps),サンプリングステップ数
Rembg Model,,,,Rembgモデル
https://github.com/zero01101/openOutpaint-webUI-extension.git,,,,https://github.com/zero01101/openOutpaint-webUI-extension.git
Control Mode (Guess Mode),控制干涉模式,,干涉模式,
Reapply ranking after moving files,,,移动文件后重新应用排名,ファイルを移婴筏酷幛衰楗螗ングを再m用
"Language extension allows users to write prompts in their native language and automatically translate UI, without the need to manually download configuration files. New plugins can also be translated.",,,,言ZのC能により、O定ファイルを手婴钎昆Ε螗愆`ドすることなく、母国Zでプロンプトを述し、UIを自拥膜朔Uすることができます。新しいプラグインも翻Uできます。
Refresh openOutpaint,,,,OpenOutpaint を更新
https://github.com/opparco/stable-diffusion-webui-two-shot.git,,,,https://github.com/opparco/stable-diffusion-webui-two-shot.git
"""darkseagreen""",,,"""深海绿""",
Python Plugin Manager,,,,Python プラグインマネ`ジャ`
(C2) Thertiary,,(C2) 第三,(C2) 第三,
Save Model Frequency (Epochs),,,,モデルの保存l度（エポック数）
IN_B_01,,模型B 输入层01,模型B 输入层01,
"For hires fix, use width/height sliders to set final resolution rather than first pass (disables Upscale by, Resize width/height to).",在高分辨率修复中，使用长宽滑块设置最终分辨率(恢复旧版高分辨率修复界面，关闭放大倍率和自适应分辨率设置),在高分辨率修复中，使用长宽滑块设置最终分辨率(恢复旧版高清修复界面，关闭放大倍率和自适应分辨率设置),在高分辨率修复中，使用长宽滑块设置最终分辨率(恢复旧版高清修复界面，关闭放大倍率和自适应分辨率设置),Highres fix で幅と高さのスライダ`を使い、最初のI理ではなく最K的な解像度をO定する (アップスケ`ル倍率はo郡摔胜辍⒎/高さのリサイズを行う)
CLIP Maximum length,,,,CLIPの最小L
Restore settings to default,恢复默认设置,,,O定をデフォルトにす
Image browser,图库浏览器,图库浏览器,图库浏览器,Image browser
Interrogate: deepbooru sort alphabetically,deepbooru 反推结果按字母顺序排序（不推荐开启）,deepbooru 反推结果按字母顺序排序（不推荐开启）,deepbooru 反推结果按字母顺序排序（不推荐开启）,Interrogate: deepbooruでgZをアルファベットにKべる
This page allows you to change default values in UI elements on other tabs.,,,这个页面可以改变一些页签的UI默认值,
Note that parseq overrides:,,,,パ`シ`クは以下を上きします。
built-in,内置插件,内置,内置,内iC能
ControlNet v1.1.276,扩散控制网络(ControlNet),,,
quick,快速,,,
Extra path to scan for ControlNet models (e.g. training output directory),检索扩散控制网络模型(ControlNet models)的附加目录（如训练输出目录）,检索 ControlNet 模型的附加目录（如训练输出目录）,检索 ControlNet 模型的附加目录（如训练输出目录）,ControlNet モデルをスキャンする追加のパス (例: 学rの出力ディレクトリなど)
default,,默认,默认,初期
Tiled VAE,分块 VAE(Tiled VAE)（开启后自动优化应用 VAE 时的显存占用）,分块 VAE,分块 VAE,Tiled VAE
Source denoise:,,,,ソ`スデノイズ：
LeReS Resolution,LeReS 分辨率（LeReS Resolution）,LeReS 分辨率（LeReS Resolution）,LeReS 分辨率（LeReS Resolution）,
Save Checkpoint Frequency,保存模型(ckpt)权重进度的频率,保存模型权重进度(ckpt)的频率,保存模型权重进度(ckpt)的频率,
Generate Captions,生成描述文本,生成描述文本,生成描述文本,キャプションを生成する
Number of pictures displayed on each page,每页显示的图像数量,每页显示的图像数量,每页显示的图像数量,
General Prompt,总提示词（General Prompt，控制整个画面，图片包含白色时默认将白色识别为总提示词蒙版）,,,
house-nudity,,,,家-ヌ`ド
sw,,,,sw
AddNet Model 5,[附加网络] 模块 5,[可选附加网络] 模型 5,[可选附加网络] 模型 5,モデル 5(AddNet)
The URL to the model on huggingface. Should be in the format of 'developer/model_name'.,huggingface 模型的 URL。应为 'developer/model_name' 的格式,huggingface 模型的 URL。应为 'developer/model_name' 的格式,huggingface 模型的 URL。应为 'developer/model_name' 的格式,
Enable steps scheduling,,,,ステップスケジュ`リングを有郡摔工
Lora Text Encoder Learning Rate,,,,LoRAテキストエンコ`ダの学率
"First time you enable the script, it may take a long time (around a minute), but once loaded, it will be faster.",初次启用，控制台会下载约2GB的文件，如遇下载失败，请科学上网。,,,
Borderradiusbase,Borderradiusbase,,,
Filter Apply,应用筛选条件,,,フィルタ`m用
Basis,,,,基
"(directory is hidden if its name starts with ""."")",,,（以‘.’开头的文件夹将默认为隐藏）,
Smooth:,,,,Smooth:
Envelope (Outer Fit),信封模式（裁切原图）,信封模式（裁切原图）,信封模式（裁切原图）,アウタ`フィット (余白ができない)
Free GPU,释放显存,,Free GPU,
整体上个别细节,,,整体上个别细节,
"Show live tag translation below prompt (WIP, expect some bugs)",,,在提示词下方显示标签实时翻译（公测测试中，可能会有一些错误）,
Rename images,,,,画像の名前を涓…
Delete intermediate,,运行结束后删除产生的中间步骤文件,运行结束后删除产生的中间步骤文件,
Include character tags in tag string,,在标签字串中包含角色标签,在标签字串中包含角色标签,
Generate lora weights when saving during training.,,,,トレ`ニング中に保存するときにLoRAの重みを生成します。
Merge LoRAs,LoRA间合并,,,
conjugate: Converts the content verb into another conjugated form.,,,,conjugate: コンテンツの釉~をeの活用形にQします。
img2img_batch_count,生成批次,,,
Roll three,抽三位出来,抽三位出来,抽三位出来,
H,,高,高,
Amount schedule,,,,量のスケジュ`ル
Batch Size,每批数量(Batch Size),每批数量(Batch Size),每批数量(Batch Size),バッチサイズ
lineart_anime_denoise,线稿提取（lineart 模型，针对动画，有降噪）,,线稿提取-动画-噪点/网格点优化（lineart_anime_denoise）,
Number of CLIP beams,,,,CLIPビ`ムの数
ladder,,,,ハシゴ
Sample Width,,,,サンプル幅
Generate human masks,,,,人gのマスクを生成
novelai-2-local-prompt,novelai 转 webui 括号,novelai 转 webui 括号,novelai 转 webui 括号,novelai-2-local-prompt
relu,relu,,,relu
negative_prompt,,,,ネガティブプロンプト
Drawing Canvas,创建空白画布,,,
Number,数量,数量,数量,Number
New preset name,新预设名称,,,
"When using 'Save' button, only save a single selected image",使用“保存”按钮时，只保存一个选定的图像,使用“保存”按钮时，只保存一个选定的图像,使用“保存”按钮时，只保存一个选定的图像,"""保存""ボタンを使うとき、g一のxkされた画像のみを保存する"
Tagging,开始反推（完成后请点击右侧按钮卸载模型）,,,
Don't,不复制配置文件（推荐）,不复制配置文件（推荐）,不复制配置文件（推荐）,しない
Allow Preview,开启预览,,显示预览窗口,
Click here after the generation to show the video,,生成后点这里显示视频,生成后点这里显示视频,踊を表示するには、生成後ここをクリックしてください
https://github.com/thygate/stable-diffusion-webui-depthmap-script.git,,,,https://github.com/thygate/stable-diffusion-webui-depthmap-script.git
pin_light,,,,ピンライト
Tag images,批量处理,,,
Re-process extra networks after Unprompted is finished (WIP - this is not yet functional!),,,,アンプロンプトがK了した後、追加のネットワ`クを再I理する（WIP-まだC能していません！）
default = 0.9,,,,既定 = 0.9
portrait-cartoon,,,,ポ`トレイトのカ`トゥ`ン
Show progressbar,显示进度条（建议开启）,显示进度条,显示进度条,プログレスバ`を表示
DreamArtist Create embedding,梦作家 创建 Embedding,梦作家 创建 Embedding,梦作家 创建 Embedding,ドリ`ムア`ティスト 埋めzみの作成
Choose latent sampling method,,选择潜变量的采样方法,选择潜变量的采样方法,Latentのサンプリングメゾッドをxk
Cond.fix: Highest,修复时调节：最高,修复时调节：最高,修复时调节：最高,Cond.fix: 最高
Image for inpainting with mask,用于局部重绘并手动画蒙版的图像,用于局部重绘并手动画蒙版的图像,用于局部重绘并手动画蒙版的图像,インペイントで使用する画像とマスク
Smoothing,,,,スム`ジング
Print debug logs to the console,将调试日志输出到控制台（不建议开启）,将调试日志输出到控制台,将调试日志输出到控制台,デバッグログをコンソ`ルに出力
Generate a checkpoint at the current training lvel.,生成当前训练级别的模型(ckpt)权重进度,生成当前训练级别的模型权重进度(ckpt),生成当前训练级别的模型权重进度(ckpt),
Show grid in results for web,在网页的结果中显示宫格图（建议开启）,在网页的结果中显示宫格图（建议开启）,在网页的结果中显示宫格图（建议开启）,WebUI上でグリッド表示
wd-v1-4-convnext-tagger,,,,wd-v1-4-convnext-tagger
Metadata,元数据,,,
mediums,,,,メディウム(成要素)
Interpolation,,插值,插值,ag
Put variable parts at start of prompt,把可变部分放在提示词文本的开头,把可变部分放在提示词文本的开头,把可变部分放在提示词文本的开头,プロンプトの浠する部分を先^に配置する
json path,json 文件路径,,,jsonのパス
Search string,,搜字串,搜字串,
https://github.com/yfszzx/stable-diffusion-webui-inspiration.git,,,,https://github.com/yfszzx/stable-diffusion-webui-inspiration.git
Message,信息,,,
Append,在结尾附加反推结果,,,追加
n_batch,,批次,批次,
pinpoint element,受另一个轴控制的 元素,,,
Send this image to ControlNet.,>> ControlNet,将此图像发送到 ControlNet,将此图像发送到 ControlNet,この画像を ControlNet に送信します。
Edit Openpose,编辑动作（需要至少准备 4 个 ControlNet 用于接收生成的图像）,,,
Hough Resolution,霍夫分辨率（Hough Resolution）,霍夫分辨率（Hough Resolution）,霍夫分辨率（Hough Resolution）,
Mask to find ? mask,,,,仕鳏工毳蕙攻 ? mask
ddetailer,检测细致化,检测细致化,检测细致化,
Cozy-Nest,Cozy-Nest 主题,,,
First frame as init image,,,,最初のフレ`ムを初期画像として
Light Color,,,,照明の色
beta1,beta1,,,ベ`タ1
"Auto SAM is mainly for semantic segmentation and image layout generation, which is supported based on ControlNet. You must have ControlNet extension installed, and you should not change its directory name (sd-webui-controlnet).",Auto SAM主要用于语义分割和图像布局生成，基于 ControlNet 支持。使用前必须安装 ControlNet 插件且未更改其目录名（sd-webui-controlNet）,,Auto SAM功能用于通过语义分割来产生蒙版或者图层拆分，这需要ControlNet的支持。所以使用该功能需要安装 ControlNet插件，并且不要改变插件文件夹的名字 (sd-webui-controlnet),
mt,,,,mt
"Use following tags to define how filenames for images are chosen: [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.","使用以下标签定义如何选择图像的文件名： [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]。默认请留空","使用以下标签定义如何选择图像的文件名： [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]。默认请留空","使用以下标签定义如何选择图像的文件名： [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]。默认请留空",
ControlNet v1.1.260,扩散控制网络(ControlNet),,,
"{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}","{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}",,,"{% for colour in ['red', 'blue', 'green'] %}\n        {% prompt %}I love {{ colour }} roses{% endprompt %}\n    {% endfor %}"
Output filename formats,输出文件名格式说明,输出文件名格式说明,输出文件名格式说明,出力ファイルフォ`マット
Save EMA Weights to Generated Models,,,,EMA Weightを生成されたモデルに保存
Detach grad from conditioning models,,,,条件付きモデルから勾配を切りxす
overlay,,,,オ`バ`レイ
Config file for Control Net models,扩散控制网络模型(ControlNet models)的配置文件,ControlNet 模型的配置文件,ControlNet 模型的配置文件,ControlNetモデルのO定ファイル
stable-diffusion-webui-depthmap-script,,,,stable-diffusion-webui-depthmap-script
sd-dynamic-prompts,动态提示词,动态提示词,动态提示词,sd-dynamic-prompts
txt,,,,txt
LoRA,,,,LoRA
ControlNet Segmentation Index,接收图像的 ControlNet 控制单元编号,,目标ControlNet单元编号,
Interrogate: use artists from artists.csv,使用 artists.csv 中的艺术家,反推：使用 artists.csv 中的艺术家,反推：使用 artists.csv 中的艺术家,
Use low VRAM mode? ? save_memory,,,,低VRAMモ`ドを使用しますか？→ メモリをs
Do not append detectmap to output,不输出探测模式图(detected maps)（如深度估算图、动作检测图等）,不输出探测模式图(detected maps)（如深度估算图、动作检测图等）,不输出探测模式图(detected maps)（如深度估算图、动作检测图等）,食訾丹欷骏蕙氓驻虺隽Δ俗芳婴筏胜
Remove All,,移除所有,移除所有,すべて削除
"In Keyframes tab, you can also set",,,,「キ`フレ`ム」タブでもO定できます
"When adding to prompt, refer to Lora by",,,当添加到提示词时，引用,
tanhshrink,tanhshrink,,,tanhshrink
The beta1 parameter for the Adam optimizer.,Adam 优化器的 beta1 参数,Adam 优化器的 beta1 参数,Adam 优化器的 beta1 参数,
db-storage1111,,,,db-storage1111
Source Denoise,,,,ソ`スデノイズ：
ControlNet v1.1.280,扩散控制网络(ControlNet),,,
Show verbose debug info at console,在控制台中输出详尽的调试信息,在控制台中输出详尽的调试信息,在控制台中输出详尽的调试信息,
TEnc Weight 3,Text Encoder 权重 3,Text Encoder 权重 3,Text Encoder 权重 3,TEncの重み3
fill up,,,,上に
filename keyword,搜索文件名关键字（按回车开始检索）,搜索文件名关键字（按回车开始检索）,搜索文件名关键字（按回车开始检索）,ファイル名 キ`ワ`ド
Tag one image,单张图片,,,
Refresh data,刷新数据,刷新数据,刷新数据,
Zoom in/out,,,缩放,
Stable-Diffusion-Webui-Civitai-Helper,C站助手(Civitai Helper),C站助手(Civitai Helper),C站助手(Civitai Helper),
Whole picture,全图,全图,全图,画像全体
Blend factor max,,,,ブレンドS数の最大
Batch Length As Row,,,,行のバッチL
Render hands with Openpose? ? openpose_hands,,,,Openposeでハンドをレンダリングしますか？? openpose_hands
IN_A_10,,模型A 输入层10,模型A 输入层10,
Textbox,文本框,文本框,文本框,テキストボックス
"Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.",,,,xkしたパラメ`タでyamlファイルをBし、o限次元グリッドを生成します。フィ`ルドにh明テキストを追加するMみzみC能です。使用方法については、readmeを参照してください。
Lets you edit captions in training datasets.,让你可以在这里编辑训练数据集的描述文本,让你可以在这里编辑训练数据集的描述文本,让你可以在这里编辑训练数据集的描述文本,
cards,卡牌视图,卡牌视图（大预览图，竖图，占用页面空间非常大）,卡牌视图（大预览图，竖图，占用页面空间非常大）,カ`ド
Restart Krita.,,,,Kritaを再起婴筏蓼埂
(in megapixels),,,（百万像素）,
Show extra options,显示额外设置,显示额外设置,显示额外设置,
settings,设置,,,
Is negative text,是负面提示词,是反向提示词,是反向提示词,ネガティブテキスト
mg,,,,mg
k_sigma,,,,k_sigma
Refresh models,刷新模型列表,刷新模型列表,刷新模型列表,モデルを更新
Save preview,,,,プレビュ`を保存
.txt (on Load and Save),,,,.txt (iみzみと保存r)
Join the official Deforum Discord discord.gg/deforum to share your creations and suggestions,,加入官方 Deforum 的 Discord discord.gg/deforum 分享您的创作和建议,加入官方 Deforum 的 Discord discord.gg/deforum 分享您的创作和建议,
Common Tags,共有 Tag,,,共通のタグ
if,,,,もし
XavierNormal,Xavier 正态,Xavier 正态,Xavier 正态,Xavier正分布
Save PNGinfo to grid,将生成参数写入宫格图（可用图片信息直接识别宫格图）,将生成参数写入宫格图（可用图片信息直接识别宫格图）,将生成参数写入宫格图（可用图片信息直接识别宫格图）,
default = 0.01,,,,既定 = 0.01
(Full = slow but pretty; Approx NN and TAESD = fast but low quality; Approx cheap = super fast but terrible otherwise),,,（Full = 预览质量好，但是慢；Approx NN和TAESD = 快速但质量低；Approx cheap = 超级快但预览效果糟糕）,
90 Degree Rotation,90度旋转,90度旋转,90度旋转,90度回
seed_travel,种子变迁,种子变迁,种子变迁,seed_travel
"and restart webui, and enjoy the joy of creation!",,,,作の喜びを摔筏皮ださい!
Inter Denoise FPD,,,,Inter Denoise FPD
Import favicons (svg),导入 网页图标（SVG格式）,导入 网页图标（SVG格式）,导入 网页图标（SVG格式）,
by,,,,作成者:
AdamW epsilon parameter,,,,AdamW epsilon パラメ`タ
XavierUniform,Xavier 均匀,Xavier 均匀,Xavier 均匀,Xavier一分布
(0 = default (~14.6); maximum noise strength for k-diffusion noise schedule),,,（0 = 默认值（~14.6）；k-diffusion噪声调度器的最大噪声强度）,
tp__yandex,,,,tp__yandex
gpu,显卡,,,
Show Preview,显示预览,,,
Max Caption Length (0=unlimited),,,,キャプションの最大L(0=o制限)
Gradio theme,,,Gradio主题,
Convert Unet to ONNX,,,将Unet转换到ONNX,
folder and copy the folder location from the address bar.,,,,アドレスバ`からフォルダの鏊をコピ`します。
Comma separated list. Specify ckpt OR ckpt:word,以逗号分割的列表。用以指定 ckpt 或 ckpt:字词,以逗号分割的列表。用以指定 ckpt 或 ckpt:字词,以逗号分割的列表。用以指定 ckpt 或 ckpt:字词,
by AUTOMATIC1111,,来自 AUTOMATIC1111,来自 AUTOMATIC1111,
Reset Tile Size,重设图块尺寸(Tile Size),重设图块尺寸(Tile Size),重设图块尺寸(Tile Size),タイルサイズをリセット。
Sort tags in the images displayed.,对当前显示图像的 Tag 进行排序,,,表示されている画像のタグをKべ替えます。
Search for hypernetworks,检索 超网络(Hypernetwork),搜索 超网络(Hypernetwork),搜索 超网络(Hypernetwork),Hypernetworksを仕
Run on incomplete,,不等到结束时才生成 (中途停止也会基于已有的结果生成动画),不等到结束时才生成 (中途停止也会基于已有的结果生成动画),
Background threshold,背景阈值,,背景阈值,後景しきい
Enable checkpoint scheduling,,,,Checkpointのschedulingを有炕
Run DFI,,,,Run DFI
Tag range:,,,,タグレンジ
Class Prompt,类(Class)提示词,类(Class)提示词,类(Class)提示词,クラスプロンプト
prompt travel,提示词变迁,提示词变迁,提示词变迁,prompt travel
Composable LoRA with step,启用动态调度支持（允许 LoRA 使用 “[tag1:tag2:step]” 的动态调度语法）,,,
: Output extension (has no dot),：输出文件的后缀（不含 . ）,：输出文件的后缀（不含 . ）,：输出文件的后缀（不含 . ）,": 出力ファイルの子 (""."" なし)"
Active in txt2img (Requires restart),在文生图页面启用（需要保存设置并重启）,在文生图页面启用（需要保存设置并重启）,在文生图页面启用（需要保存设置并重启）,txt2imgで有 (再起婴必要)
Paths for saving,保存路径,保存路径,保存路径,保存するパス
Related to original file,与原文件相关的命名参数,与原文件相关的命名参数,与原文件相关的命名参数,オリジナルファイルにvB
"Torch active: Peak amount of VRAM used by Torch during generation, excluding cached data.\nTorch reserved: Peak amount of VRAM allocated by Torch, including all active and cached data.\nSys VRAM: Peak amount of VRAM allocation across all applications / total GPU VRAM (peak utilization%).",Torch active： 在生成过程中，Torch使用的显存(VRAM)峰值，不包括缓存的数据。\nTorch reserved： Torch 分配的显存(VRAM)的峰值量，包括所有活动和缓存数据。\nSys VRAM： 所有应用程序分配的显存(VRAM)的峰值量 / GPU 的总显存(VRAM)（峰值利用率%）,Torch active： 在生成过程中，Torch使用的显存(VRAM)峰值，不包括缓存的数据。\nTorch reserved： Torch 分配的显存(VRAM)的峰值量，包括所有活动和缓存数据。\nSys VRAM： 所有应用程序分配的显存(VRAM)的峰值量 / GPU 的总显存(VRAM)（峰值利用率%）,Torch active： 在生成过程中，Torch使用的显存(VRAM)峰值，不包括缓存的数据。\nTorch reserved： Torch 分配的显存(VRAM)的峰值量，包括所有活动和缓存数据。\nSys VRAM： 所有应用程序分配的显存(VRAM)的峰值量 / GPU 的总显存(VRAM)（峰值利用率%）,
R-ESRGAN 4x+ Anime6B,R-ESRGAN 4x+ Anime6B,,R-ESRGAN 4x+ Anime6B（新手动漫向首选）,R-ESRGAN 4x+ Anime6B
Use an,,,,を使う
haw,,,,haw
Create,创建,创建,创建,作成
Directly Draw Scribbles,直接绘制草图,,,
Run benchmark,开始基准评估,跑分,跑分,ベンチマ`クをg行
x4,,,,x4
Split over-sized images,分割过大的图像,分割过大的图像,分割过大的图像,
A tab with the full openOutpaint UI. Run with the --api flag.,,,,完全な openOutpaint UI を持つタブ。--api フラグを付けてg行します。
Model directory,模型目录,模型目录,模型目录,
Decoder Tile Size,解码器图块尺寸(Decoder Tile Size),解码器图块尺寸(Decoder Tile Size),解码器图块尺寸(Decoder Tile Size),デコ`ダ`のタイルサイズ
tp__google,,,,tp__google
Append interrogated prompt at each iteration,,,,ル`プごとにInterrogateによるプロンプトを末尾に加える
Both,全部,全部,全部,I方
hidden_s_or_n,hidden_s_or_n,,,hidden_s_or_n
Batch from directory,批量操作,批量操作,批量操作,ディレクトリから一括I理
IN_B_08,,模型B 输入层08,模型B 输入层08,
"Passing ControlNet parameters with ""Send to img2img""",将图像发送至图生图时一并传递ControlNet设置,使用“发送到图生图”传递ControlNet参数,使用“发送到图生图”传递ControlNet参数,「img2imgに送」でControlNetのパラメ`タを渡す
Yes,是,是,是,Yes
": Symlinks will break if you move or rename the repository or any\nof its parent folders or otherwise change the path such that the symlink\nbecomes invalid. In which case, repeat the above steps with the new",,,,: リポジトリまたはそのHフォルダの移婴涿前涓、シンボリックリンクがo郡摔胜毪瑜Δ圣靴工涓をした龊悉恕シンボリックリンクが菠欷皮筏蓼い蓼埂辘筏郡龊悉稀⑿陇筏ぅ靴工巧嫌の手を再度g行してください。
cfg scale,提示词相关性(CFG Scale),提示词相关性(CFG Scale),提示词相关性(CFG Scale),CFGスケ`ル
Backup/Restore,备份与恢复,,备份/还原,
M00,,中间层,中间层,
for: It's a for loop.,,,,for: forル`プです。
Interrogate,开始反推,开始反推,开始反推,インタロゲ`ト
Found tags,高于最低置信度阈值的tag将会被摘录至此处,找到的标签(tags),找到的标签(tags),つかったタグ
Segmentation status,执行状态,,分割处理状态,
Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.,,,,背景を自婴浅去します。アニメ画像用に微{整されたonnxモデルを使用します。GPUで幼鳏筏蓼埂
word masks,,,,ワ`ドマスク
CFG-Schedule-for-Automatic1111-SD,,,,CFG-Schedule-for-Automatic1111-SD
* change 'type' to clear/reload dropdowns.,改变坐标轴类型可清空、刷新选项,改变坐标轴类型可清空、刷新选项,改变坐标轴类型可清空、刷新选项,
Layers,,,,レイヤ`
Tag count filter,,,,タグカウントフィルタ`
change X-Y,交换XY轴内容,,,
file not found: None,未检索到模型,未检索到模型,未检索到模型,
Z values,Z轴值,Z轴值,Z轴值,ZSの
Use online version,使用在线版本,,,
Controlnet input directory,,,Controlnet输入目录,
正w中文Z言包,繁体中文语言包,,,
Selected Tags,已选择的 Tag,,,xkしたタグのみ
"If you want to use Width/Height which are not multiples of 64, please change noise_type to 'Uniform', in Keyframes --> Noise.",,,,64の倍数ではない幅/高さを使用する龊悉稀Keyframes--> Noiseでnoise_typeを「Uniform」に涓してください。
no_NO Localization,,,,no_NO 翻U
pre-depth background removal,,,,プレデプス背景除去
Maintenance,维护,维护,维护,メンテナンス
Copyright Tags,,版权标签(Tags),版权标签(Tags),
Strict Tokens,,,,密なト`クン
right-to-left,,,,右から左へ
stable-diffusion-webui-blip2-captioner,,,,stable-diffusion-webui-blip2-captioner
"If you are using these templates, please let me know if they are useful.",如果你在用这些模板，请告诉我它们是否有用,如果你在用这些模板，请告诉我它们是否有用,如果你在用这些模板，请告诉我它们是否有用,これらのテンプレ`トを使っている方は、役に立っているかどうか教えてください。
If Empty,仅无注释时,,,空の龊
ControlNet v1.1.185,扩散控制网络(ControlNet),,,
Get Model Info from Civitai,从 Civitai 获取模型信息,从Civitai获取模型信息,从Civitai获取模型信息,
Apply changes to ALL displayed images,将更改应用于当前所有显示的图像,,,表示されているすべての画像に涓をm用
Generated frames folder,,,,生成したフレ`ムフォルダ
G,,,,G
Model_A,模型A,模型A,模型A,
All models in this directory will receive the selected model's metadata,此目录下所有模型都将被粘贴与选中模型完全相同的元数据,此目录下所有模型都将被粘贴与选中模型完全相同的元数据,此目录下所有模型都将被粘贴与选中模型完全相同的元数据,このディレクトリ内のすべてのモデルはxkされたモデルのメタデ`タを受け取る
pndm,pndm,,,
Operation to perform at the end step ? str,,,,最後のステップでg行する操作 ? str
sd-webui-segment-anything,Segment Anything 蒙版绘制插件,,,
Always save all generated image grids,始终保存所有生成的宫格图,始终保存所有生成的宫格图,始终保存所有生成的宫格图,グリッド画像を常に保存する
stable-diffusion-webui-auto-translate-language,自动翻译插件,,,stable-diffusion-webui-auto-translate-language
Threshold B,阈值B（此值根据预处理器选项不同发生变化，滑动条不可用时代表此预处理器无该项设置）,阈值B（此值根据预处理器选项不同发生变化，滑动条不可用时代表此预处理器无该项设置）,阈值B（此值根据预处理器选项不同发生变化，滑动条不可用时代表此预处理器无该项设置）,しきい B
portrait-special,,,,肖像画-特e
Run preprocessor,,,开始预处理,
tp_sogou,,,,tp_sogou
"Cheap neural network approximation. Very fast compared to VAE, but produces pictures with 4 times smaller horizontal/vertical resolution and lower quality.",,,,易NNモデル：VAEと比べ高速だが、水平/垂直解像度が４倍小さく、画像品|が低い。
Train,训练,训练,训练,学
Put weight sets. float number x 25,输入权重，共25个浮点数，逗号分隔,输入权重，共25个浮点数，逗号分隔,输入权重，共25个浮点数，逗号分隔,
Save Video Settings,,保存视频设置,保存视频设置,踊のO定を保存
x0_pred,,,,x0_pred
Show result images,显示输出图像,显示输出图像,显示输出图像,出力画像を表示
Copy,,,,コピ`
gif,gif,,,
Image for GroundingDINO,需要使用 GroundingDINO 处理的图像,,GroundingDINO识别的结果,
URL for extension's git repository,扩展的 git 仓库网址,扩展的 git 仓库网址,扩展的 git 仓库网址,C能のリポジトリのURL
Licenses,证书,许可协议,许可协议,ライセンス
img2img_steps,采样迭代步数(Steps),,,
Heun,Heun,,,Heun
>,>,,,
Training steps,训练迭代步数,训练迭代步数,训练迭代步数,
×,×,,,
Number of frames for lead in/out,渐入/渐出帧数,渐入/渐出帧数,渐入/渐出帧数,リ`ドイン/アウトのフレ`ム数
openpose_faceonly,姿态检测（openpose 模型，OpenPose 算法，仅脸部）,,姿态检测（OpenPose 算法，仅脸部）,
darken,,,,比^ 暗
"Uses a trained model file, produces WD 1.4 Tags. Model link - https://mega.nz/file/ptA2jSSB#G4INKHQG2x2pGAVQBn-yd_U5dMgevGF8YYM9CR_R1SY",使用经过训练的模型文件，生成 Waifu Diffusion 1.4 标签。模型链接 - https://mega.nz/file/ptA2jSSB#G4INKHQG2x2pGAVQBn-yd_U5dMgevGF8YYM9CR_R1SY,使用经过训练的模型文件，生成 Waifu Diffusion 1.4 标签。模型链接 - https://mega.nz/file/ptA2jSSB#G4INKHQG2x2pGAVQBn-yd_U5dMgevGF8YYM9CR_R1SY,使用经过训练的模型文件，生成 Waifu Diffusion 1.4 标签。模型链接 - https://mega.nz/file/ptA2jSSB#G4INKHQG2x2pGAVQBn-yd_U5dMgevGF8YYM9CR_R1SY,
Save JSON,储存为 JSON文件,储存为 JSON文件,储存为 JSON文件,JSONを保存
Leave empty for default main branch,留空默认安装主分支,,留空的话就使用默认分支,
Perlin W,,,,Perlin W
dog-black-white,,,,犬-白\
Uses D-Adaptation(LR Free) AdamW. Recommended LR is 1.0 at base,,,,D-Adaptation(LR Free) AdamWを使用中。 baseではLR 1.0が推Xされています。
Enable Region 2,启用此区域,,启用区域 2,
ControlNet v1.1.146,扩散控制网络(ControlNet),,,
Prior Loss Weight,先验损失权重(Prior Loss Weight),先验损失权重(Prior Loss Weight),先验损失权重(Prior Loss Weight),正t化のp失の重み
Edit common tags.,编辑共有 Tag,,,共通のタグを集
do: It's a do-until loop.,,,,do: do-untilル`プです。
Colorbgmask,Colorbgmask,,,
ControlNet v1.1.199,扩散控制网络(ControlNet),,,
Class prompt,类(Class)提示词,类(Class)提示词,类(Class)提示词,
(so they are used as literal brackets and not for emphasis),,,（这样它们就被用作字面意义上的括号，而不是用于强调）,
Preview image negative prompt,预览图负面提示词,预览图反向提示词,预览图反向提示词,
Made by,,,,作成者
Add Lora to prompt,将 LoRA 添加到提示词,将 LoRA 模型添加到提示词,将 LoRA 模型添加到提示词,プロンプトに LoRA を追加
Negative strength,,,,ネガティブの度
training-picker,训练图挑选器,训练图挑选器,训练图挑选器,training-picker
"Please, change animation mode to 2D or 3D to enable Hybrid Mode",,,,ハイブリッドモ`ドを有郡摔工毪摔膝ニメ`ションモ`ドを2Dまたは3Dに涓してください
Save background instead of foreground,仅保存背景而非前景,,保存背景而不是前景,
Install,安装,安装,安装,インスト`ル
Asymmetric Tiling,,,,Asymmetric Tiling
Scale to maximum width or height,,,,最大幅または高さに合わせる
Save as half,以 float16 保存,以 float16 保存,以 float16 保存,
prompt,,,,プロンプト
Model list will be output here,模型列表将会在此处输出,模型列表将会在此处输出,模型列表将会在此处输出,
Disable SAM functionality and upload manually created mask to ControlNet inpaint.,禁用 Segment Anything Model 功能并将手动创建的蒙版上传到 ControlNet 进行局部重绘,,禁用SAM所有功能手动上传蒙版到ControlNet,
Freeze CLIP Normalization Layers,,,,CLIP正化レイヤ`を固定
Modules,模块,模块,模块,モジュ`ル
Checkbox,勾选框,勾选框,勾选框,チェックボックス
SD upscale,使用 SD 放大(SD upscale),使用 SD 放大(SD upscale),使用 SD 放大(SD upscale),SDアップスケ`ル
Calculate training parameters for a human subject. Enables prior preservation.,计算训练人物主体需要的参数。并启用先验存留(prior preservation),计算训练人物主体需要的参数。并启用先验存留(prior preservation),计算训练人物主体需要的参数。并启用先验存留(prior preservation),
"performance is measured in iterations per second (it/s) and reported for different batch sizes (e.g. 1, 2, 4, 8, 16...)",性能以每秒迭代次数 (it/s) 衡量，并针对不同的批量大小（例如 1、2、4、8、16 ...）进行报告,,,
Retouch,修饰(Retouch),,,
https://github.com/ilian6806/stable-diffusion-webui-state.git,,,,https://github.com/ilian6806/stable-diffusion-webui-state.git
seg_ofcoco,语义分割（seg 模型，OneFormer 算法，COCO 协议）,,语义分割（seg，OneFormer 算法，COCO 协议）,
Half Cosine Down,半区间余弦递减(Half Cosine Down),,,
digipa-high-impact,,,,digipaハイインパクト
Location,,,,鏊
Colorerrortexthover,Colorerrortexthover,,,
"Tile overlap, in pixels for SCUNET upscalers. Low values = visible seam.",,,使用SCUNET upscalers时Tile size间的重叠，此值较低的话可能会有明显接缝,
Use negative embedding (DreamArtist),使用负面 Embedding (梦作家),使用反向 Embedding (梦作家),使用反向 Embedding (梦作家),
ControlNet v1.1.281,扩散控制网络(ControlNet),,,
Path name modifier,,,,パス名の修子
HeunDiscrete,,,,HeunDiscrete
-75%,,,,-75%
(C5) Thertiary,,(C5) 第三,(C5) 第三,
Lora Model,,,,LoRA モデル
Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.,,,,カスタマイズ可能な拥拈を追加することで、きzみやポップア`ト抗なしに高いCFG Scaleを可能にします。
BLIP: maximum description length,,,BLIP: 最大描述长度,
t2ia_sketch_pidi,草稿差分（t2iadapter_sketch 模型，PiDiNet 算法）,,t2ia自适应 - 草稿像素差分处理（sketch_pidi）,
Classify type,,,,分のNe
stable-diffusion-webui-images-browser,图库浏览器,图库浏览器,图库浏览器,stable-diffusion-webui-images-browser
API Keys,,API 密钥,API 密钥,
Cutoff and Power,,,,カットオフとパワ`
Settings > Manage Resources...,,,,O定 > リソ`スの管理
replace preview,用当前生成图片替换预览,用当前生成图片替换预览,用当前生成图片替换预览,プレビュ`を置Q
Download system info,,,下载系统信息,
Highres. percentage chance,高清修复：随机概率,高清修复：随机概率,高清修复：随机概率,高解像度のパ`センテ`ジ_率
casing: Converts the casing of content.,,,,casing: コンテンツの大文字と小文字をQします。
Data directory,,,,デ`タ保存用フォルダ`
IN_B_00,,模型B 输入层00,模型B 输入层00,
[hash:sha1].[output_extension],,,,[hash:sha1].[output_extension]
"Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.",,,,"モデルをfp16/bf16 no-ema/ema-only からxkし.safetensor形式にQします。モデルのいずれかの部分をQ/コピ`/削除します: unet, text encoder(clip), vae."
Interrogate Options,提示词反推,反推提示词（图生图页面）,反推提示词,InterrogateO定
Background Color,,,,背景色
Switch background color by clicking the Enable buttons in SD Web UI,,,,SD Web UIの「有炕」ボタンをクリックして背景色を切り替える
Subseed schedule,,,,サブシ`ドのスケジュ`ル
Preset Weights,预设权重,预设权重,预设权重,
This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.,,,,このC能は画像をブロックにQし、Litematica modを使用してMinecraftにgにインポ`トできる回路恧蜃鞒嗓筏蓼埂
scale ratio,,,缩放比例,
LLuL Enabled,,,,LLuLを有炕
Use legacy weights ? legacy_weights,,,,^去の重み付けを使用する ? legacy_weights
Eta,Eta,,,Eta
Path to image file ? str,,,,画像ファイルへのパス <unk> str
Last message,,,最近的信息,前回のメッセ`ジ
Invert colors if your image has white background.,"使用白色背景图片时请启用""反色模式""","使用白色背景图片时请启用""反色模式""","使用白色背景图片时请启用""反色模式""",白背景の龊稀⑸を反する
BS,,,,BS
Regions,分区,分区,分区,I域
Video frames,,,,Video frames
Write all generated prompts to a file,将所有生成的提示词写入文件,将所有生成的提示词写入文件,将所有生成的提示词写入文件,生成されたすべてのプロンプトをファイルにきzむ
Step count (grad mode),步数 (梯度模式),步数 (梯度模式),步数 (梯度模式),
File name to save setting as,,,,O定を保存するファイル名
or,或,或,或,
- Adjust brush size,,,- 调整画笔大小,
set,,,,set
ControlNet v1.1.2,扩散控制网络(ControlNet),,,
512x Model,,,,512x モデル
"weights,for beta, base beta,IN00,IN02,...IN11,M00,OUT00,...,OUT11",各层 β 权重,,,
Y values,Y轴值,Y轴值,Y轴值,YSの
Aesthetic imgs embedding,美术风格图集 Embedding,美术风格图集 Embedding,美术风格图集 Embedding,美的埋めzみを使用する
Generated Caption,,,,生成されたキャプション
"Use following tags to define how subdirectories for images and grids are chosen: [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.","使用以下标签定义如何选择图像和宫格图的子目录： [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]。默认请留空","使用以下标签定义如何选择图像和宫格图的子目录： [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]。默认请留空","使用以下标签定义如何选择图像和宫格图的子目录： [steps], [cfg], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]。默认请留空",
Join the,,,,参加する
[ControlNet] Pre Threshold B,[ControlNet] 预处理器 阈值B,[ControlNet] 预处理器 阈值B,[ControlNet] 预处理器 阈值B,[ControlNet] 事前しきいB
number of seed,随机种子(seed),,,
(M9) Multiplier,,(M9) 倍率,(M9) 倍率,
GroundingDINO + Segment Anything can achieve [text prompt]->[object detection]->[segmentation],GroundingDINO + Segment Anything 可以实现[文本提示]->[对象检测]->[分割]的过程,,GroundingDINO+分割万物可以实现[文本提示词]->[物体识别]->[分割蒙版]过程,
Diffusion Weights (training snapshots),,,,Diffusion ウェイト (トレ`ニングrのスナップショット)
ControlNet v1.1.128,扩散控制网络(ControlNet),,,
Enable Region 5,启用此区域,,启用区域 5,
LLuL Max steps,,,,LLuL最大ステップ
Move VAE to GPU (if possible),尽可能将 VAE运算 转移到GPU,,在GPU中加载VAE,
"A, B or C","A, B或C","A, B或C","A, B或C",A、BまたはC
7 units,,,启用了7个单元,
Output directory,输出目录,输出目录,输出目录,出力ディレクトリ
Iterate seed every line,每行输入都换一个随机种子,每行输入都换一个随机种子,每行输入都换一个随机种子,1行ごとにシ`ドを1やす
bilinear,,,,bilinear
Search and Replace in,检索范围,,,～で仕鳏筏浦Qします。
ur,,,,ur
Apply changes to filtered images,将更改应用于筛选出的图像,,,フィルタリングされた画像に涓をm用する
set: Stores a value into a given variable.,,,,set: 指定された涫にを格{します。
enable_multi_images,,,,enable_multi_images
Pruning Methods,压缩方案,压缩方案,压缩方案,
Specify the amount that you wish to expand the mask by (recommend 30),,,蒙版外扩的像素（推荐30）,
weird,,,,奇妙
Detection Detailer,检测细致化,检测细致化,检测细致化,Detection Detailer
ControlNet v1.1.190,扩散控制网络(ControlNet),,,
mask image:,蒙版图像,,蒙版,マスク画像:
sd-webui-3d-open-pose-editor,3D Openpose 编辑器插件,,,
AddNet TEnc Weight 2,[附加网络] Text Encoder 权重 2,[可选附加网络] Text Encoder 权重 2,[可选附加网络] Text Encoder 权重 2,TEncの重み 2(AddNet)
tp__iciba,,,,tp__iciba
border,,边框,边框,ボ`ダ`
GroundingDINO Model (Auto download from huggingface),GroundingDINO 模型（自动从 huggingface 下载）,,GroundingDINO模型(如果没有将从huggingface下载),
sd-webui-tome,"词元合并加速(Token Merging, ToMe)插件",,,
Exported Text,导出文本,,,
Import a model from Huggingface.co instead of using a local checkpoint.,从 Huggingface.co 导入模型而非使用本地的 Stable Diffusion 模型(ckpt),从 Huggingface.co 导入模型而非使用本地的模型(ckpt),从 Huggingface.co 导入模型而非使用本地的模型(ckpt),
digipa-med-impact,,,,digipaハイインパクト
System,系统,系统,系统,システムO定
ControlNet v1.1.187,扩散控制网络(ControlNet),,,
How to use,使用方法,,,
AddNet Model 3,[附加网络] 模块 3,[可选附加网络] 模型 3,[可选附加网络] 模型 3,モデル 3(AddNet)
OUT_A_05,,模型A 输出层05,模型A 输出层05,
Max magic prompt length,魔法提示词最大长度,魔法提示词最大长度,魔法提示词最大长度,Magic prompt の最大L
Move,,,,移
ControlNet v1.1.287,扩散控制网络(ControlNet),,,
UniPC skip type,UniPC 跳过形式,UniPC 采样跳过类型 (t_uniform适合512及更高分辨率；logSNR适合低分辨率，否则会出现不合理的细节；t_quadratic略好于logSNR),UniPC 采样跳过类型 (t_uniform适合512及更高分辨率；logSNR适合低分辨率，否则会出现不合理的细节；t_quadratic略好于logSNR),UniPC スキップのN
spaceship-scribbles,,,,宇宙船 落き
Enable Region 3,启用此区域,,启用区域 3,
ExtraNetwork default card size,附加网络缩略图默认大小,,,
Generates anime tags using databases and models for tokenizing.,,,,デ`タベ`スやモデルを使ってアニメのタグを生成し、ト`クン化する。
zh_Hans Localization,,,,zh_Hans Localization
Sort LoRA models by,LoRA 模型的排序方式,LoRA 模型的排序方式,LoRA 模型的排序方式,LoRAのKび替え
"(ENSD; does not improve anything, just produces different results for ancestral samplers - only useful for reproducing images)",,,（ENSD这个参数并不会改善什么，它会影响先祖采样的结果，大多数情况它被用来重现图片）,
"Will show your current sd model selected. Also showing if you are idle, or generating something - in that case, total image/s being generated.",,,,ステ`タスに、F在xkされているsdのモデルが表示されます。また、アイドル状Bであるか、何かを生成しているか（その龊稀⒚毪たりの生成枚数）も表示されます。
Scribble Mode (Invert colors),涂鸦模式（反色，强制预处理器重新识别）,涂鸦模式（反色，强制预处理器重新识别）,涂鸦模式（反色，强制预处理器重新识别）,
ControlNet v1.1.210,扩散控制网络(ControlNet),,,
ControlNet v1.1.289,扩散控制网络(ControlNet),,,
Exclude tags (split by comma),排除以下标签(逗号分隔),排除以下标签(逗号分隔),排除以下标签(逗号分隔),除外タグ (カンマで区切る)
Inter Blur:,,,,Inter Blur:
Token merging ratio for high-res pass,,,高清修复Token合并率,
[ControlNet] Guidance Strength,[ControlNet] 引导强度,[ControlNet] 引导强度,[ControlNet] 引导强度,
LLuL Upscaler AA,,,,LLuLアップスケ`ラ`AA
OUT_A_00,,模型A 输出层00,模型A 输出层00,
Accent Generate Button,高亮 “生成” 按钮,,,
IN_B_09,,模型B 输入层09,模型B 输入层09,
+50%,,,,+50%
end at this step,结束分区的迭代步数(steps)（建议设为150）,迭代止步于,迭代止步于,このステップでK了
ca,,,,ca
Guidance strength (T),引导强度（Guidance strength）,引导强度（迭代参与%，Guidance strength）,引导强度（迭代参与%，Guidance strength）,
https://github.com/Maurdekye/training-picker.git,,,,https://github.com/Maurdekye/training-picker.git
Refresh wildcards,,,,ワイルドカ`ドの一Eを更新する
Prompt (press Ctrl+Enter or Alt+Enter to generate),提示词（按 Ctrl+Enter 或 Alt+Enter 生成）\nPrompt,提示词（按 Ctrl+Enter 或 Alt+Enter 生成）\nPrompt,提示词（按 Ctrl+Enter 或 Alt+Enter 生成）\nPrompt,プロンプト (Ctrl+Enter か Alt+Enter を押して生成)
Denoising strength for face images,,,面部重绘幅度,
Refresh TAC temp files,,,刷新“Tag自动填充”临时文件,
Separate values for Y axis using commas.,使用逗号分隔 Y 轴的值,使用逗号分隔 Y 轴的值,使用逗号分隔 Y 轴的值,"YSに用いるをカンマ(,)で区切って入力してください。"
"Scanning takes time, just wait. Check console log for detail",扫描用时较长，开始扫描后，请打开控制台以获得详细信息和日志，如遇报错，请先访问C站网页确认C站是否崩溃，C站恢复访问后，可再次开始扫描，扫描继承之前的进度，其他详细信息见插件GitHub页面,请稍等，扫描会持续一段时间，请在控制台查看详细信息。,请稍等，扫描会持续一段时间，请在控制台查看详细信息。,
Hide caption,,,,キャプションを非表示にする
Flatfile,,纯文字文件,纯文字文件,
ControlNet v1.1.136,扩散控制网络(ControlNet),,,
Prompt Fusion,,,提示词融合,
stable-diffusion-webui-daam,,,,stable-diffusion-webui-daam
Vector,向量,向量,向量,ベクトル
Copy Metadata,开始复制元数据,开始复制元数据,开始复制元数据,メタデ`タをコピ`
enter any additional notes,输入附加说明,,,
Ending index of the substring ? end,,,,部分文字列の末尾インデックス ? end
Euler a,Euler a,,,Euler a
COMMANDLINE_ARGS,,,,COMMANDLINE_ARGS
2D or 3D animation_mode,,,,2D または 3D アニメ`ションモ`ド
https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git,,,,https://github.com/toriato/stable-diffusion-webui-wd14-tagger.git
Other Setting,其他设置,其他设置,其他设置,
up,上,上,上,上
1. Get Model Info by Civitai Url,1.使用 Civitai 链接获取模型信息,1. 从网址获取模型信息,1. 从网址获取模型信息,
framesync.xyz,,,,framesync.xyz
Fps. 0=Original,,,,Fps. 0=Original
Select components to hide,选择需要隐藏的选项,,选择要隐藏的组件,非表示にするコンポ`ネントをxk
The seed to use when generating samples. Set to -1 to use a random seed every time.,生成样本时使用的随机种子。设置为 -1 时每次都使用随机的种子,生成样本时使用的随机种子。设置为 -1 时每次都使用随机的种子,生成样本时使用的随机种子。设置为 -1 时每次都使用随机的种子,
Optical Flow,,,,オプティカルフロ`
Classification CFG Scale,分类提示词相关性(Classification CFG scale),分类提示词相关性(Classification CFG scale),分类提示词相关性(Classification CFG scale),分CFGスケ`ル
OUT09,,输出层09,输出层09,
Update Extension and Restart,,,,C能を更新して再起
txt2mask,,,,txt2mask
Input,,,,入力
Contrast schedule,,,,コントラストのスケジュ`ル
Area 2 Weight,蒙版 2 的权重(Weight),,,
EMA (nagetive),EMA (负),EMA (负),EMA (负),EMA（ネガティブ）
Cond.fix: Lowest,修复时调节：最小,修复时调节：最小,修复时调节：最小,Cond.fix: 最低
Prepend,前置反推结果,,,先^に加える
Enable webcam,,,打开摄像头,
Cardssize,卡片尺寸（附加网络面板）,卡片尺寸（附加网络面板）,卡片尺寸（附加网络面板）,
Token Merging - Stride Y,步幅 Y,,,
"(0=disable, higher=faster)",,,（0=关闭，此参数越高速度也越快）,
Color sketch inpainting,,,,インペイントで使用するカラ`スケッチ
Editing Enabled,开启元数据编辑,开启元数据编辑,开启元数据编辑,集が有
house-special,,,,家-特e
(Optional) Path to directory with classification/regularization images,（可选）带有分类/规范化图像的目录路径,（可选）带有分类/规范化图像的目录路径,（可选）带有分类/规范化图像的目录路径,（オプション）分/正化画像が含まれるディレクトリへのパス
script,脚本,脚本,脚本,スクリプト
(in pixels),,,（单位：像素）,
both,全部恢复,,两者全部,
ControlNet v1.1.215,扩散控制网络(ControlNet),,,
Translated Text,译文,,,翻Uされた文字列
Training,训练,训练,训练,学
Color,,,,色{a正
Card height for Extra Networks,,,附加网络卡片高度,
gray,,,,グレ`
Find the first index of the following value(s) ? _find,,,,次のの最初のインデックスをつける <unk> _find
hash,哈希值,哈希,哈希,ハッシュ
(B4) Secondary,,(B4) 第二,(B4) 第二,
Comment ? str,,,,コメント ? str
Anti Blur,,,,アンチブラ`
Full res mask padding,,,,フル解像度マスク パディング
Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.,,,,Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.
Never,,,从不,
openOutpaint-webUI-extension,,,,openOutpaint-webUI-extension
Hybrid Video,,,,ハイブリッドビデオ
Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections,将图像的潜空间状态进行镜像和翻转，以生成从轻度平衡的构图到完全对称的任何图像,将潜变量状态的图像进行镜像和翻转，以生成从轻度平衡的构图到完全对称的任何图像,将潜变量状态的图像进行镜像和翻转，以生成从轻度平衡的构图到完全对称的任何图像,微妙なバランスの取れた成から完璧な反射まで、あらゆるものを作り出すために潜在的な画像にミラ`リングとフリップをm用します。
Generate Graph,,,,グラフを作成する
Maximum width,,,最大宽度,
Create hypernetwork,创建超网络(Hypernetwork),创建超网络(Hypernetwork),创建超网络(Hypernetwork),Hypernetworkを作成
https://github.com/kohya-ss/sd-webui-additional-networks.git,,,,https://github.com/kohya-ss/sd-webui-additional-networks.git
lineart_coarse,线稿提取（lineart 模型，针对草稿）,,线稿提取-草稿（lineart_coarse）,
Include original image in output window ? include_original,,,,出力ウィンドウにオリジナル画像を含める ? include_original
extra-options-section,,,额外选项,
calculate dimension of LoRAs(It may take a few minutes if there are many LoRAs),计算维度（LoRA过多将拖慢速度）,,,
sets: The atomic version of [set] that lets you set multiple variables at once.,,,,sets: 1度に}数の涫をO定できる[set]のアトミック版です。
Open Resource Folder,,,,リソ`スパックフォルダを_く
Control Model - 9,控制模型-9,,,
Move or Delete,移动或删除,,,移婴蓼郡舷鞒
Card width for Extra Networks,,,附加网络卡片宽度,
hard_light,,,,ハ`ドライト
Generate Stereo side-by-side image,,,,Side-by-sideの立体画像を生成する
Gen,生成预览,,,
animation,动画相关,动画,动画,アニメ`ション
Directory for saving images using the Save button,使用“保存”按钮保存图像的目录,使用“保存”按钮保存图像的目录,使用“保存”按钮保存图像的目录,保存ボタンで画像を保存するディレクトリ
Show advanced options,,,,オプションを表示
Create blank canvas,创建空白画布（使用手绘草稿而非上传的图片）,创建空白画布（使用手绘草稿而非上传的图片）,创建空白画布（使用手绘草稿而非上传的图片）,空のキャンバスを作成
config: Updates your settings with the content for the duration of a run.,,,,config: g行期g中、O定をコンテンツで更新します。
glu,glu,,,glu
loss_vlb,,,,loss_vlb
enable_multi_images: Allows to use multiple init_images or multiple masks,,,,}数画像を使用する: }数の初期化画像や}数のマスクを使用できます
Russian localization,,,,ロシアZ翻U
Layer3 mask strength,,,,レイヤ`3のマスク不透明度
In Res,,,,イン
Leave blank to use instance prompt.,留空以使用实例提示词,留空以使用实例提示词,留空以使用实例提示词,
Enable Region 1,启用此区域,,启用区域 1,
bs,,,,bs
hiresfix,高分辨率修复,,,
Use weighted choice,,,,重み付きのxkを使用
ready,就绪,,,
Comp save extra frames,,,,追加フレ`ムを保存
stable-diffusion-webui-wildcards,通配符,通配符,通配符,
Download All files,,,下载所有文件,
A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif,,,,Img2imgのためにgifをフレ`ムg位で抽出し、アニメ`ションgifにMみすスクリプトです。
NONE,非(NOT),,,なし
webui-user.sh,,,,webui-user.sh
Use Concepts List,使用概念列表,使用概念列表,使用概念列表,コンセプトリストを使用
Start Auto Translate,开始自动翻译,,,自臃Uを_始
OVERLAY (0=Off),,,,OVERLAY (0=Off)
disabled,关闭此功能,禁用,禁用,o
Use via API,,使用了 via API,使用了 via API,APIを通して利用する
Precision of selected area ? precision,,,,xkしたI域の精度 ? precision
Colorprimarytexthover,Colorprimarytexthover,,,
DPM2,DPM2,,,DPM2
Scribble Mode,涂鸦模式（反色，强制预处理器重新识别）,涂鸦模式（反色，强制预处理器重新识别）,涂鸦模式（反色，强制预处理器重新识别）,
if: Checks whether a variable is equal to a given value.,,,,if: 涫が指定されたと等しいかどうかをチェックします。
filename_format,,文件名格式,文件名格式,
alpha and beta,"α 和 β（格式<α1 β1,α2 β2,...>，若组内仅一个值，视为α=β）",,,
Add fluff terms? ? use_fluff,,,,d毛条件を追加しますか? <unk> use_fluff
Save the mask size to the following variable ? size_var,,,,マスクのサイズを以下の涫に保存する <unk> size_var
Load Settings,,载入设定,载入设定,O定のiみzみ
copy,复制,复制,复制,コピ`する
: Original extension,：原始文件的后缀（不含 . ）,：原始文件的后缀（不含 . ）,：原始文件的后缀（不含 . ）,: 元の子
Add layer normalization,添加层归一化,添加层归一化,添加层归一化,レイヤ`の正化を追加
Advanced Options,,,高级选项,
https://github.com/hako-mikan/sd-webui-regional-prompter.git,,,,https://github.com/hako-mikan/sd-webui-regional-prompter.git
"Choose a number of terms from a list, in this case we choose two artists:",从列表中选几项，这里选了两个艺术家,从列表中选几项，这里选了两个艺术家,从列表中选几项，这里选了两个艺术家,以下のプロンプトの龊稀artistから2つをxkします。
Truncate tags by token count.,按 Token 数删节 Tag,,,ト`クン数でタグを切りめます。
ControlNet v1.1.217,扩散控制网络(ControlNet),,,
Resize crops to 512x512,缩放剪裁至 512x512,缩放剪裁至 512x512,缩放剪裁至 512x512,512x512にリサイズする
Use checkbox to enable the extension; it will be enabled or disabled when you click apply button,,,,チェックボックスを使って、C能の有炕?o炕を行えます。m用ボタンをクリックすると、有?o郡巫Bが反映されます。
Slerp angle,球面线性插值角度,球面线性插值角度,球面线性插值角度,スラ`プ角度
Pad begin/end frames,预留开始/结束帧,预留开始/结束帧,预留开始/结束帧,
Only masked,仅蒙版,仅蒙版,仅蒙版,マスクのみ
ControlNet v1.1.104,扩散控制网络(ControlNet),,,
"Don't checkpoint the gradients, Duh. Set to False to slightly increase speed at the cost of a bit of VRAM.",保存权重进度时不要保存梯度，啊不废话。设置为 False 以消耗一点显存(VRAM)为代价略微提高速度,保存权重进度时不要保存梯度，啊不废话。设置为 False 以消耗一点显存(VRAM)为代价略微提高速度,保存权重进度时不要保存梯度，啊不废话。设置为 False 以消耗一点显存(VRAM)为代价略微提高速度,
Send to Multi-Merge,,>> 多重合并,>> 多重合并,
Looping recommendations:,,,,ル`プ推X事：
big-to-small,,,,大きいものから小さいもの
Mask contrast schedule is from 0-255. Normal is 1. Affects all masks.,,,,マスクコントラストスケジュ`ルは0?255の欷扦埂Ｍǔ￥1です。すべてのマスクに影します。
extensions,扩展,,扩展(插件),
Sigma min,最小 Sigma,最小 Sigma,最小 Sigma,Sigma min
(S8) Inter-Method,,(S8) 插值方法,(S8) 插值方法,
Model 3,模型 3,模型 3,模型 3,モデル 3
Filepath:,文件目录：,,路径,
Denoise Mask,蒙版降噪（消除蒙版边缘模糊）,,,
Select activation function of hypernetwork. Recommended : Swish / Linear(none),选择超网络的激活函数。建议：Swish / Linear(线性，等于不用),选择超网络的激活函数。建议：Swish / Linear(线性，等于不用),选择超网络的激活函数。建议：Swish / Linear(线性，等于不用),Hypernetworkの活性化v数(activation function)をxk。 推X: Swish / Linear(none)
Enable Bilingual Localization,启用双语本地化,启用双语对照翻译,启用双语对照翻译,二言Z表示C能を有郡摔工
?Save & Restart,?保存并重启,,,
Calculate Split Loss,,,,分割p失を算する
Animator,,,,Animator
Fast Decoder,快速解码,快速解码,快速解码,高速デコ`ダ
ControlNet v1.1.261,扩散控制网络(ControlNet),,,
deepbooru: use spaces in tags,,,deepbooru: 使用空格分隔tags,
tp__iflytek,,,,tp__iflytek
"loading LoCon/LyCoris networks in webui. NOTE: depreciated in favor of https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris, due to error with with other lora ext.",,,,LoCon/LyCorisネットワ`クをwebuiでiみzむようにしました。注：他のLoRAC能とのエラ`により、https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris は非推Xとなりました。
Video file format,视频格式,视频格式,视频格式,
Translate negative prompt,翻译负面提示词,,,
Apply changes to selected image,将更改应用于已选择的图像,,,xkした画像に涓をm用
posex,Posex 3D OpenPose 编辑器,3D OpenPose 编辑器插件(Posex),3D OpenPose 编辑器插件(Posex),posex
use scale,,,,スケ`ルを使用
iter,,迭代器,迭代器,iter
Check New Version from Civitai,开始检查是否有新版模型,从Civitai检查模型更新,从Civitai检查模型更新,
Sanity Sample Negative Prompt,,,,正常性_J用サンプルのネガティブプロンプト
OUT_B_00,,模型B 输出层00,模型B 输出层00,
Smooth,,,,Smooth
Preview image prompt,预览图提示词,预览图提示词,预览图提示词,
"Save a copy of model to log directory every N steps, 0 to disable",,,,Nステップごとにモデルのコピ`をログディレクトリに保存します。o郡摔工龊悉0を入力してください。
KDPM2Discrete,,,,KDPM2Discrete
Hand Size,手尺寸,,,
(C4) Thertiary,,(C4) 第三,(C4) 第三,
Prompt for this mask,此蒙版区域的提示词(Prompt),,,
#: Houses a comment that does not affect your final prompt.,,,,#: 最K的なプロンプトに影を与えない程度のコメントを入れる。
Important notes and Help,,,,重要な注意事とヘルプ
IN_B_10,,模型B 输入层10,模型B 输入层10,
Show only favorite Axis Option,仅显示常用坐标轴类型,仅显示常用坐标轴类型,仅显示常用坐标轴类型,
"Load your 3D model/animation inside webui, or edit model pose as well, then send screenshot to txt2img or img2img to ControlNet.",,,,web UI内に3Dモデル/アニメ`ションをiみzんだり、モデルのポ`ズを集して、スクリ`ンショットをControlNet用にtxt2imgまたはimg2imgに送信できます。
Debug log,调试日志,,启用日志,デバッグログ
Color force Grayscale,,,,カラ`を制的にグレ`スケ`ルにする
Use same seed for all images,为所有图像使用同一个随机种子,为所有图像使用同一个随机种子,为所有图像使用同一个随机种子,
manipulations,有复合选项菜单,,,操作
predicted_iou_threshold,IoU目标检测 预测阈值(Predicted IoU Threshold),,,
C,,,,C
Memory Optimized SHA256,优化 SHA256哈希值 计算时的内存占用,,,
Embeddings,,,,埋めzみ
C:\path\to\metadata.json,,,,C:\path\to\metadata.json
dog-scribbles,,,,犬-落き
Sub directory depth,子目录探索深度,,子目录深度,サブディレクトリの深さ
Generate preview images every N steps.,每 N 步生成一次预览图像,每 N 步生成一次预览图像,每 N 步生成一次预览图像,
My prompt is more important,以 文字提示词 为主,,更关注提示词,
I've finished my sketch,根据图像创建分区,,,
Send to img2img ControlNet,>> 图生图(ControlNet),,>>图生图ControlNet,img2img ControlNet に送
Head Size,头尺寸,,,
Noise multiplier for img2img,图生图噪声倍率,图生图噪声倍率,图生图噪声倍率,Img2imgのノイズ\算
"Feature-rich UI tab that allows image viewing, search-filtering and editing.",,,,画像の表示、仕鳐榨％毳骏辚螗啊⒕集を可能にするC能N富なUIタブ。
path name,路径名,路径名,路径名,パス名
Replace or save the selected component.,替换或保存已选择的组件,,,
Colorborder,Colorborder,,,
Postprocessing operation order,后处理操作顺序,后处理操作顺序,后处理操作顺序,後I理操作の序
- Others,--其他设置--,--其他设置--,--其他设置--,
Sonar,,,,Sonar
Original file's hash (good for deleting duplication),原文件哈希(sha1算法)+输出文件后缀（方便去重）,原文件哈希(sha1算法)+输出文件后缀（方便去重）,原文件哈希(sha1算法)+输出文件后缀（方便去重）,元のファイルのハッシュ (重}を削除するのに最m)
Output directory for mask previews,蒙版预览的输出目录,蒙版预览的输出目录,蒙版预览的输出目录,
Interrogate Result,反推结果,,,インタロゲ`トのY果
replicate,,,,}u
The denoising strength for the final loop of each image in the batch.,,,,バッチ内の各画像の最Kル`プにおけるノイズ除去の度です。
"in <>, like <apple>, <hair>",,,,<apple>、<hair>のように、<>で表します。
Config-Presets,预设配置,预设配置,预设配置,Config-Presets
"Save an csv containing the loss to log directory every N steps, 0 to disable",每 N 步保存一个包含 loss 的 csv 表格到日志目录，0 表示禁用,每 N 步保存一个包含 loss 的 csv 表格到日志目录，0 表示禁用,每 N 步保存一个包含 loss 的 csv 表格到日志目录，0 表示禁用,指定したステップ数ごとにlossなどのログをcsvに保存する。0でo炕。
Info object,全部信息,全部信息,全部信息,
Search for LyCORIS/LoHa,检索 LyCORIS,,搜索LyCORIS/LoHa模型,
Colorerror,Colorerror,,,
Reload Checkpoints,,重载模型(ckpt),重载模型(ckpt),
? Caution: You should only use these options if you know what you are doing. ?,,,? 警告: 除非你知道你在做什么，否则请不要使用这里的选项. ?,? 注意: これらのオプションは、何をしているか分かっている龊悉摔韦呤褂盲筏皮ださい。?
Focal point edges weight,焦点线条权重,焦点线条权重,焦点线条权重,焦点xのウェイト
Latent tile height,潜空间图块(Latent tile)高度,潜变量分块(Latent tile)高度,潜变量分块(Latent tile)高度,Latentタイルの高さ
save anime gif,保存为GIF,,,
Send to Layer3,,,,レイヤ`3に送
Generate forever,无限生成,无限生成,无限生成,停止するまで生成をAける
Resize and fill,填充,填充,填充,k横比をS持(埋める)
[ControlNet] Preprocessor,[ControlNet] 预处理器,[ControlNet] 预处理器,[ControlNet] 预处理器,[ControlNet] プリプロセッサ
Image for Image Layout,需要生成 图像布局 的图片,,要拆分的图片,
folder location and (auto-detected) repository location.,,,,フォルダの鏊と（自食觯━辚荪弗去辘鏊。
"Use following tags to define how subdirectories for images and grids are chosen: [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; leave empty for default.",,,,"画像やグリッドのサブディレクトリ名として、以下のタグを使えます: [steps], [cfg],[prompt_hash], [prompt], [prompt_no_styles], [prompt_spaces], [width], [height], [styles], [sampler], [seed], [model_hash], [model_name], [prompt_words], [date], [datetime], [datetime<Format>], [datetime<Format><Time Zone>], [job_timestamp]; 空冥摔工毪去钎榨━毳仍O定が使われます。"
(must be < sampling steps),,,（必须小于采样步数）,
Prompt length ? prompt_length,,,,プロンプトのLさ →プロンプトL
Canny low threshold,硬边缘下限阈值（Canny low threshold）,弱边缘判断阈值（Canny low threshold）,弱边缘判断阈值（Canny low threshold）,
Read generation parameters from prompt or last generation if prompt is empty into user interface.,从提示词(prompt)中自动提取生成参数，若当前提示词为空则从上次的生成信息中读取（允许将包含正面、负面、采样器、步数、模型等信息的整段生成信息全部粘贴到提示词区域，点击后可自动将对应信息填入并删除多余内容）,从提示词(prompt)中自动提取生成参数，若当前提示词为空则从上次的生成信息中读取（允许将包含正面、负面、采样器、步数、模型等信息的整段生成信息全部粘贴到提示词区域，点击后可自动将对应信息填入并删除多余内容）,从提示词(prompt)中自动提取生成参数，若当前提示词为空则从上次的生成信息中读取（允许将包含正面、负面、采样器、步数、模型等信息的整段生成信息全部粘贴到提示词区域，点击后可自动将对应信息填入并删除多余内容）,プロンプトから生成パラメ`タをiみzむか、プロンプトが空の龊悉献钺幛紊成パラメ`タをUIにiみzむ。
Hide samplers in user interface,,,在UI中隐藏的采样器,
relu6,relu6,,,relu6
<--,,,,<--
Trajectory,,,,E
Show warnings in console.,将警告信息输出到控制台,将警告信息输出到控制台,将警告信息输出到控制台,コンソ`ルに警告を表示する
Visualize Cross-Attention,,Cross-Attention 可视化,Cross-Attention 可视化,Visualize Cross-Attention
fineart,,,,ファインア`ト
IN05,,输入层05,输入层05,
inpaint_only,,,仅重绘蒙版（inpaint_only）,
Select activation function of hypernetwork,选择超网络的激活函数,选择超网络的激活函数,选择超网络的激活函数,
centered,居中,,,
fill down,,,,下に
Ctrl+up/down precision when editing (attention:1.1),"使用 Ctrl + ↑/↓ 设置 ""(tag:1.1)"" 时的精度","使用 Ctrl + ↑/↓ 设置 ""(tag:1.1)"" 时的精度","使用 Ctrl + ↑/↓ 设置 ""(tag:1.1)"" 时的精度",集rのCtrl+↑/↓の精度 (attention:1.1)
Downscaling,缩小,缩小,缩小,s小する
API Key,,API 密钥,API 密钥,API キ`
Download the pose as .json file,,,将姿态保存成.json文件,
Send to inpaint upload,,,,Inpaint uploadに送
Field Of View,,,,野の冥
Aesthetic learning rate,美术风格学习率,美术风格学习率,美术风格学习率,Aesthetic 学率
FOV schedule,,,,FOVのスケジュ`ル
Guided images schedules,,,,ガイド付き画像のスケジュ`ル
"Only applies to inpainting models. Determines how strongly to mask off the original image for inpainting and img2img. 1.0 means fully masked, which is the default behaviour. 0.0 means a fully unmasked conditioning. Lower values will help preserve the overall composition of the image, but will struggle with large changes.",仅适用于局部重绘专用的模型（模型后缀为 inpainting.ckpt 的模型）。决定了蒙版在局部重绘以及图生图中屏蔽原图内容的强度。 1.0 表示完全屏蔽原图，这是默认行为。0.0 表示完全不屏蔽让原图进行图像调节。较低的值将有助于保持原图的整体构图，但很难遇到较大的变化,仅适用于局部重绘专用的模型（模型后缀为 inpainting.ckpt 的模型）。决定了蒙版在局部重绘以及图生图中屏蔽原图内容的强度。 1.0 表示完全屏蔽原图，这是默认行为。0.0 表示完全不屏蔽让原图进行图像调节。较低的值将有助于保持原图的整体构图，但很难遇到较大的变化,仅适用于局部重绘专用的模型（模型后缀为 inpainting.ckpt 的模型）。决定了蒙版在局部重绘以及图生图中屏蔽原图内容的强度。 1.0 表示完全屏蔽原图，这是默认行为。0.0 表示完全不屏蔽让原图进行图像调节。较低的值将有助于保持原图的整体构图，但很难遇到较大的变化,inpainting model(inpainting用のStable Diffusionモデル)にのみm用されます。inpaintとimg2imgで、元の画像をマスクする度をQ定します。1.0は完全にマスクされます(デフォルト)。0.0は完全にマスクされていない状Bです。が低いほど画像の全体的な恧暇S持されますが、大幅な涓には苦氦工毪长趣摔胜辘蓼埂
"Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.",,,,Deepdanbooru interrogateと同に、々な代替モデルを使用してg一または}数の画像ファイルをい合わせる。
Outpainting mk2,向外绘制第二版,向外绘制第二版,向外绘制第二版,Outpainting mk2
Prompt order,提示词顺序,提示词顺序,提示词顺序,プロンプトの序
tp_niutrans,,,,tp_niutrans
ControlNet v1.1.112,扩散控制网络(ControlNet),,,
OUT08,,输出层08,输出层08,
Filename word regex,文件名用词的正则表达式,文件名用词的正则表达式,文件名用词的正则表达式,ファイル名の正表F(学用)
img2img_width,宽度,,,
Training info,该模型的训练信息,训练信息,训练信息,トレ`ニングの情
Preprocessor resolution,预处理器分辨率,,预处理分辨率,
ControlNet v1.1.156,扩散控制网络(ControlNet),,,
Blend factor slope,,,,ブレンドS数のAき
"String to use as wrap for parser wildcard, .e.g __wildcard__",,,,文解析でワイルドカ`ドの欷撙趣筏剖褂盲工胛淖至 例: __wildcard__
Dataset Filter,数据集筛选条件,,,デ`タセットフィルタ
Difference,,,,差分
Cadence,,,,回数
lineart_anime,线稿提取（lineart 模型，针对动画）,,线稿提取-动画（lineart_anime）,
ViT-L-14,,,,ViT-L-14
Merge Board,合并面板,合并面板,合并面板,Merge Board
Batch Size to Simulate,,,,シミュレ`トするバッチサイズ
Swipe left/right navigates to the next image,向左/向右滑动导航到下一个图像,,左右滑动用于导航到下一个图片,
Scale Prior Loss,,,,p失をスケ`ルする
seed,随机种子(seed),随机种子(seed),随机种子(seed),シ`ド
performance,性能(it/s),,,
Only,仅负面,只有,只有,Only
Comma separated list OR * for all,,,,コンマで区切られたリスト、または * 指定によるすべて
Size of the thumbnails (px),缩略图尺寸（像素）,,缩略图的像素量,
tp__translateCom,,,,tp__translateCom
Create New Canvas,,,新建画布,
Settings > Dockers,,,,O定 > Docker
w,宽,,,
"Run: seed, subseed, subseed strength.",,,,g行：シ`ド、サブシ`ド、サブシ`ドの度。
Class Token,,,,クラスト`クン
Sequential XY Merge and Generation,开始XY队列合并，并生成图像,,,
{1-3$$artist1|artist2|artist3},{1-3$$艺术家1|艺术家2|艺术家3},{1-3$$艺术家1|艺术家2|艺术家3},{1-3$$艺术家1|艺术家2|艺术家3},{1-3$$artist1|artist2|artist3}
Use alpha as mask,,,,マスクとしてアルファを使用
?? Load,,,?? 加载,
checkpoint,模型,模型,模型,
Hidden UI tabs (requires restart),需要隐藏的选项卡（可多选，需要保存设置并重启）,需要隐藏的选项卡 (需要重启),需要隐藏的选项卡 (需要重启),UIからタブをLす (再起婴必要)
Open drawing canvas!,创建绘图画布（使用手绘草稿而非上传的图片）,创建绘图画布（使用手绘草稿而非上传的图片）,创建绘图画布（使用手绘草稿而非上传的图片）,
Convert ONNX to TensorRT,,,转换ONNX到TensorRT,
"The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.",,,,"The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video."
Wildcards can be used and the joiner can also be specified:,可以用通配符，也可以指定拼接符,可以用通配符，也可以指定拼接符,可以用通配符，也可以指定拼接符,ワイルドカ`ドを何でつなぐかも指定できます。
size,文件大小,大小,大小,サイズ
? Open config file...,?打开配置文件,,,
Discussions,,,,ディスカッション
Normal,,正态,正态,收分布
Add the image's number to its picture in the grid (when 'Add number to filename' is on),将编号添加到宫格图中的子图片上（当“将编号添加到文件名”处于启用状态时）,,,
no,否,否,否,no
Position/Rotate X,,,,位置/xS回
iw,,,,iw
max_frames,,最大帧数,最大帧数,
Sort Order,顺序,,,ソ`ト
Frames to render. 0=ALL,,,,Frames to render. 0=ALL
height,高度,高度,高度,高さ
Tile size for all SwinIR.,适用所有 SwinIR 系算法的图块尺寸(Tile size),适用所有 SwinIR 系算法的图块尺寸(Tile size),适用所有 SwinIR 系算法的图块尺寸(Tile size),SwinIRのタイルサイズ
ControlNet v1.1.233,扩散控制网络(ControlNet),,,
Render steps,,,,レンダリングrのステップ数
Caption Backup File,注释备份文件,,,キャプションバックアップファイル
Save wildcards,,,,ワイルドカ`ドを保存
Elliptic Limbs,椭圆形肢体,椭圆形肢体,椭圆形肢体,
Frequency,按频率,,,l度
Snapshot to Resume,,,,スナップショットから再_する
Instance prompt(Optional),实例(Instance)提示词 (可选),实例(Instance)提示词 (可选),实例(Instance)提示词 (可选),
"You can try it by own, to dig more deeper into Abyss ...",可自行探索，以窥深渊,可自行探索，以窥深渊,可自行探索，以窥深渊,
Default cropped image output directory,裁切后的成品的默认输出目录,裁切后的成品的默认输出目录,裁切后的成品的默认输出目录,既定の切りiき画像出力ディレクトリ
"Enabling this will provide better results and editability, but cost more VRAM.",启用此功能将提供更好的结果和可编辑性，但会消耗更多显存(VRAM),启用此功能将提供更好的结果和可编辑性，但会消耗更多显存(VRAM),启用此功能将提供更好的结果和可编辑性，但会消耗更多显存(VRAM),
Secondary model (B),模型 B,模型 B,模型 B,2つ目のmodel (B)
outline inflating,,,,アウトライン{
Discord Webhook,,,,DiscordをWebフォ`ク
Color coherence video every N frames,,,,Nフレ`ムごとにカラ`の一性を保つ
Seed travel,种子变迁,种子变迁,种子变迁,Seed travel
sk,,,,sk
Stop processing images and return any results accumulated so far.,停止处理图像，并返回迄今为止累积的任何结果,停止处理图像，并返回迄今为止累积的任何结果,停止处理图像，并返回迄今为止累积的任何结果,I理を中断し、それまでに出来たY果を表示
VAE Checkpoints to cache in RAM,在内存中缓存的 VAE 数量,在内存中缓存的 VAE 数量,在内存中缓存的 VAE 数量,RAMにキャッシュするVAEの数
text encoder,文本编码器,,,
enabled,启用,,,
Max Image Size,最大图像尺寸,最大图像尺寸,最大图像尺寸,最大画像サイズ
Balance between eyes,,,,目gのバランス
txt2img-grids,宫格图(t2i),宫格图(t2i),宫格图(t2i),txt2img-grids
Select which Real-ESRGAN models to show in the web UI. (Requires restart),选择要在 Web UI 中显示的 Real-ESRGAN 系列放大算法（需要保存设置并重启）,选择要在 Web UI 中显示的 Real-ESRGAN 系列放大算法（需要保存设置并重启）,需要显示的Real-ESRGAN算法（一般用于高清放大相关，需要重启）,
LLuL Start steps,,,,LLuLスタ`トステップ
"Resizes image to this height. If 0, height is inferred from either of two nearby sliders.",将高度调整到此值，0表示根据目标宽度或放大倍率自适应调整,将高度调整到此值，0表示根据目标宽度或放大倍率自适应调整,将高度调整到此值，0表示根据目标宽度或放大倍率自适应调整,画像をこの高さにリサイズする。0 の龊稀⒏撙丹辖くにある２つのスライダ`のいずれかから推定される。
TEnc Weight 1,Text Encoder 权重 1,Text Encoder 权重 1,Text Encoder 权重 1,TEncの重み1
Cross attention optimization,,,交叉注意力优化,
CLIP: skip inquire categories,CLIP：跳过查询类别,CLIP：跳过查询类别,CLIP：跳过查询类别,CLIP: おい合わせカテゴリ`をスキップ
Abysz-LAB-Ext,,,,Abysz-LAB-Ext
stable-diffusion-webui-rembg,背景去除插件,,,stable-diffusion-webui-rembg
Image with MD5 Hash,以MD5哈希值命名的图片文件,以MD5哈希值命名的图片文件,以MD5哈希值命名的图片文件,
Disregard checkpoint information from pasted infotext,,,忽略从粘贴的信息文本中获取的大模型信息,
Checkpoints to cache in RAM,缓存在内存(RAM)中的 Stable Diffusion 模型(ckpt) 数,缓存在内存(RAM)中的模型(ckpt)数,缓存在内存(RAM)中的模型(ckpt)数,RAMにキャッシュするcheckpointの数
(B3) Secondary,,(B3) 第二,(B3) 第二,
Textual Inversion,嵌入式(Embedding),嵌入式(T.I. Embedding),嵌入式(T.I. Embedding),Textual Inversion
Colorprimaryborderhover,Colorprimaryborderhover,,,
Generate lora weights when training is canceled.,,,,トレ`ニングキャンセルrにLoRAのWeightsを生成します。
Clip skip,Clip 跳过层,Clip 跳过层,Clip 跳过层,Clip skip
Midas Resolution,MiDaS 分辨率（MiDaS Resolution）,MiDaS 分辨率（MiDaS Resolution）,MiDaS 分辨率（MiDaS Resolution）,
portrait-scribbles,,,,肖像画-落き
save csv,保存为CSV,,,
OUT11,,输出层11,输出层11,
Upscale height ? upscale_height,,,,アップスケ`ルの高さ? upscale_height
Output style,,,,出力方法
Initialization text,初始化文字,初始化文字,初始化文字,初期O定用テキスト
Run,运行,运行,运行,g行
Output directory for txt2img grids,文生图宫格的输出目录,文生图宫格的输出目录,文生图宫格的输出目录,txt2imgグリッド画像の出力ディレクトリ
Enable Region 4,启用此区域,,启用区域 4,
"Original Text = ""A, A, B, C""?Common Tags = ""B, A""?Edit Tags = ""X, Y""","　　原始文本：“A, A, B, C”，共有 Tag：“B, A”，编辑为：“X, Y”",,,"元のテキスト= ""A、A、B、C"" 共通のタグ= ""B、A"" タグを集= ""X、Y"""
Number of instance to select ? select,,,,xkするインスタンス数 ? select
Active in negative prompts (Requires restart),在负面提示词中启用（需要保存设置并重启）,在负面提示词中启用（需要保存设置并重启）,在负面提示词中启用（需要保存设置并重启）,ネガティブプロンプトで有 (再起婴必要)
Sigma max,最大 Sigma,最大 Sigma,最大 Sigma,Sigma max
Inter Blur,,,,Inter Blur
3 units,,,启用了3个单元,
[NPW] Weight,,,,[NPW] 重み
Do not resize images,,,不调整图像大小,画像のサイズを涓しない
Region 1,区域 1,区域 1,区域 1,
parrotzone,,,,parrotzone
Use EMA for finetuning,使用 EMA 进行微调,使用 EMA 进行微调,使用 EMA 进行微调,
Get or set index statements ? verbatim,,,,インデックス文を取得またはO定する → verbatim
Import settings from file,,从文件导入设置,从文件导入设置,
Latent (nearest),Latent（最邻近插值）,潜变量 (最近邻),潜变量 (最近邻),Latent (二アレストag)
Scribble,,,涂鸦,
sm,,,,sm
Process Att-Map,,,,Att-MapのI理を行う
Import Files,导入文件,导入文件,导入文件,
tp__volcEngine,,,,tp__volcEngine
Check models’ new version,检查模型版本,,检查模型的新版本,
for detailed explanation.,以了解详细说明,以了解详细说明,以了解详细说明,を参照。
PNGs,,,,PNG
"json input path (Optional, only for append results)",json 文件输入路径（可选，仅作为附加结果）,,,jsonの入力パス (任意、Y果の追加のみ)
Cutoff Interpolation,,,,Cutoff ag法
Pad the input images token lenght to this amount. You probably want to do this.,将输入图像的词元长度垫齐到此数量。你可能会想要这样做,将输入图像的词元长度垫齐到此数量。你可能会想要这样做,将输入图像的词元长度垫齐到此数量。你可能会想要这样做,
delete next,删除后 N 张,删除后 N 张,删除后 N 张,次を削除
Extra filename (do not use e621.csv here!),附加词库文件（不要使用e621.csv）,附加词库文件（不要使用e621.csv）,附加词库文件（不要使用e621.csv）,
Generate 4 demo videos with 3D inpainted mesh.,,,,3D inpaint meshで4つのデモを生成します。
Merge&Gen,合并+生成,,,
Segment Anything部分,,,Segment Anything部分,
Subject A ? subject_a,,,,Subject A ? subject_a
Filewords,,,,ファイルワ`ド
ControlNet v1.1.8,扩散控制网络(ControlNet),,,
Branch,分支,,分支,
lo,,,,lo
"(in tokens - for texts shorter than specified, if they don't fit into 75 token limit, move them to the next 75 token chunk)",,,（单位token，分块后每组token会填充成75token的块）,
diff image color,差异图像颜色,,,
Token Merging - Ratio,合并比例（比例越高加速效果越明显，同时对画面影响也越大）,,,
Negative replacement ? negative_replacement,,,,ネガティブ置Q ? negative_replacement
Restore Selected Config,从所选设置中进行恢复,,还原所选的配置,
New Scribble Drawing Width,草图画布宽度,,,
All images generated with CompVis/stable-diffusion-v1-4 +,,,,画像はすべてCompVis/stable-diffusion-v1-4 +で生成しています。
write merged model ID to,将合并后的 模型ID 写入：,,,
Copy or move captions together,,,,同じキャプションは一wに、コピ`または移婴工
Saving to a directory,其他保存设置,保存到目录,保存到目录,ディレクトリへの保存
Skip NSFW Preview Images,,,跳过成人内容预览图,
Extra network card height,附加网络缩略图高度,,,
[Loopback] Automatically send generated images to this ControlNet unit,[回送迭代] 自动将生成图片发送到此控制单元进行迭代约束干涉,,回送（Loopback）自动回送产生的图片到本ControlNet单元,
Uncheck all copies,取消选中所有副本,,清空缓存的蒙版,
Remove selection [Delete],移除（按Delete),,,xk欷蛳鞒 [Delete]
IN_A_07,,模型A 输入层07,模型A 输入层07,
Contour padding in pixels ? contour_padding,,,,郭のパディング（ピクセルg位） ? contour_padding
Train with DreamArtist,使用梦作家训练,使用梦作家训练,使用梦作家训练,ドリ`ムア`ティストでトレ`ニング
Search Results,,搜寻结果,搜寻结果,
"(if the file size is above the limit, or either width or height are above the limit)",,,（如果图片文件的大小、长或宽超过限制的话）,
A1111 txt2img (Euler a),,,,A1111 txt2img (Euler a)
Save with JSON,保存JSON文件,保存JSON文件,保存JSON文件,JSON で保存
,,,,
house-digipa-med-impact,,,,家-digipa中インパクト
Mask file,,,,マスクのファイル
Search tags / Filter images by tags,搜索与筛选 Tag,,,タグ仕/タグによる画像フィルタ`
: Original filename without extension,：原始文件名（不含后缀）,：原始文件名（不含后缀）,：原始文件名（不含后缀）,: 子なしの元のファイル名
Generate all possible prompt combinations.,,,,すべてのプロンプトのMみ合わせを生成します。
Area 4 Weight,蒙版 4 的权重(Weight),,,
Maximum prompt token count,,,最大提示词token数,
Match Frame 0 LAB,,匹配帧 0 LAB,匹配帧 0 LAB,フレ`ム0のLABに一致する
ControlNet-M2M,扩散控制网络-视频转绘,ControlNet-视频转绘,ControlNet-视频转绘,ControlNet-M2M
ne,,,,ne
tile_gaussian,高斯噪声（tile_gaussian，tile预处理）,,,
Show intermediate steps,,,显示中间过程,
Increase coherency by padding from the last comma within n tokens when using more than 75 tokens,当使用超过 75 个词元(tokens)时，通过从 n 个词元中的最后一个逗号留空来提高一致性,当使用超过 75 个词元(tokens)时，通过从 n 个词元中的最后一个逗号留空来提高一致性,当使用超过 75 个词元(tokens)时，通过从 n 个词元中的最后一个逗号留空来提高一致性,75ト`クン以上を使用する龊稀nト`クン内の最後のカンマからパディングして一性を高める
Segment Anything,Segment Anything 蒙版绘制,,分割万物(SAM),
This text is used to rotate the feature space of the imgs embs,此文本用于旋转图集 Embeddings 的特征空间,此文本用于旋转图集 Embeddings 的特征空间,此文本用于旋转图集 Embeddings 的特征空间,このテキストは、Embedding画像の特湛臻gを回させるために使用されます
delete,删除,删除,删除,
W,,宽,宽,
X. Attn.,,,,X Attn.
Check progress,查看进度,查看进度,查看进度,
Maximum aesthetic_score,美学评分上限,,,最大美的スコア
Enable Devtools Log,,启用开发工具日志,启用开发工具日志,
ControlNet v1.1.285,扩散控制网络(ControlNet),,,
Background Threshold ? bg_threhsold,,,,背景しきい ? bg_threhsold
"sha1, blake2s, shake_256, sha256, md5-sha1, sha512_256, shake_128, mdc2, ripemd160, whirlpool, md5, sha3_384, sha512, sha3_512, blake2b, sha224, sm3, sha512_224, sha3_224, sha384, md4, sha3_256",,,,"sha1, blake2s, shake_256, sha256, md5-sha1, sha512_256, shake_128, mdc2, ripemd160, whirlpool, md5, sha3_384, sha512, sha3_512, blake2b, sha224, sm3, sha512_224, sha3_224, sha384, md4, sha3_256"
Array of valid values (used in conjunction with _new) ? _choices,,,,有郡の配列 (_newとMみ合わせて使用) ? _choices
Scale to Fit (Inner Fit),缩放模式（扩展原图，推荐）,缩放模式（扩展原图，推荐）,缩放模式（扩展原图，推荐）,インナ`フィット (余白ができる)
Prevent Empty Spot,,,,空のスポットを防止する
Edit Caption,编辑注释信息,,,キャプションを集
phi,,,,ファイ...
Pages:,,,,ペ`ジ
https://github.com/deforum-art/deforum-for-automatic1111-webui.git,,,,https://github.com/deforum-art/deforum-for-automatic1111-webui.git
-,-,,,
Concept 3,,,,コンセプト 3
Use checkbox to mark the extension for update; it will be updated when you click apply button,,,,チェックボックスを使って、更新したいC能にチェックを入れてください。チェックした目は、m用ボタンをクリックすると更新されます。
fareast,,,,|方
Archive filename pattern,,,自定义文件命名格式,
"Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.",,,,LoRAの度を、ブロックごとにオンザフライでm用します。プリセット、重量分析、ランダム化、XYプロットが含まれます。
Near schedule,,,,近いスケジュ`ル
Minimum height,,,最小高度,
Negative mask precision of selected area ? neg_precision,,,,xk欷违庭ティブマスク精度 ? neg_precision
Var. seed,差异随机种子,差异随机种子,差异随机种子,浠用シ`ド
unet,Unet,,,
Minimum value of the Mimic Scale Scheduler,模拟提示词相关性(Mimic CFG Scale) 调度函数下限（一般设为3-4）,,,
Inpaint upload,局部重绘(上传蒙版),局部重绘(上传蒙版),局部重绘(上传蒙版),Inpaintアップロ`ド
Image Layout,图像布局,,图层拆分,
AddNet UNet Weight 5,[附加网络] UNet 权重 5,[可选附加网络] UNet 权重 5,[可选附加网络] UNet 权重 5,UNetの重み 5(AddNet)
ControlNet v1.1.200,扩散控制网络(ControlNet),,,
Load lycoris: non-conventional rank adapters; in separate networks gallery tab.,,,,Load lycoris: non-conventional rank adapters; in separate networks gallery tab.
Reload/Save Settings (config.json),重新加载/保存设置（config.json）,,,O定を再iみzみ/保存(config.json)
Apply Horizontal Flip,应用水平翻转,应用水平翻转,应用水平翻转,水平方向に反をm用
AddNet TEnc Weight 4,[附加网络] Text Encoder 权重 4,[可选附加网络] Text Encoder 权重 4,[可选附加网络] Text Encoder 权重 4,TEncの重み 4(AddNet)
Mask blend mode ? mode,,,,マスクブレンドモ`ド → モ`ド
most_different,最大差异,最大差异,最大差异,
txt2img_denoising_strength,高分辨率修复-重绘幅度,,,
UI related,UI界面相关,UI界面相关,UI界面相关,UIvB
https://github.com/fkunn1326/openpose-editor.git,,,,https://github.com/fkunn1326/openpose-editor.git
bh1,,,,bh1
portrait-black-white,,,,肖像画-白\
Draw full canvas background,绘制完整的画布背景,,绘制完整的画布背景,
Train_Tuning,,,,トレイン_チュ`ニング
Save Weights,,,,重みを保存
ControlNet v1.1.278,扩散控制网络(ControlNet),,,
OUT_A_01,,模型A 输出层01,模型A 输出层01,
house-anime,,,,家のアニメ
stable-diffusion-webui-auto-tls-https,自动 tls-https,自动 tls-https,自动 tls-https,
Single Image,单张图像,单张图像,单张图像,g一画像
ControlNet v1.1.3,扩散控制网络(ControlNet),,,
Find and manage wildcards in the Wildcards Manager tab.,,,,ワイルドカ`ドはワイルドカ`ドマネ`ジャ`のタブで管理します。
elif,,,,elif
Use Custom Threshold (WDv1.4 Tagger),自定义 WD1.4 Tag反推算法 置信阈值,,,カスタムしきいを使用 (WDv1.4 Tagger)
ControlNet v1.1.264,扩散控制网络(ControlNet),,,
ControlNet v1.1.176,扩散控制网络(ControlNet),,,
txt2img2img,,,,txt2img2img
Tile size for SCUNET upscalers.,,,SCUNET放大时的潜变量分块（tile）大小,
Add CLIP results to Caption,,,,CLIPのY果をキャプションに追加
Leave empty to use img2img batch controlnet input directory,留空默认使用 图生图 扩散控制网络 的输入目录,,留空将使用图生图-批处理的Controlnet输入目录,
Save results as video,保存结果为视频,保存结果为视频,保存结果为视频,Y果を踊として保存
"The untranslated characters will be translated automatically and will not affect the old translations. Use the function in the lower right corner to easily check and quickly modify the current translation.1,Save the setting;2,Click start button;3,Reload your browser.",未翻译的字符将自动翻译，不会影响旧的翻译。 使用右下角的功能可以轻松查看和快速修改当前翻译。1、保存设置；2、点击开始按钮；3、重新加载浏览器。,,,未翻Uの文字は自拥膜朔Uされ、古い翻Uに影を与えることはありません。右下のC能を使うと、F在の翻Uをgに_Jし、素早く修正することができます。1.O定を保存します。2._始ボタンをクリックします。3.ブラウザを再iみzみします。
house-weird,,,,家-奇妙
Copy and Overwrite,复制并覆写,,,コピ`して上き
Prompts,提示词,提示词,提示词,プロンプト
Selected Image :,对上方已选中的图像进行操作：,,,xkした画像
Train with reconstruction,训练时开启重建,训练时开启重建,训练时开启重建,再Bでトレ`ニング
Output filename,,,输出文件名,
binary,图像二值化（Binary）,二值,二值,binary
ControlNet v1.1.212,扩散控制网络(ControlNet),,,
Minimum value of the CFG Scale Scheduler,提示词相关性(CFG Scale) 调度函数下限,,,
Minimum prompt token count,,,最小提示词token数,
Minimum ranking,,,最小评级,
Pixelize,,,,ドット}にQ
+100%,,,,+100%
Max flavors to append.,,,,追加するフレ`バ`の最大
Edit-Anything,Edit-Anything,,,
et,,,,et
"Save a checkpoint every N steps, 0 to disable",每隔 N 步保存一次模型权重进度(ckpt)，设置为 0 以禁用,每隔 N 步保存一次模型权重进度(ckpt)，设置为 0 以禁用,每隔 N 步保存一次模型权重进度(ckpt)，设置为 0 以禁用,
Train multiple concepts from a JSON file or string.,从 JSON 文件或字符串训练多个概念,从 JSON 文件或字符串训练多个概念,从 JSON 文件或字符串训练多个概念,
Skip img2img processing when using img2img initial image,使用图生图初始化图像时跳过图生图处理,使用图生图初始化图像时跳过图生图处理,使用图生图初始化图像时跳过图生图处理,img2img の初期画像を使用r、img2img I理をスキップする
Attention,,,,Attention
Caption min length,,,,キャプションの最小L
this subreddit,reddit,,,
Refresh List,刷新列表,刷新列表,刷新列表,
dog-digipa-high-impact,,,,犬-digipaハイインパクト
Miscellaneous,,,,その他
--------,--------,---------,---------,
dog-n,,,,犬-n
Combinatorial batches,组合批次,组合批次,组合批次,Mみ合わせのバッチ
"Euler Ancestral - very creative, each can get a completely different picture depending on step count, setting steps to higher than 30-40 does not help",Euler Ancestral - 非常有创意，可以根据迭代步数获得完全不同的图像，将迭代步数设置为高于 30-40 不会有正面作用,Euler Ancestral - 非常有创意，可以根据迭代步数获得完全不同的图像，将迭代步数设置为高于 30-40 不会有正面作用,Euler Ancestral - 非常有创意，可以根据迭代步数获得完全不同的图像，将迭代步数设置为高于 30-40 不会有正面作用,
DPM++ SDE Karras,,,,DPM++ SDE Karras
Use the same seed for all prompts in this batch,对这批次中的所有提示词使用相同的种子,对这批次中的所有提示词使用相同的种子,对这批次中的所有提示词使用相同的种子,このバッチ内のすべてのプロンプトに同じシ`ドを使用する
"String to use as right bracket for parser variants, .e.g {variant1|variant2|variant3}",,,,文解析でバリエ`ションの右括弧として使用する文字列 例: {variant1|variant2|variant3}
Invert mask,,,,マスクを反
portrait-nudity,,,,肖像画-ヌ`ド
scribble_pidinet, 涂鸦处理（scribble 模型，PiDiNet 算法）,, 涂鸦处理（scribble，PiDiNet 算法）,
Save depth maps,,,,深度マップを保存
(use (text) to make model pay more attention to text and [text] to make it pay less attention),,,（使用(text)来增加提示词权重，[text]来降低提示词权重）,
TODO: Control/status panel,,,,TODO: コントロ`ル/ステ`タスパネル
linear_with_warmup,,,,linear_with_warmup
point2 x,,,,点2_横
elu,elu,,,elu
NORMALIZE (0=Off)),,,,NORMALIZE (0=Off))
img2pez,,,,img2pez
Input Negative Theme,,,,ネガティブテ`マを入力
cosine_annealing,,,,cosine_annealing
"Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.",,,,少数の画像を埋めzむ学ができます。これは画Lを付与することになります。そして、それらの埋めzんだものを使って画像を生成することもできます。
Bucket Cropping,,,,バケットクロッピング
Tile size for ESRGAN upscalers. 0 = no tiling.,ESRGAN 的图块尺寸(Tile size)。0 为不分块(no tiling),ESRGAN 的图块尺寸(Tile size)。0 为不分块(no tiling),ESRGAN 的图块尺寸(Tile size)。0 为不分块(no tiling),ESRGANのタイルサイズ。0とするとタイルしない。
Save Embedding,保存 Embedding,保存 Embedding,保存 Embedding,Embeddingを保存
extension by,,扩展来自,扩展来自,
Image Parameters,预览图像的生成参数,图像参数,图像参数,画像パラメ`タ
GPU,,,,GPU
Model A,模型A,模型A,模型A,
Fixed seed,固定随机种子,固定随机种子,固定随机种子,固定シ`ド
Enter hypernetwork layer structure,输入超网络层结构,输入超网络层结构,输入超网络层结构,Hypernetworkのレイヤ`造を入力
"If this is set, then random prompts are generated, even if the seed is the same.",如果设置了此项，则会生成随机提示词，即使种子相同,如果设置了此项，则会生成随机提示词，即使种子相同,如果设置了此项，则会生成随机提示词，即使种子相同,O定されている龊稀シ`ドが同じであってもランダムなプロンプトが生成されます。
sv,,,,sv
Next Page,下一页,下一页,下一页,次のペ`ジ
Time in ms to wait before triggering completion again (Requires restart),触发补全前的等待时间（单位:毫秒，需要保存设置并重启）,触发补全前的等待时间（单位:毫秒，需要保存设置并重启）,触发补全前的等待时间（单位:毫秒，需要保存设置并重启）,再びa完を作婴丹护毪蓼扦未Crg (ミリ秒、再起婴必要)
ControlNet Inpaint Number,接收蒙版的 ControlNet 编号,,目标ControlNet单元编号,
ControlNet Unit 1,控制单元 1,,ControlNet单元1,
Add the image's number to its picture in the grid.,,,,グリッド内の画像に画像の番号を追加
Model 2,模型 2,模型 2,模型 2,モデル 2
Output,输出,,输出,出力
Shift attention,关注转移,关注转移,关注转移,Shift attention
Save separate diffusers snapshots when training is canceled.,,,,トレ`ニングのキャンセルrにディフュ`ザ`のスナップショットをeに保存します。
nudity,,,,ヌ`ド
spaceship-c,,,,宇宙船演算子(c)
Sub-folder,保存目录（可选择子目录）,子文件夹,子文件夹,
"Total number of training steps to perform. If provided, overrides num_train_epochs.",要执行的训练迭代步数总数。如果填了，则覆盖 '训练多少期(num_train_epochs)',要执行的训练迭代步数总数。如果填了，则覆盖 '训练多少期(num_train_epochs)',要执行的训练迭代步数总数。如果填了，则覆盖 '训练多少期(num_train_epochs)',
Loss for latent match (grad mode),匹配潜空间(latent)损失 (梯度模式),匹配潜变量(latent)损失 (梯度模式),匹配潜变量(latent)损失 (梯度模式),
"Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.",,,,D8ahazardによるランダムパッチ。v2、2.1モデル用の自鹰愆`ドO定YAMLファイル; 2.1モデルの注意を修正するための潜在的な散パッチ (no-halfなしの\いボックス) 、それ以外にも思いつく限りのこと。
? Add custom fields...,?添加其他可选的预设内容,,,
e.g. A portrait photo of embedding_name,示例： A portrait photo of embedding_name,示例： A portrait photo of embedding_name,示例： A portrait photo of embedding_name,例: A portrait photo of embedding_name
Interrogate: keep models in VRAM,将模型保存在显存(VRAM)中（不建议开启）,将模型保存在显存(VRAM)中（不建议开启）,将模型保存在显存(VRAM)中（不建议开启）,Interrogate: モデルをVRAMに保持する
OUT_A_07,,模型A 输出层07,模型A 输出层07,
internal order,内部排序,内部排序,内部排序,内部序
Randomize,随机化,随机化,随机化,Randomize
txt2img_enable_hr,是否启用高分辨率修复,,,
"Select Layer weights initialization. relu-like - Kaiming, sigmoid-like - Xavier is recommended",选择初始化层权重的方案，类relu - Kaiming，类sigmoid - Xavier 都是比较推荐的选项,选择初始化层权重的方案，类relu - Kaiming，类sigmoid - Xavier 都是比较推荐的选项,选择初始化层权重的方案，类relu - Kaiming，类sigmoid - Xavier 都是比较推荐的选项,
"Useful for I'm feeling lucky and Magic Prompt. If this is set, then negative prompts are not generated.",对手气不错和魔法提示词很有用。如果设置了此项，则不会生成否定提示,对手气不错和魔法提示词很有用。如果设置了此项，则不会生成否定提示,对手气不错和魔法提示词很有用。如果设置了此项，则不会生成否定提示,
"Result = ""X, C, E""?(A->"""", B->X, D->"""")","　　结果：“X, C, E”（A->“<无>”，B->X，D->“<无>”）",,,"Result = ""X, C, E"" (A->"""", B->X, D->"""")"
CLIP: maximum number of lines in text file (0 = No limit),CLIP：文本文件中的最大行数（0 为无限制）,CLIP：文本文件中的最大行数（0 为无限制）,CLIP：文本文件中的最大行数（0 为无限制）,CLIP: テキストファイル内の行の最大数(0 = 制限なし)
Latent,Latent,潜变量,潜变量,Latent
Jinja2 templates are an expressive alternative to the standard syntax. See the Help section below for instructions.,Jinja2 模板是标准语法富有表现力的一种替代品，相关说明参见下方帮助栏,Jinja2 模板是标准语法富有表现力的一种替代品，相关说明参见下方帮助栏,Jinja2 模板是标准语法富有表现力的一种替代品，相关说明参见下方帮助栏,Jinja2テンプレ`トは、文の代わりに表F力Nかなものです。手については、以下のヘルプセクションを参照してください。
The other site allows for making keyframes using,,,,他のw所ではキ`フレ`ムを作るためにS可されています
txt2img_hr_upscaler,高分辨率修复-放大算法,,,
Use CosineAnnealingWarmupRestarts Scheduler,,,,CosineAnnealingWarmupRestartスケジュ`ラを使用。
"The path to the concepts JSON file, or a JSON string.",储存概念的 JSON 文件的路径，或 JSON 字符串,储存概念的 JSON 文件的路径，或 JSON 字符串,储存概念的 JSON 文件的路径，或 JSON 字符串,
UniPC Order,,,,UniPC 次数
2D,,,,2D
article,,,,事
Page Index,页码,页码,页码,ペ`ジのインデックス
Canvas Background Color,,,,キャンバスの背景色
BLIP: minimum description length,,,BLIP: 最小描述长度,
Highres. Width,高清修复：第一遍宽度,高清修复：第一遍宽度,高清修复：第一遍宽度,ハイレゾの幅
Post-Processing,后处理,后处理,后处理,後I理
Randomize Highres. percentage,随机化 启用高分辨率修复的几率,随机化 启用高清修复的几率,随机化 启用高清修复的几率,
Highres. Height,高清修复：第一遍高度,高清修复：第一遍高度,高清修复：第一遍高度,ハイレゾの高さ
"You can create these images by run ""Create inspiration images"" script in txt2img page,",,,,これらの画像は、txt2imgペ`ジに「インスピレ`ション画像を作成」スクリプトをg行することで作成できます。
Loopback,回送,回送,回送,ル`プバック
"You may need to undo this for an update, if you have git issues and don't know how to deal with them",如果更新时出现问题，请还原以上所有操作至初始状态,如果更新时出现问题，请还原以上所有操作至初始状态,如果更新时出现问题，请还原以上所有操作至初始状态,
Cleanup non-default temporary directory when starting webui,启动 WebUI 时清理非默认临时目录,启动 WebUI 时清理非默认临时目录,启动 WebUI 时清理非默认临时目录,webui起rにデフォルト以外のテンポラリディレクトリをクリ`ンアップする。
"Added the ability to scale Inpaint, Sketch, and Inpaint Sketch. Adds useful hotkeys",,,,Inpaint、スケッチ、Inpaintスケッチをスケ`ル(大s小)するC能を追加しました。便利なショ`トカットキ`を追加します。
MBW Each,AB模型分别分层设置权重(MBW Each),AB模型分别分块设置权重(MBW Each),AB模型分别分块设置权重(MBW Each),
Keep original size,,,保持原始尺寸,
unset,,,,解除
Expand by default,,,,デフォルトで展_
Apply block weight from text,将手动输入的权重应用于滑动条,将手动输入的权重应用于滑动条,将手动输入的权重应用于滑动条,
Learning Rate,学习率,学习率,学习率,学率
ESRGAN_4x,ESRGAN_4x,,,ESRGAN_4x
time_uniform,,,,time_uniform
Most frequent tags in captions,训练时tag的频率列表,训练用描述文本里tags的频率列表,训练用描述文本里tags的频率列表,キャプション内で最もl繁に出Fするタグ
Save debug images to WebUI folder ? save,,,,デバッグ画像をWebUIフォルダに保存 ? save
Weight 4,权重 4,权重 4,权重 4,重み 4
stable-diffusion-webui-localization-zh_CN,简体中文语言包,简体中文语言包,简体中文语言包,
Next batch,下一批,下一批,下一批,
Open...,打开,打开...,打开...,
Maximum score,,,最大分数,
point3 y,,,,点3_k
path/to/caption,,,,path/to/caption
Image preview height,,,,プレビュ`の高さ
interpolation method,插值算法,插值算法,插值算法,ag法
Chant filename (Chants are longer prompt presets),预设提示词库文件（Chant filename，用于快速补全整段预设提示词）,,Chant文件名（Chants是长提示词的预设）,
Generate Samples,,,,サンプルを生成
Saves Optimizer state as separate *.optim file. Training can be resumed with HN itself and matching optim file.,将优化器状态保存为单独的 *.optim 文件。可以使用超网络(HN)本身和匹配的 optim 文件继续中断了的训练。,将优化器状态保存为单独的 *.optim 文件。可以使用超网络(HN)本身和匹配的 optim 文件继续中断了的训练。,将优化器状态保存为单独的 *.optim 文件。可以使用超网络(HN)本身和匹配的 optim 文件继续中断了的训练。,
ControlNet v1.1.239,扩散控制网络(ControlNet),,,
Launch Krita.,,,,Kritaを起
Negative lr weight,负面的学习率权重,反向的学习率权重,反向的学习率权重,ネガティブ学率の重み
Image width,图像宽度,图像宽度,图像宽度,画像の幅
sd-webui-multiple-hypernetworks,多超网络模型加载,复数超网络加载,复数超网络加载,
Merge Mode,合并模式（下方设置的 α 与 β 将代入公式）,,,
Startup profile,,,启动概述,
"Prompt bs (well, that's what they call it) ? prompt_bs",,,,Prompt bs (一般にそう呼ばれている) ? prompt_bs
extension by bbc_mc,由bbc_mc编写,由bbc_mc编写,由bbc_mc编写,
"Translate: x, y, z",,,,"Q: x, y, z"
ControlNet v1.1.186,扩散控制网络(ControlNet),,,
OUT_A_09,,模型A 输出层09,模型A 输出层09,
"API info may not be necessary for some boorus, but certain information or posts may fail to load without it. For example, Danbooru doesn't show certain posts in search results unless you auth as a Gold tier member.",,API 信息对于某些 boorus 可能不是必需的，但如果没有它，某些信息或图帖可能无法加载。 例如，除非你的 API 验证属于黄金会员，否则 Danbooru 不会在搜索结果中显示某些图帖,API 信息对于某些 boorus 可能不是必需的，但如果没有它，某些信息或图帖可能无法加载。 例如，除非你的 API 验证属于黄金会员，否则 Danbooru 不会在搜索结果中显示某些图帖,
Change CTRL keybindings to SHIFT,将 CTRL 绑定更改为 SHIFT,将 CTRL 绑定更改为 SHIFT,将 CTRL 绑定更改为 SHIFT,Ctrlキ`割り当てをShiftに涓する
Renew Page,刷新页面,刷新页面,刷新页面,ペ`ジの更新
Overwrite,覆写原有注释,,,上き
Options in main UI,,,主界面的选项,
tp_lingvanex,,,,tp_lingvanex
Primary detection model (A),首要检测模型 (A),首要检测模型 (A),首要检测模型 (A),
Colorprimary,Colorprimary,,,
Depth,,,深度,深度
ko_KR Localization,,,,ko_KR Localization
Pooling Max,,,,最大ポ`リング
OUT_B_05,,模型B 输出层05,模型B 输出层05,
Official Deforum Wiki:,,,,Deforum Wiki:
inpaint_global_harmonious,蒙版整合（inpaint 模型）,,局部重绘蒙版整合（inpaint_global_harmonious）,
"With img2img, fill image's transparent parts with this color.",在图生图中使用以下颜色填充透明区域,在图生图中使用以下颜色填充透明区域,在图生图中使用以下颜色填充透明区域,Img2imgで画像の透明部分をこの色でTりつぶします。
Outfill method:,填充方法：,填充方法：,填充方法：,Tりつぶしの方法：
conjugate,,,,活用する
tab,有独立选项卡,选项卡,选项卡,タブ
IN_B_05,,模型B 输入层05,模型B 输入层05,
same to Strength,使用强度算法（与直接在生成时调用LoRA结果相同）,,,
ControlNet v1.1.118,扩散控制网络(ControlNet),,,
Help for Jinja2 templates,Jinja2 模板帮助,Jinja2 模板帮助,Jinja2 模板帮助,Jinja2 テンプレ`トのヘルプ
Adds a tab that lets you preview how CLIP model would tokenize your text.,新增一个选项卡让你能够预览 CLIP 模型如何对你的文本进行词元拆分(tokenize),新增一个选项卡让你能够预览 CLIP 模型如何对你的文本进行词元拆分(tokenize),新增一个选项卡让你能够预览 CLIP 模型如何对你的文本进行词元拆分(tokenize),CLIPモデルがどのようにテキストをト`クン化するかをプレビュ`できるタブを追加します。
Use txt2img,,,,txt2img を使用
online,需联网,线上,线上,オンライン
rgb,,,,rgb
Guidance Start (T),引导介入时机（Start）,引导介入时机（Start）,引导介入时机（Start）,ガイダンス_始 (T)
load keys,加载 键 列表,,,
sampling,,,,サンプリング
Number of repeats for a single input image per epoch; used only for displaying epoch number,每期(epoch)中单个输入图像的重复次数； 仅用于显示期数,每期(epoch)中单个输入图像的重复次数； 仅用于显示期数,每期(epoch)中单个输入图像的重复次数； 仅用于显示期数,エポックごとの1つの入力イメ`ジにするRり返し回数。エポック数の表示にのみ使用
Weight 2,权重 2,权重 2,权重 2,重み 2
x3,,,,x3
https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git,,,,https://github.com/CodeExplode/stable-diffusion-webui-embedding-editor.git
Custom Diffusion,,,,Custom Diffusion
DeepDanbooru,,,,DeepDanbooru
Load BG,添加背景,,,
https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git,,,,https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111.git
Conditional statement ? my_var,,,,条件付きステ`トメント ? _var
point1 x,,,,点1_横
Train Hypernetwork; you must specify a directory,,,,Hypernetwork トレ`ニング; ディレクトリを指定してください
Travel steps between stages,每个阶段变迁的迭代步数,每个阶段变迁的迭代步数,每个阶段变迁的迭代步数,
Recursively search for wildcards,,,通配符（wildcards）使用递归查找,
Move completion popup together with text cursor,补全弹窗随文本光标一起移动（建议开启）,补全弹窗随文本光标一起移动（建议开启）,补全弹窗随文本光标一起移动（建议开启）,a完ポップアップをテキストカ`ソルと一wに移
"File size limit for the above option, MB",上述选项的文件大小限制，单位：MB,上述选项的文件大小限制，单位：MB,上述选项的文件大小限制，单位：MB,上オプションのファイルサイズ制限 (MB)
A-B,A-B,,,
Which algorithm to use to produce the image,使用哪种算法生成图像,使用哪种算法生成图像,使用哪种算法生成图像,画像を生成するために使用するアルゴリズムをxkします。
Only run this shortcode if using full resolution inpainting mode ? only_full_res,,,,完全解像度修庭猢`ドを使用する龊悉摔韦摺このショ`トコ`ドをg行する <unk> only_full_res
Restarts noise scheduler every nth epoch,,,,ノイズスケジュ`ラを各エポックごとに再起婴筏蓼
Elemental,元素水平操作(Elemental),,,
Find more settings on the,,,,よりなO定は
Enabled,启用,启用,启用,有炕
Overwrite Old Hypernetwork,覆写旧的超网络模型,覆写旧的超网络,覆写旧的超网络,古いHypernetworkを上きする
Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.,,,,Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.
Combinatorial generation,组合生成,组合生成,组合生成,Mみ合わせ生成
maximum aesthetic_score,美学评分上限,美学评分上限,美学评分上限,
Instance Token + Description,实例的词元(Token) + 描述,实例的词元(Token) + 描述,实例的词元(Token) + 描述,
From img2img2 settings,,,,Img2img2O定より
"Hypernetwork name to create, leave it empty to use selected",,,,Hypernetwork名を作成します。空白のままにすると empty が使用されます
Cond. Image Mask Weight,图像调节屏蔽度,图像调节屏蔽度,图像调节屏蔽度,
sd_dreambooth_extension,dreambooth 扩展,dreambooth 扩展,dreambooth 扩展,sd_dreambooth_extension
ControlNet v1.1.137,扩散控制网络(ControlNet),,,
"Tile overlap, in pixels for ESRGAN upscalers. Low values = visible seam.",ESRGAN 的图块重叠(Tile overlap)像素。较小时可见接缝,ESRGAN 的图块重叠(Tile overlap)像素。较小时可见接缝,ESRGAN 的图块重叠(Tile overlap)像素。较小时可见接缝,ESRGANのタイルの重}部分のピクセル数。少なくするとつなぎ目がえやすくなる。
ViT-H-14,,,,ViT-H-14
science,技术验证,科学,科学,サイエンス
Add difference:A+(B-C)*alpha,添加差分（ A + (B-C)×α ）,,,
Layer5,,,,Layer5
"Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.",,,,}数のHypernetworksを一度にm用するC能を追加します。なる重みで}数のHypernetworksをBA的にm用します。
gl,,,,gl
contains,,,,含む
ControlNet v1.1.240,扩散控制网络(ControlNet),,,
Include meta tags in tag string,,在标签字串中包含属性标签,在标签字串中包含属性标签,
(O4) Output ckpt Name,,(O4) ckpt 输出名,(O4) ckpt 输出名,
Save textual inversion and hypernet settings to a text file whenever training starts.,每当训练开始时，将 嵌入式(Embedding) 和 超网络(Hypernetwork) 设置保存到文本文件中,训练开始时，将 textual inversion 和 hypernet 的设置保存到 txt 中,训练开始时，将 textual inversion 和 hypernet 的设置保存到 txt 中,トレ`ニングの_始rにテキストの反とハイパ`ネットO定をテキストファイルに保存します。
time_quadratic,,,,time_quadratic
The source checkpoint to extract for training.,用于训练的要提取的源 Stable Diffusion 模型(ckpt),用于训练的要提取的源模型(ckpt),用于训练的要提取的源模型(ckpt),
Glow mode,,,,グロ`モ`ド
Override random nature of shortcode with predetermined outcome ? _case,,,,ショ`トコ`ドのランダムな性|を事前にQ定されたY果で上きする <unk> _case
system,操作系统,,,
ControlNet v1.1.291,扩散控制网络(ControlNet),,,
Apply Style,应用风格,应用风格,应用风格,
Write prompts to file,将提示词写入文件,将提示词写入文件,将提示词写入文件,プロンプトをファイルにき出し
Search for embeddings,检索 嵌入式(Embedding),搜索 嵌入式(Embedding),搜索 嵌入式(Embedding),Embeddings を仕
? Reset,重置,,,
Ignore: keep prompt and styles dropdown as it is.,,,忽略：不处理样式,
Step method (grad mode),步进方法 (梯度模式),步进方法 (梯度模式),步进方法 (梯度模式),
Gelbooru Prompt,Gelbooru标签自动摘录,Gelbooru标签自动摘录,Gelbooru标签自动摘录,Gelbooru Prompt
Number of grids in each row,每行显示多少格,每行显示多少格,每行显示多少格,
ControlNet v1.1.184,扩散控制网络(ControlNet),,,
"Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.",基于 Shivam Shiaro 的代码移植的 Dreambooth 训练，为低显存(lower-VRAM)显卡做了优化,基于 Shivam Shiaro 的代码移植的 Dreambooth 训练，为低显存(lower-VRAM)显卡做了优化,基于 Shivam Shiaro 的代码移植的 Dreambooth 训练，为低显存(lower-VRAM)显卡做了优化,Dreambooth trainingはShivam Shiaro氏のリポジトリを元に、低VRAMのGPU向けに最m化されています。
Use original name for output filename during batch process in extras tab,在附加功能选项卡中的批量处理过程中，使用原始名称作为输出文件名,在附加功能选项卡中的批量处理过程中，使用原始名称作为输出文件名,在附加功能选项卡中的批量处理过程中，使用原始名称作为输出文件名,その他タブでバッチI理をするH、元のファイル名を出力ファイル名に使う
zoom_enhance: Upscales a selected portion of the image. ENHANCE!,,,,zoom_enhance: 画像のxkした部分をアップスケ`ルします。ENHANCE!
seg_ufade20k,语义分割（seg 模型，UniFormer 算法，ADE20k 协议）,,语义分割（seg，UniFormer 算法，ADE20k 协议）,
"Scan Exif-/.txt-data (initially slower, but required for many features to work)",扫描图片的 Exif 信息与同名 txt 文件（会拖慢读取速度，但大部分功能依赖此设置）,,扫描Exif-/.txt数据（初次使用会花费一些时间，不过一些功能需要这些信息）,Exif-/.txt-data をスキャンします (最初はWくなりますが、多くのC能が幼鳏工毪郡幛吮匾です)
Replace new-line character with comma,用逗号替换换行符,,,改行をカンマに置Q
Image Tags,,图像标签(Tags),图像标签(Tags),
Tile overlap for ESRGAN upscalers.,,,ESRGAN放大时潜变量分块（tile）重叠大小,
ControlNet-5,控制网络-5,,,
Focal point entropy weight,焦点熵权重,焦点熵权重,焦点熵权重,焦点エントロピ`のウェイト
Bilinear,,,,Bilinear
Add selection [Enter],添加到选中（按Enter）,,,xkを追加[Enter]
Turkish localization,,,,トルコZ翻U
celu,celu,,,celu
linear_burn,,,,linear_burn
Only extract keyframes (recommended),只提取关键帧（推荐）,只提取关键帧（推荐）,只提取关键帧（推荐）,キ`フレ`ムのみ抽出する (推X)
Fix broken CLIP position IDs,修复损坏的 CLIP 位置 ID,,,
Pixel Perfect,自动设置预处理器分辨率,,对齐预处理和输出图片分辨率,
"DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.",,,,DFIエクスパンドは、DFIで食訾丹欷坎糠证违ē氓袱蛱くする。注）DFIトレランスは、食訾丹欷婴の量を修正します。これは、Y果の大小にかかわらず、そのY果にのみ影します。a完的なパラメ`タ`です。0=オフ。
Save Preset,保存预设,,保存预设,
Sigma adjustment for finding noise for image,为寻找图中噪点的 Sigma 调整,为寻找图中噪点的 Sigma 调整,为寻找图中噪点的 Sigma 调整,画像のノイズをつけるためのSigmaの{整
Cond.fix: Disabled (none),修复时调节：禁用 (无),修复时调节：禁用 (无),修复时调节：禁用 (无),Cond.fix: o (oし)
Send to ControlNet,>> ControlNet,发送到 ControlNet,发送到 ControlNet,ControlNet に送る
ControlNet v1.1.243,扩散控制网络(ControlNet),,,
sd-3dmodel-loader,,,,sd-3dmodel-loader
Use cross attention optimizations while training,训练时开启 cross attention 优化,训练时开启 cross attention 优化,训练时开启 cross attention 优化,トレ`ニング中にクロスアテンションの最m化を使用する
top,顶部,,,
Live preview method,,,实时预览方法,
Look for,,,,探す
Wildcards Manager,,,,ワイルドカ`ドの管理
"Once again, this `dynamic` demo has not removed/re-implemented all features present","再次声明，这个选项卡现在只是个摆设，所有操作都要自己去改 CSS 文件，单击""应用风格""与""应用设置""重启后生效","再次声明，这个选项卡现在只是个摆设，所有操作都要自己去改 CSS 文件，单击""应用风格""与""应用设置""重启后生效","再次声明，这个选项卡现在只是个摆设，所有操作都要自己去改 CSS 文件，单击""应用风格""与""应用设置""重启后生效",
ExtraNetwork sidebar default width,附加网络侧边栏 默认宽度,,,
"Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.",向 webui 添加一个选项卡，允许用户自动从视频中提取关键帧，并手动裁剪 512x512 大小以用于模型训练,向 webui 添加一个选项卡，允许用户自动从视频中提取关键帧，并手动裁剪 512x512 大小以用于模型训练,向 webui 添加一个选项卡，允许用户自动从视频中提取关键帧，并手动裁剪 512x512 大小以用于模型训练,踊からキ`フレ`ムを自拥膜顺槌訾扦るタブを webui に追加します。 その後、512x512のクロップを手婴浅槌訾筏匹猊钎胙Яに使用します。
Steps schedule,,,,ステップのスケジュ`ル
Cosine Up,余弦递增(Cosine Up),,,
3D Openpose,3D Openpose 编辑器,,,
Move/Copy/Delete matching .txt files,将图片的移动、复制、删除操作应用到与之同名的 txt 文件（建议开启）,将图片的移动、复制、删除操作应用到与之同名的 txt 文件（建议开启）,将图片的移动、复制、删除操作应用到与之同名的 txt 文件（建议开启）,一致する.txtファイルを移/コピ`/削除
Subject Name to replace class with in cations,描述文本中要替换类(class)的主体名(subject),描述文本中要替换类(class)的主体名(subject),描述文本中要替换类(class)的主体名(subject),
Create debug image,创建调试(debug)图像,创建调试(debug)图像,创建调试(debug)图像,デバッグイメ`ジの作成
AddNet UNet Weight 2,[附加网络] UNet 权重 2,[可选附加网络] UNet 权重 2,[可选附加网络] UNet 权重 2,UNetの重み 2(AddNet)
Save Presets,保存预设,,,
An easy way to mix and match elements to prompts that affect the style of the result.,,,,Y果のスタイルに影を与える要素をプロンプトに混ぜてマッチさせるgな方法です。
Weights Presets,权重预设,,,
"When adding extra network such as Hypernetwork or Lora to prompt, use this multiplier for it.",,,,Hypernetwork や LoRA などの追加ネットワ`クをプロンプトに追加するH、この倍率をm用する。
Upscale width ? upscale_width,,,,アップスケ`ルの幅 ? upscale_width
Training Wizard (Object/Style),训练配置器 (物件/风格),训练配置器 (物件/风格),训练配置器 (物件/风格),トレ`ニングウィザ`ド (オブジェクト/スタイル)
Interrogator,反推算法,反推算法,反推算法,インタロゲ`タ`
Do not show any images in results for web,不在网页的结果中显示任何图像（不建议开启）,不在网页的结果中显示任何图像,不在网页的结果中显示任何图像,WebUIのY果画面に画像を表示しない
wrap,,,,折り返す
OUT03,,输出层03,输出层03,
sigma tmin,最小(tmin) sigma,最小(tmin) sigma,最小(tmin) sigma,sigma tmin
Show images zoomed in by default in full page image viewer,在整页图像查看器中，默认放大显示图像（建议开启）,在整页图像查看器中，默认放大显示图像（建议开启）,在整页图像查看器中，默认放大显示图像（建议开启）,フルペ`ジ画像ビュ`アでデフォルトで画像を大して表示する
Steps between prompts,每个提示词之间的迭代步伐,每个提示词之间的迭代步伐,每个提示词之间的迭代步伐,
1. The tags common to all displayed images are shown in comma separated style.,1.所有当前显示的图像，其共有 Tag 均以逗号分隔的样式显示,,,1. すべての表示画像に共通するタグはカンマ区切りのスタイルで表示されます。
saturation,,,,彩度
Ctrl+up/down precision when editing <extra networks:0.9>,"使用 Ctrl + ↑/↓ 设置 ""<extra networks:0.9>"" 时的精度","使用 Ctrl + ↑/↓ 设置 ""<extra networks:0.9>"" 时的精度","使用 Ctrl + ↑/↓ 设置 ""<extra networks:0.9>"" 时的精度",集rのCtrl+↑/↓の精度 <extra networks:0.9>
ControlNet v1.1.250,扩散控制网络(ControlNet),,,
latest,最新,最新,最新,最新版
ControlNet v1.1.270,扩散控制网络(ControlNet),,,
(booru only),,,(只针对booru),
"Predefined percentage buttons, applied to dimensions (75, 125, 150)",,,,事前に定xされたs尺（%）ボタン。サイズにm用される（75、125、150）
Alphabetical Order,按字母序,,,アルファベット
Layer5 opacity,,,,Layer5 不透明度
Extra arguments,,,额外参数,
logsigmoid,logsigmoid,,,logsigmoid
All Displayed Ones,所有当前显示图像,,,全表示
Original filename without extension,原文件名+输出文件后缀,原文件名+输出文件后缀,原文件名+输出文件后缀,子なしの元のファイル名
ControlNet部分,,,ControlNet部分,
Copy to txt2img ControlNet Inpainting,,,将蒙版复制到文生图ControlNet重绘,
Enable GroundingDINO,启用 GroundingDINO,,启用GroundingDINO,
Copy image to:,将图片复制到:,将图片复制到:,将图片复制到:,画像のコピ`先:
Send to buttons,发送到其他页面的按钮,,,
Hidden UI tabs,,,需要隐藏的页签,
(M7) Multiplier,,(M7) 倍率,(M7) 倍率,
Print the variable's value ? _out,,,,涫のを表示? _out
Evaluate as floats instead of integers ? _float,,,,整数ではなく浮有∈点数としてuします。 ? _float
Colorerrorbg,Colorerrorbg,,,
Camera Far,远景阈值,,,
There about 6000 artists and art styles in these files.,,,,これらのファイルにはs6000人のア`ティストとア`トスタイルがあります。
Use mask,,,,マスクを使用
SPACE + Drag Mouse,,,空格键+鼠标拖动,
Spanish localization,,,,スペインZ翻U
The denoising curve controls the rate of denoising strength change each loop. Aggressive: Most of the change will happen towards the start of the loops. Linear: Change will be constant through all loops. Lazy: Most of the change will happen towards the end of the loops.,,,,ノイズ除去の曲は、ル`プごとにノイズ除去度の浠率をコントロ`ルします。 Aggressive: ル`プの序Pに最も浠します。 Linear: すべてのル`プを通して浠は一定です。 Lazy: ル`プのKPに最も浠します。
Load results,加载结果,加载结果,加载结果,Y果をiみzむ
thumbs,缩略视图,拇指视图（小预览图，方图，真的只有大拇指甲盖大小，文字看不太清）,拇指视图（小预览图，方图，真的只有大拇指甲盖大小，文字看不太清）,
Will upscale the image depending on the selected target size type,,,,xkしたタ`ゲットサイズのNに辘袱啤⒒像をアップスケ`ルします
Example: Default args should use 221 as total keyframes.,,,,例：デフォルト引数では、合キ`フレ`ム数として221を使用する必要があります。
Load Hypernetwork creation option from saved json file,,,,保存された json ファイルから Hypernetwork の作成オプションをiみzむ
Translation Z,,,,ZS方向の移
Create images embedding,创建图集 Embedding,创建图集 Embedding,创建图集 Embedding,埋めzみ画像を作成
ControlNet v1.1.223,扩散控制网络(ControlNet),,,
OUT_B_09,,模型B 输出层09,模型B 输出层09,
Dataset folder structure,,,,デ`タセットのフォルダ造
Judge,,,,判定
Only set this variable if it doesn't already exist ? _new,,,,この涫が存在しない龊悉摔韦咴O定する ? _new
ControlNet v1.1.208,扩散控制网络(ControlNet),,,
Tuning,,,,チュ`ニング
Focal point face weight,焦点面部权重,焦点面部权重,焦点面部权重,焦点面のウェイト
ControlNet v1.1.246,扩散控制网络(ControlNet),,,
"Only masked padding, pixels",仅蒙版重绘参考半径(像素),仅蒙版模式的边缘预留像素,仅蒙版模式的边缘预留像素,"""マスクのみ""外趣斡喟 (px)"
Colorprimarytextactive,Colorprimarytextactive,,,
Use lossless compression for webp images,对 webp 图片使用无损压缩,对 webp 图像使用无损压缩,对 webp 图像使用无损压缩,webp形式の画像にロスレスRsを使用する
Available,可用,可用,可用,C能リスト
Preprocess,预处理,预处理,预处理,前I理_始
ControlNet inpaint not masked,在 ControlNet 中重绘非蒙版区域,,复制（非蒙版）到ControlNet重绘,
Motion use prev img,,,,前の画像を使用した婴
IN_A_04,,模型A 输入层04,模型A 输入层04,
Swap Steps,,,,ステップの入れ替え
This script is deprecated. Please use the full Deforum extension instead.,,此脚本已弃用。请改用完整的 Deforum 扩展,此脚本已弃用。请改用完整的 Deforum 扩展,
"Reuse seed from last generation, mostly useful if it was randomed",重用上一次使用的随机种子，如果想要固定结果就会很有用,重用上一次使用的随机种子，如果想要固定结果就会很有用,重用上一次使用的随机种子，如果想要固定结果就会很有用,前回の生成rに使用したシ`ドを再利用します。前回がランダムなシ`ドであった龊悉擞郡扦埂
